use lexi_matic::Lexer;

#[derive(Lexer, Debug, PartialEq, Eq, Clone)]
#[lexer(skip = r"[ \t\r\n\f]+", skip = r"#[^\n]*\n")]
pub enum Token<'a> {
    #[token("assume")]
    Assume,
    #[token("match")]
    Match,
    #[token("assert")]
    Assert,
    #[token("in")]
    In,
    #[token("method")]
    Method,
    #[token("!")]
    Excl,
    #[regex("(and|&)")]
    And,
    #[token("or")]
    Or,
    #[regex("(~|not)")]
    Negate,
    #[regex("(implies|==>)")]
    Cond,
    #[regex("(bicond|<==>)")]
    Bicond,
    #[regex("(eq|=)")]
    Equal,
    #[regex("(mp|modus-ponens)")]
    MethodMp,
    #[regex("(mt|modus-tollens)")]
    MethodMt,
    #[token("both")]
    MethodBoth,
    #[token("left-and")]
    MethodLeftAnd,
    #[token("right-and")]
    MethodRightAnd,
    #[token("left-either")]
    MethodLeftEither,
    #[token("right-either")]
    MethodRightEither,
    #[token("false-elim")]
    MethodFalseElim,
    #[token("absurd")]
    MethodAbsurd,
    #[token("claim")]
    MethodClaim,
    #[regex("(dn|double-neg|double-negation)")]
    MethodDn,
    #[token("chain")]
    MethodChain,
    #[token("chain->")]
    MethodChainConclude,
    #[token("true")]
    True,
    #[token("false")]
    False,
    #[token("true-intro")]
    MethodTrueIntro,
    #[token("equiv")]
    MethodEquiv,
    #[token("left-iff")]
    MethodLeftIff,
    #[token("right-iff")]
    MethodRightIff,
    #[regex("(cd|conj-d|conj-dilemma|conjunctive-dilemma)")]
    MethodCd,
    #[token("(")]
    ParenOpen,
    #[token(")")]
    ParenClose,
    #[token("{")]
    BraceOpen,
    #[token("}")]
    BraceClose,
    #[token(";")]
    Semicolon,
    #[token(",")]
    Comma,
    #[token(".")]
    Period,
    #[regex("(prev|past|inputs)")]
    PrevState,
    #[regex("(next|future|outputs)")]
    NextState,
    #[token("set")]
    Set,
    #[token("fn")]
    Function,
    #[token("->")]
    RightArrow,
    #[token["["]]
    LeftBracket,
    #[token("]")]
    RightBracket,
    #[token("rel")]
    Relation,
    #[token("datatype")]
    Datatype,
    #[token(":=")]
    ColonEquals,
    #[token("by-induction")]
    ByInduction,
    #[token("forall")]
    ForAll,
    #[token("exists")]
    Exists,
    #[token("define")]
    Define,
    #[token("disable")]
    Disable,
    #[token("enable")]
    Enable,
    #[token("uspec")]
    MethodUspec,
    #[token("pick-any")]
    MethodUgen,
    #[token("egen")]
    MethodEgen,
    #[token("pick-witness")]
    MethodESpec,
    #[token("let")]
    LetExpr,
    #[token("lambda")]
    Lambda,
    #[token("cond")]
    CondRule,
    #[token("suppose-absurd")]
    SupposeAbsurd,
    #[token("_")]
    Underscore,
    #[token("fix")]
    Fix,
    #[token("dmatch")]
    DMatch,
    #[regex("(by|because-of|due-to)")]
    By,
    #[regex("\\?[a-zA-Z_][a-zA-Z0-9_]*")]
    Atom(&'a str),
    #[regex("[a-zA-Z_][a-zA-Z0-9_]*")]
    Identifier(&'a str),
    // #[regex("[0-9]+(?:_[0-9]+)*")]
    // Int,
}

pub fn lexer(src: &str) -> TokenIterator {
    Token::lex(src)
}
