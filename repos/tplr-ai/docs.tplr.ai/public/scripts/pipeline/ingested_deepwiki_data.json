{
  "/tplr-ai/templar/1-overview": {
    "original_deepwiki_href": "/tplr-ai/templar/1-overview",
    "title": "Overview",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/1-overview",
    "level": 0,
    "target_astro_path": "/",
    "main_markdown_content": "# Overview\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [README.md](README.md)\n- [docs/miner.md](docs/miner.md)\n- [docs/validator.md](docs/validator.md)\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [pyproject.toml](pyproject.toml)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n- [tests/test_comms.py](tests/test_comms.py)\n- [uv.lock](uv.lock)\n\n</details>\n\n\n\nThis page provides an introduction to Templar, a decentralized training framework for large language models that leverages the Bittensor network to coordinate distributed training across heterogeneous compute resources connected via the internet.\n\nSources: [pyproject.toml:5-9](), [README.md:38-47]()\n\n## What is Templar?\n\nTemplar is a system for incentivized distributed training of large language models. It connects diverse computational nodes through a carefully designed incentive mechanism, enabling collaborative training while ensuring honest participation and quality contributions. The framework implements a peer-to-peer architecture where participants contribute their computational resources to train a shared model, with rewards proportional to the quality of their contributions.\n\nSources: [README.md:38-47](), [README.md:50-57]()\n\n## System Architecture\n\n### High-Level Architecture\n\n```mermaid\ngraph TD\n    subgraph \"Bittensor Network\"\n        BT[\"BitTensor Blockchain\"]\n    end\n    \n    subgraph \"Participant Nodes\"\n        MN[\"Miner<br/>(neurons/miner.py)\"]\n        VL[\"Validator<br/>(neurons/validator.py)\"]\n        AG[\"Aggregator<br/>(neurons/aggregator.py)\"]\n    end\n    \n    subgraph \"Storage Layer\"\n        R2[\"Cloudflare R2 Storage\"]\n        subgraph \"Buckets\"\n            GB[\"Gradients Bucket\"]\n            DB[\"Dataset Bucket\"]\n            AB[\"Aggregator Bucket\"]\n        end\n    end\n    \n    subgraph \"Monitoring\"\n        WB[\"Weights & Biases\"]\n        IF[\"InfluxDB\"]\n        LK[\"Loki Logging\"]\n    end\n    \n    MN <-->|\"Set/get weights<br/>tplr.comms.ChainManager\"| BT\n    VL <-->|\"Set/get weights<br/>tplr.comms.ChainManager\"| BT\n    \n    MN -->|\"Upload gradients<br/>comms.put()\"| GB\n    MN <-----|\"Get datasets<br/>R2DatasetLoader\"| DB\n    MN <-----|\"Gather peer gradients<br/>comms.gather()\"| GB\n    VL -->|\"Upload evaluations<br/>comms.put()\"| GB\n    VL <-----|\"Evaluate miner gradients<br/>comms.gather()\"| GB\n    AG <-----|\"Gather & process gradients<br/>comms.gather()\"| GB\n    AG -->|\"Store aggregated state<br/>comms.save_checkpoint()\"| AB\n    \n    MN -.->|\"Log metrics<br/>tplr.metrics.MetricsLogger\"| WB\n    VL -.->|\"Log metrics<br/>tplr.metrics.MetricsLogger\"| WB\n    MN -.->|\"Log metrics<br/>tplr.metrics.MetricsLogger\"| IF\n    VL -.->|\"Log metrics<br/>tplr.metrics.MetricsLogger\"| IF\n    MN -.->|\"Log events<br/>tplr.logger\"| LK\n    VL -.->|\"Log events<br/>tplr.logger\"| LK\n```\n\nSources: [neurons/miner.py:65-755](), [neurons/validator.py:85-775](), [src/tplr/comms.py:64-221](), [src/tplr/comms.py:383-414]()\n\n### Gradient Exchange Workflow\n\n```mermaid\nsequenceDiagram\n    participant M as \"Miner<br/>(neurons/miner.py)\"\n    participant R2 as \"R2 Storage<br/>(tplr.comms.Comms)\"\n    participant V as \"Validator<br/>(neurons/validator.py)\"\n    participant BT as \"Bittensor<br/>(Chain)\"\n    \n    Note over M,BT: Window N begins (current_window = N)\n    \n    M->>M: window_step = 0\n    M->>R2: Load dataset pages for window (R2DatasetLoader.next_pages)\n    M->>M: Train model on dataset batches\n    M->>M: Accumulate gradients (model.backward())\n    M->>M: Compress gradients (tplr.prepare_gradient_dict)\n    M->>R2: Upload compressed gradients (comms.put)\n    \n    V->>R2: Gather miner gradients (comms.gather)\n    V->>V: Evaluate gradient quality (evaluate_model_on_batches)\n    V->>V: Calculate scores (loss_before - loss_after)\n    V->>V: Update OpenSkill ratings (update_openskill_ratings)\n    V->>BT: Set weights on blockchain\n    \n    Note over M,BT: Window N+1 begins (current_window = N+1)\n    \n    M->>R2: Gather peer gradients (comms.gather)\n    M->>M: Decompress and apply gradients\n    M->>M: Update model (optimizer.step)\n    M->>M: global_step += 1\n```\n\nSources: [neurons/miner.py:225-255](), [neurons/validator.py:490-514](), [neurons/validator.py:516-775]()\n\n## Core Components\n\n### Miners\n\nMiners train the model on assigned data subsets and share their gradients with peers. They:\n\n1. Load a subset of the dataset based on the current window and their UID\n2. Perform forward and backward passes to compute gradients\n3. Compress gradients using DCT transform and top-k selection\n4. Upload compressed gradients to R2 storage\n5. Gather and apply peer gradients to update their model\n6. Progress to the next window\n\nThe `Miner` class in [neurons/miner.py]() implements this functionality, with its main loop in the asynchronous `run()` method.\n\nSources: [neurons/miner.py:65-229](), [README.md:64-117]()\n\n### Validators\n\nValidators evaluate miners' gradient contributions and set weights on the blockchain. They:\n\n1. Gather gradients submitted by miners\n2. Evaluate each miner's contribution by measuring loss improvement\n3. Calculate scores based on the performance improvement\n4. Update OpenSkill ratings for miners\n5. Set weights on the blockchain to influence reward distribution\n\nThe `Validator` class in [neurons/validator.py]() implements this functionality, with evaluation logic in `evaluate_model_on_batches()` and weight setting in `update_weights()`.\n\nSources: [neurons/validator.py:85-144](), [neurons/validator.py:356-437](), [README.md:140-184]()\n\n### Communication System\n\nThe communication system, implemented in the `Comms` class, handles data exchange between nodes:\n\n1. **Gradient Exchange**: Efficient transfer of compressed gradients\n2. **Dataset Access**: Loading training data from R2 storage\n3. **Checkpoint Management**: Saving and loading model states\n4. **Blockchain Integration**: Setting and getting weights on the Bittensor network\n\nKey methods include `put()` for uploading data, `gather()` for collecting peer gradients, and `s3_get_object()`/`s3_put_object()` for R2 storage operations.\n\nSources: [src/tplr/comms.py:64-221](), [src/tplr/comms.py:322-371]()\n\n### Gradient Compression\n\nTo reduce communication overhead, Templar uses:\n\n1. **DCT Transform**: Converting gradients to frequency domain\n2. **Top-K Selection**: Keeping only the most significant coefficients\n3. **Momentum Tracking**: Maintaining gradient momentum between updates\n\nThis compression is handled by `TransformDCT` and `CompressDCT` classes (imported in miners and validators).\n\nSources: [neurons/miner.py:130-147](), [neurons/validator.py:159-175]()\n\n## Storage Architecture\n\n```mermaid\ngraph TD\n    subgraph \"R2Storage\"\n        GB[\"Gradients Bucket<br/>(comms.bucket)\"]\n        DB[\"Dataset Bucket<br/>(R2DatasetLoader)\"]\n        AB[\"Aggregator Bucket<br/>(comms.load_aggregation)\"]\n    end\n    \n    subgraph \"DataFlow\"\n        M[\"Miner.run()\"]\n        V[\"Validator.run()\"]\n        A[\"Aggregator\"]\n    end\n    \n    M -->|\"comms.put()<br/>gradient-{window}-{uid}.pt\"| GB\n    M <--->|\"R2DatasetLoader.next_pages()<br/>data_{page_number}.parquet\"| DB\n    M <--->|\"comms.gather()<br/>gradient-{window}-{uid}.pt\"| GB\n    \n    V -->|\"comms.put_peer_list()<br/>peers_{window}.json\"| GB\n    V <--->|\"comms.gather()<br/>gradient-{window}-{uid}.pt\"| GB\n    V <--->|\"R2DatasetLoader.next_pages()<br/>data_{page_number}.parquet\"| DB\n    \n    A -->|\"comms.put()<br/>aggregation-{window}.pt\"| AB\n    \n    V <--->|\"comms.load_aggregation()<br/>aggregation-{window}.pt\"| AB\n    M <--->|\"comms.load_aggregation()<br/>aggregation-{window}.pt\"| AB\n```\n\nSources: [src/tplr/comms.py:174-220](), [neurons/miner.py:339-350](), [neurons/validator.py:832-858]()\n\n## System Configuration\n\nTemplar uses a configuration system with parameters defined in [hparams.json](). Key parameters include:\n\n| Parameter | Description | Default Value |\n|-----------|-------------|--------------|\n| `topk_compression` | Compression ratio for gradients | 32 |\n| `blocks_per_window` | Blockchain blocks per training window | 7 |\n| `pages_per_window` | Dataset pages to process per window | 6 |\n| `batch_size` | Training batch size | 6 |\n| `learning_rate` | Base learning rate | 4e-4 |\n| `checkpoint_frequency` | Windows between checkpoint saves | 100 |\n| `validator_offset` | Windows validators lag behind miners | 2 |\n\nSources: [hparams.json:1-53]()\n\n## Incentive Mechanism\n\nThe incentive system aligns individual miner incentives with the collective goal of improving model performance:\n\n1. **Gradient Evaluation**: Validators compute a score based on loss improvement from each miner's gradient\n2. **OpenSkill Ratings**: Miners are rated using the PlackettLuce model based on their contributions\n3. **Weight Setting**: Weights on the blockchain are updated based on these ratings\n4. **Reward Distribution**: Miners receive rewards proportional to their assigned weights\n\nThis mechanism encourages honest participation and quality contributions.\n\nSources: [neurons/validator.py:356-437](), [README.md:216-270]()\n\n## Implementation Details\n\nTemplar is implemented in Python and relies on several key libraries:\n\n- **PyTorch**: For model definition and training (LlamaForCausalLM)\n- **Bittensor**: For blockchain integration and incentive mechanism\n- **Cloudflare R2**: For distributed storage\n- **OpenSkill**: For fair rating of miner contributions\n- **WandB/InfluxDB/Loki**: For monitoring and telemetry\n\nThe implementation follows an asynchronous model, with extensive use of Python's `asyncio` for handling concurrent operations.\n\nSources: [pyproject.toml:11-36](), [src/tplr/__init__.py:22-36]()\n\n## Related Pages\n\n- For detailed miner functionality, see [Miners](#2)\n- For validator operations, see [Validators](#3)\n- For aggregation server, see [Aggregation Server](#4)\n- For communication system details, see [Communication System](#6)\n- For system architecture, see [System Architecture](#1.1)",
    "resolved_links": [
      {
        "text": "README.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/README.md",
        "original_deepwiki_href": "README.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/miner.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/miner.md",
        "original_deepwiki_href": "docs/miner.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/validator.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/validator.md",
        "original_deepwiki_href": "docs/validator.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "pyproject.toml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/pyproject.toml",
        "original_deepwiki_href": "pyproject.toml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_comms.py",
        "original_deepwiki_href": "tests/test_comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "uv.lock",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/uv.lock",
        "original_deepwiki_href": "uv.lock",
        "context": "collapsible_aside_link"
      },
      {
        "text": "pyproject.toml:5-9",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "README.md:38-47",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "README.md:50-57",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:65-755",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:85-775",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:64-221",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:383-414",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:225-255",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:490-514",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:516-775",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:65-229",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "README.md:64-117",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:85-144",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:356-437",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "README.md:140-184",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:322-371",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:130-147",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:159-175",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:174-220",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:339-350",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:832-858",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:1-53",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "README.md:216-270",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "pyproject.toml:11-36",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/__init__.py:22-36",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Miners",
        "href": "/miners#2",
        "original_deepwiki_href": "#2",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Validators",
        "href": "/validators#3",
        "original_deepwiki_href": "#3",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Aggregation Server",
        "href": "/aggregation-server#4",
        "original_deepwiki_href": "#4",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Communication System",
        "href": "/communication-system#6",
        "original_deepwiki_href": "#6",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "System Architecture",
        "href": "/system-architecture#1.1",
        "original_deepwiki_href": "#1.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Bittensor Network\"\n        BT[\"BitTensor Blockchain\"]\n    end\n    \n    subgraph \"Participant Nodes\"\n        MN[\"Miner<br/>(neurons/miner.py)\"]\n        VL[\"Validator<br/>(neurons/validator.py)\"]\n        AG[\"Aggregator<br/>(neurons/aggregator.py)\"]\n    end\n    \n    subgraph \"Storage Layer\"\n        R2[\"Cloudflare R2 Storage\"]\n        subgraph \"Buckets\"\n            GB[\"Gradients Bucket\"]\n            DB[\"Dataset Bucket\"]\n            AB[\"Aggregator Bucket\"]\n        end\n    end\n    \n    subgraph \"Monitoring\"\n        WB[\"Weights & Biases\"]\n        IF[\"InfluxDB\"]\n        LK[\"Loki Logging\"]\n    end\n    \n    MN <-->|\"Set/get weights<br/>tplr.comms.ChainManager\"| BT\n    VL <-->|\"Set/get weights<br/>tplr.comms.ChainManager\"| BT\n    \n    MN -->|\"Upload gradients<br/>comms.put()\"| GB\n    MN <-----|\"Get datasets<br/>R2DatasetLoader\"| DB\n    MN <-----|\"Gather peer gradients<br/>comms.gather()\"| GB\n    VL -->|\"Upload evaluations<br/>comms.put()\"| GB\n    VL <-----|\"Evaluate miner gradients<br/>comms.gather()\"| GB\n    AG <-----|\"Gather & process gradients<br/>comms.gather()\"| GB\n    AG -->|\"Store aggregated state<br/>comms.save_checkpoint()\"| AB\n    \n    MN -.->|\"Log metrics<br/>tplr.metrics.MetricsLogger\"| WB\n    VL -.->|\"Log metrics<br/>tplr.metrics.MetricsLogger\"| WB\n    MN -.->|\"Log metrics<br/>tplr.metrics.MetricsLogger\"| IF\n    VL -.->|\"Log metrics<br/>tplr.metrics.MetricsLogger\"| IF\n    MN -.->|\"Log events<br/>tplr.logger\"| LK\n    VL -.->|\"Log events<br/>tplr.logger\"| LK",
      "sequenceDiagram\n    participant M as \"Miner<br/>(neurons/miner.py)\"\n    participant R2 as \"R2 Storage<br/>(tplr.comms.Comms)\"\n    participant V as \"Validator<br/>(neurons/validator.py)\"\n    participant BT as \"Bittensor<br/>(Chain)\"\n    \n    Note over M,BT: Window N begins (current_window = N)\n    \n    M->>M: window_step = 0\n    M->>R2: Load dataset pages for window (R2DatasetLoader.next_pages)\n    M->>M: Train model on dataset batches\n    M->>M: Accumulate gradients (model.backward())\n    M->>M: Compress gradients (tplr.prepare_gradient_dict)\n    M->>R2: Upload compressed gradients (comms.put)\n    \n    V->>R2: Gather miner gradients (comms.gather)\n    V->>V: Evaluate gradient quality (evaluate_model_on_batches)\n    V->>V: Calculate scores (loss_before - loss_after)\n    V->>V: Update OpenSkill ratings (update_openskill_ratings)\n    V->>BT: Set weights on blockchain\n    \n    Note over M,BT: Window N+1 begins (current_window = N+1)\n    \n    M->>R2: Gather peer gradients (comms.gather)\n    M->>M: Decompress and apply gradients\n    M->>M: Update model (optimizer.step)\n    M->>M: global_step += 1",
      "graph TD\n    subgraph \"R2Storage\"\n        GB[\"Gradients Bucket<br/>(comms.bucket)\"]\n        DB[\"Dataset Bucket<br/>(R2DatasetLoader)\"]\n        AB[\"Aggregator Bucket<br/>(comms.load_aggregation)\"]\n    end\n    \n    subgraph \"DataFlow\"\n        M[\"Miner.run()\"]\n        V[\"Validator.run()\"]\n        A[\"Aggregator\"]\n    end\n    \n    M -->|\"comms.put()<br/>gradient-{window}-{uid}.pt\"| GB\n    M <--->|\"R2DatasetLoader.next_pages()<br/>data_{page_number}.parquet\"| DB\n    M <--->|\"comms.gather()<br/>gradient-{window}-{uid}.pt\"| GB\n    \n    V -->|\"comms.put_peer_list()<br/>peers_{window}.json\"| GB\n    V <--->|\"comms.gather()<br/>gradient-{window}-{uid}.pt\"| GB\n    V <--->|\"R2DatasetLoader.next_pages()<br/>data_{page_number}.parquet\"| DB\n    \n    A -->|\"comms.put()<br/>aggregation-{window}.pt\"| AB\n    \n    V <--->|\"comms.load_aggregation()<br/>aggregation-{window}.pt\"| AB\n    M <--->|\"comms.load_aggregation()<br/>aggregation-{window}.pt\"| AB"
    ],
    "potential_frontmatter": {
      "title": "Overview"
    }
  },
  "/tplr-ai/templar/1.1-system-architecture": {
    "original_deepwiki_href": "/tplr-ai/templar/1.1-system-architecture",
    "title": "System Architecture",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/1.1-system-architecture",
    "level": 1,
    "target_astro_path": "/system-architecture",
    "main_markdown_content": "# System Architecture\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/aggregator.py](neurons/aggregator.py)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [pyproject.toml](pyproject.toml)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/chain.py](src/tplr/chain.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n- [src/tplr/compress.py](src/tplr/compress.py)\n- [src/tplr/neurons.py](src/tplr/neurons.py)\n- [telemetry/simulator/loki-test.py](telemetry/simulator/loki-test.py)\n- [tests/test_comms.py](tests/test_comms.py)\n- [tests/test_model_comparison.py](tests/test_model_comparison.py)\n- [uv.lock](uv.lock)\n\n</details>\n\n\n\nThis document provides a comprehensive overview of the Templar framework's architecture, outlining its core components and their interactions. Templar is a decentralized training framework built on the Bittensor network that enables collaborative training of large language models across distributed compute resources.\n\nFor information about the incentive mechanisms that drive the distributed training process, see [Incentive Design](#1.2).\n\n## Core Components\n\n```mermaid\ngraph TD\n    subgraph \"Network Layer\"\n        BN[\"Bittensor Network\"]\n        MG[\"Metagraph\"]\n    end\n\n    subgraph \"Node Layer\"\n        M[\"Miners\"]\n        V[\"Validators\"]\n        A[\"AggregationServer\"]\n    end\n\n    subgraph \"Storage Layer\"\n        R2[\"Cloudflare R2 Storage\"]\n        subgraph \"Buckets\"\n            GB[\"Gradients Bucket\"]\n            DB[\"Dataset Bucket\"]\n            AB[\"Aggregator Bucket\"]\n            CP[\"Checkpoint Storage\"]\n        end\n    end\n\n    subgraph \"Communication Layer\"\n        CM[\"Comms Module\"]\n        CH[\"Chain Manager\"]\n    end\n\n    M <--> BN\n    V <--> BN\n    BN <--> MG\n\n    M <--> CM\n    V <--> CM\n    A <--> CM\n    \n    CM <--> CH\n    CH <--> BN\n\n    GB <--> CM\n    DB <--> CM\n    AB <--> CM\n    CP <--> CM\n\n    style Network fill:#f9f9f9\n    style Node fill:#f9f9f9\n    style Storage fill:#f9f9f9\n    style Communication fill:#f9f9f9\n```\n\nSources:\n- [neurons/miner.py:124-184](neurons/miner.py)\n- [neurons/validator.py:173-222](neurons/validator.py)\n- [neurons/aggregator.py:120-132](neurons/aggregator.py)\n- [src/tplr/comms.py:64-122](src/tplr/comms.py)\n\nThe Templar system consists of four main architectural layers:\n\n1. **Network Layer**: Provides the decentralized infrastructure via Bittensor blockchain\n2. **Node Layer**: Comprises the different types of nodes that perform specific roles\n3. **Storage Layer**: Offers distributed storage for gradients, datasets, and model checkpoints\n4. **Communication Layer**: Facilitates data exchange between nodes and storage\n\n## Node Types and Responsibilities\n\n```mermaid\ngraph TD\n    subgraph \"Miner\"\n        M_Train[\"Model Training\"]\n        M_Grad[\"Gradient Computation\"]\n        M_Comp[\"Gradient Compression\"]\n        M_Post[\"Gradient Posting\"]\n    end\n\n    subgraph \"Validator\"\n        V_Gath[\"Gradient Gathering\"]\n        V_Eval[\"Gradient Evaluation\"]\n        V_Weight[\"Weight Setting\"]\n        V_Sync[\"Model Synchronization\"]\n    end\n\n    subgraph \"Aggregator\"\n        A_Gath[\"Gradient Collection\"]\n        A_Agg[\"Gradient Aggregation\"]\n        A_Post[\"Aggregation Posting\"]\n    end\n\n    M_Train --> M_Grad --> M_Comp --> M_Post\n    V_Gath --> V_Eval --> V_Weight --> V_Sync\n    A_Gath --> A_Agg --> A_Post\n\n    M_Post -.-> V_Gath\n    M_Post -.-> A_Gath\n    A_Post -.-> V_Sync\n```\n\nSources:\n- [neurons/miner.py:228-755](neurons/miner.py)\n- [neurons/validator.py:516-1866](neurons/validator.py)\n- [neurons/aggregator.py:162-380](neurons/aggregator.py)\n\n### Miner Neurons\n\nMiners are responsible for training the language model and generating gradients. Their key functions include:\n\n1. Loading training data from the dataset bucket\n2. Performing forward and backward passes through the model\n3. Compressing gradients using DCT-based compression\n4. Uploading compressed gradients to the gradient bucket\n\n### Validator Neurons\n\nValidators evaluate the quality of miners' gradients and set weights on the blockchain. Their key functions include:\n\n1. Gathering gradients from miners\n2. Evaluating gradient quality by measuring loss improvement\n3. Calculating and setting weights on the blockchain\n4. Tracking miner performance with OpenSkill ratings\n\n### Aggregation Server\n\nThe aggregation server collects and combines gradients from miners, providing a consolidated source for model updates. Its key functions include:\n\n1. Gathering gradients from miners\n2. Aggregating gradients based on validator weights\n3. Storing aggregated gradients for validators and miners to use\n\n## Data Flow and Gradient Processing\n\n```mermaid\nflowchart TD\n    subgraph \"Miner Processing\"\n        MT[\"Model Training\"] --> GC[\"Gradient Computation\"]\n        GC --> WD[\"Weight Decay\"]\n        WD --> MM[\"Momentum Update\"]\n        MM --> DCTS[\"DCT Transform\"]\n        DCTS --> COMP[\"Top-K Compression\"]\n        COMP --> UP[\"Upload to R2\"]\n    end\n\n    subgraph \"Validator Processing\"\n        DL[\"Download Gradients\"] --> DECOMP[\"Decompress\"]\n        DECOMP --> EVAL[\"Evaluate Improvement\"]\n        EVAL --> SCORE[\"Calculate Score\"]\n        SCORE --> WT[\"Set Weights\"]\n    end\n\n    subgraph \"Aggregator Processing\"\n        AG_DL[\"Download Gradients\"] --> AG_WT[\"Apply Weights\"]\n        AG_WT --> AG_COMB[\"Combine Gradients\"]\n        AG_COMB --> AG_UP[\"Upload Aggregation\"]\n    end\n\n    UP --> DL\n    UP --> AG_DL\n    AG_UP --> EVAL\n    WT --> AG_WT\n```\n\nSources:\n- [src/tplr/neurons.py:40-124](src/tplr/neurons.py)\n- [neurons/miner.py:395-405](neurons/miner.py)\n- [neurons/validator.py:489-514](neurons/validator.py)\n\n### Gradient Compression Mechanism\n\nA key innovation in Templar is the DCT-based gradient compression system that enables efficient sharing of gradients across nodes.\n\n1. **Transform DCT**: Converts gradients to frequency domain using Discrete Cosine Transform\n2. **Compression**: Selects top-K coefficients for transmission\n3. **Decompression**: Reconstructs gradients from compressed representation\n\n```mermaid\nflowchart LR\n    subgraph \"DCT Compression Pipeline\"\n        direction LR\n        GRAD[\"Original Gradient\"] --> ENCODE[\"DCT Transform\\nTransformDCT.encode()\"]\n        ENCODE --> COMPRESS[\"Top-K Selection\\nCompressDCT.compress()\"]\n        COMPRESS --> TRANSMIT[\"Transmit\\nidxs + vals\"]\n    end\n\n    subgraph \"DCT Decompression Pipeline\"\n        direction LR\n        RECEIVE[\"Receive\\nidxs + vals\"] --> DECOMPRESS[\"Reconstruction\\nCompressDCT.decompress()\"]\n        DECOMPRESS --> DECODE[\"Inverse DCT\\nTransformDCT.decode()\"]\n        DECODE --> RECONST[\"Reconstructed Gradient\"]\n    end\n\n    TRANSMIT --> RECEIVE\n```\n\nSources:\n- [src/tplr/compress.py:35-98](src/tplr/compress.py)\n- [src/tplr/compress.py:123-177](src/tplr/compress.py)\n\n## Communication System\n\nThe communication system is the backbone of Templar, enabling data exchange between nodes and storage. It provides a unified interface for all data operations.\n\n```mermaid\nclassDiagram\n    class Comms {\n        +wallet: Wallet\n        +bucket: Bucket\n        +session: Session\n        +client_semaphore: Semaphore\n        +put(state_dict, uid, window, key)\n        +get(uid, window, key)\n        +gather(uids, window, key)\n        +load_checkpoint(model, optimizer, scheduler)\n        +save_checkpoint(model, optimizer, scheduler)\n        +post_peer_list(peers, window)\n        +get_peer_list()\n    }\n\n    class ChainManager {\n        +commitments: Dict\n        +peers: PeerArray\n        +eval_peers: Dict\n        +fetch_commitments()\n        +get_commitment(uid)\n        +try_commit(wallet, bucket)\n        +update_peers_with_buckets()\n    }\n\n    class Bucket {\n        +name: str\n        +account_id: str\n        +access_key_id: str\n        +secret_access_key: str\n    }\n\n    Comms --|> ChainManager : inherits\n    Comms --> Bucket : uses\n```\n\nSources:\n- [src/tplr/comms.py:64-154](src/tplr/comms.py)\n- [src/tplr/chain.py:37-72](src/tplr/chain.py)\n\nThe `Comms` class provides the following key functions:\n\n1. **Data Exchange**: Methods for storing and retrieving data from R2 storage\n2. **Gradient Gathering**: Collects and processes gradients from multiple miners\n3. **Checkpoint Management**: Saves and loads model checkpoints\n4. **Peer Management**: Handles peer discovery and selection\n\nThe `ChainManager` is responsible for:\n\n1. **Chain Commitments**: Manages commitments to the Bittensor blockchain\n2. **Bucket Authentication**: Stores and retrieves bucket credentials\n3. **Peer Management**: Tracks active peers and updates peer lists\n\n## Storage System\n\n```mermaid\ngraph TD\n    subgraph \"R2 Storage\"\n        GB[\"Gradients Bucket\"]\n        DB[\"Dataset Bucket\"]\n        AB[\"Aggregator Bucket\"]\n        CP[\"Checkpoint Storage\"]\n    end\n\n    subgraph \"Gradient Files\"\n        GRAD_FILE[\"gradient-{window}-{uid}-v{version}.pt\"]\n    end\n\n    subgraph \"Dataset Files\"\n        DATA_FILE[\"page-{number}.parquet\"]\n    end\n\n    subgraph \"Aggregation Files\"\n        AGG_FILE[\"aggregation-{window}.pt\"]\n    end\n\n    subgraph \"Checkpoint Files\"\n        CKP_FILE[\"checkpoint-{window}-v{version}.pt\"]\n    end\n\n    GB --> GRAD_FILE\n    DB --> DATA_FILE\n    AB --> AGG_FILE\n    CP --> CKP_FILE\n```\n\nSources:\n- [src/tplr/comms.py:265-318](src/tplr/comms.py)\n- [src/tplr/comms.py:322-371](src/tplr/comms.py)\n- [src/tplr/comms.py:373-455](src/tplr/comms.py)\n\nStorage in Templar is handled through Cloudflare R2, which provides a scalable and distributed storage solution. The system uses four main buckets:\n\n1. **Gradients Bucket**: Stores gradients uploaded by miners\n2. **Dataset Bucket**: Contains training data in Parquet format\n3. **Aggregator Bucket**: Stores aggregated gradients from the aggregation server\n4. **Checkpoint Storage**: Maintains model checkpoints for recovery and synchronization\n\n## Integration with Bittensor Network\n\n```mermaid\nflowchart TD\n    subgraph \"Templar System\"\n        M[\"Miners\"]\n        V[\"Validators\"]\n        A[\"Aggregation Server\"]\n    end\n\n    subgraph \"Bittensor Network\"\n        SUB[\"Subtensor\"]\n        MG[\"Metagraph\"]\n        WT[\"Weight Setting\"]\n        STS[\"Stakes\"]\n    end\n\n    M -->|\"Register Hotkeys\"| SUB\n    V -->|\"Register Hotkeys\"| SUB\n    V -->|\"Set Weights\"| WT\n    SUB -->|\"Update\"| MG\n    STS -->|\"Influence\"| MG\n    MG -->|\"Determine Rewards\"| M\n    MG -->|\"Determine Influence\"| V\n```\n\nSources:\n- [neurons/validator.py:134-142](neurons/validator.py)\n- [neurons/miner.py:114-123](neurons/miner.py)\n- [src/tplr/chain.py:174-195](src/tplr/chain.py)\n\nThe Templar system integrates with the Bittensor network through several mechanisms:\n\n1. **Hotkey Registration**: Miners and validators register their hotkeys on the subnet\n2. **Weight Setting**: Validators set weights on the blockchain based on gradient quality\n3. **Metagraph Synchronization**: Nodes periodically synchronize with the metagraph\n4. **Chain Commitments**: Nodes commit bucket information to the chain for discovery\n\n## Window-Based Training Cycle\n\n```mermaid\nsequenceDiagram\n    participant M as Miner\n    participant R2 as R2 Storage\n    participant V as Validator\n    participant A as Aggregator\n    participant BT as Bittensor\n\n    Note over M,BT: Window N\n    \n    M->>M: Train model on dataset\n    M->>M: Prepare gradients\n    M->>R2: Upload compressed gradients\n    \n    V->>R2: Gather gradients\n    V->>V: Evaluate gradients\n    V->>BT: Set weights on chain\n    \n    A->>R2: Collect gradients\n    A->>A: Aggregate gradients\n    A->>R2: Store aggregated gradients\n    \n    Note over M,BT: Window N+1\n    \n    M->>R2: Load aggregated gradients\n    M->>M: Update model parameters\n    V->>R2: Load aggregated gradients\n    V->>V: Update model parameters\n```\n\nSources:\n- [neurons/miner.py:320-406](neurons/miner.py)\n- [neurons/validator.py:626-643](neurons/validator.py)\n- [neurons/aggregator.py:210-310](neurons/aggregator.py)\n\nThe Templar system operates on a window-based cycle, where each window corresponds to a specific number of blockchain blocks. The training process follows these steps:\n\n1. **Miners**:\n   - Train models on data for the current window\n   - Generate and compress gradients\n   - Upload gradients to R2 storage\n\n2. **Validators**:\n   - Gather gradients from miners\n   - Evaluate gradient quality\n   - Set weights on the blockchain\n\n3. **Aggregator**:\n   - Collect gradients from miners\n   - Aggregate gradients based on weights\n   - Store aggregated result for next window\n\n4. **Next Window**:\n   - All participants load aggregated gradients\n   - Update model parameters\n   - Begin next training cycle\n\n## Peer Selection and Management\n\n```mermaid\nflowchart TD\n    subgraph \"Validator\"\n        VP[\"Peer Selection\"]\n        VR[\"OpenSkill Ratings\"]\n        VW[\"Weight Setting\"]\n    end\n\n    subgraph \"Peer Management\"\n        PL[\"Peer List Generation\"]\n        PR[\"Peer Repository\"]\n        PC[\"Peer Commitment\"]\n    end\n\n    subgraph \"Nodes\"\n        M[\"Miners\"]\n        V[\"Other Validators\"]\n    end\n\n    VR -->|\"Influence\"| VP\n    VP -->|\"Generate\"| PL\n    PL -->|\"Store\"| PR\n    M -->|\"Register\"| PC\n    V -->|\"Register\"| PC\n    PC -->|\"Inform\"| PR\n    PR -->|\"Provide\"| VP\n```\n\nSources:\n- [neurons/validator.py:396-423](neurons/validator.py)\n- [src/tplr/chain.py:426-487](src/tplr/chain.py)\n- [src/tplr/neurons.py:127-196](src/tplr/neurons.py)\n\nPeer selection and management is a critical aspect of the Templar system:\n\n1. **Peer Selection**:\n   - Validators select peers based on OpenSkill ratings\n   - Ratings are calculated from gradient evaluation results\n   - Peer lists are periodically updated to maintain system health\n\n2. **Peer Commitment**:\n   - Nodes commit their bucket information to the blockchain\n   - Commitments include account ID, access keys, and bucket names\n   - Other nodes discover peers by reading these commitments\n\n3. **Peer Update Mechanism**:\n   - New peer lists are generated with a future effective window\n   - Nodes fetch peer lists and update them when appropriate\n   - Inactive peers are pruned and replaced with active ones\n\n## Checkpoint Management\n\n```mermaid\nflowchart TB\n    subgraph \"Checkpoint Creation\"\n        ST[\"Model State\"]\n        OPT[\"Optimizer State\"]\n        SCH[\"Scheduler State\"]\n        MOM[\"Momentum\"]\n        META[\"Metadata\"]\n    end\n\n    subgraph \"Checkpoint Management\"\n        S[\"Save Checkpoint\"]\n        L[\"Load Checkpoint\"]\n        V[\"Version Control\"]\n    end\n\n    subgraph \"Model Synchronization\"\n        CU[\"Catchup Process\"]\n        AG[\"Aggregation Loading\"]\n        SY[\"Sync Verification\"]\n    end\n\n    ST --> S\n    OPT --> S\n    SCH --> S\n    MOM --> S\n    META --> S\n    \n    S --> V\n    V --> L\n    \n    L --> CU\n    AG --> CU\n    CU --> SY\n```\n\nSources:\n- [neurons/miner.py:730-747](neurons/miner.py)\n- [neurons/validator.py:582-620](neurons/validator.py)\n- [src/tplr/neurons.py:199-284](src/tplr/neurons.py)\n\nThe checkpoint management system in Templar ensures model consistency and enables recovery:\n\n1. **Checkpoint Creation**:\n   - Saves model state, optimizer state, scheduler state, and momentum\n   - Includes metadata like current window and version information\n   - Checkpoints are created periodically based on configuration\n\n2. **Checkpoint Loading**:\n   - Loads model state from checkpoints during initialization\n   - Supports version-based checkpoint selection\n   - Handles compatibility between different versions\n\n3. **Model Synchronization**:\n   - Provides a catchup mechanism for nodes that are behind\n   - Loads aggregated gradients to sync with current state\n   - Verifies sync status between nodes\n\n## Configuration Management\n\nThe Templar system uses a centralized hyperparameter configuration system that controls various aspects of the distributed training process.\n\n| Parameter Category | Example Parameters | Description |\n|-------------------|-------------------|-------------|\n| Model Configuration | `hidden_size`, `num_hidden_layers`, `sequence_length` | Controls the structure and size of the language model |\n| Training Parameters | `learning_rate`, `batch_size`, `momentum_decay` | Defines the training process behavior |\n| System Configuration | `blocks_per_window`, `checkpoint_frequency`, `topk_compression` | Controls system-wide behavior and timing |\n| Peer Management | `topk_peers`, `peer_replacement_frequency`, `minimum_peers` | Configures peer selection behavior |\n| Evaluation Metrics | `openskill_beta`, `openskill_tau`, `binary_score_ma_alpha` | Parameters for scoring and rating miners |\n\nSources:\n- [hparams.json:1-53](hparams.json)\n- [neurons/validator.py:87-124](neurons/validator.py)\n- [neurons/miner.py:67-105](neurons/miner.py)\n\n## Error Handling and Recovery\n\nThe Templar system implements several mechanisms for error handling and recovery:\n\n1. **Gradient Gathering Retries**: When gathering gradients fails, nodes retry with exponential backoff\n2. **Catchup Mechanism**: Nodes that are behind can catch up using aggregated gradients\n3. **Peer Replacement**: Inactive or failing peers are automatically replaced\n4. **Checkpoint Recovery**: Nodes can restore from checkpoints after failures\n5. **Connection Error Handling**: R2 storage connections are retried and recreated on failure\n\nThese mechanisms ensure the system's resilience in the face of network issues, node failures, and other adverse conditions.\n\nSources:\n- [src/tplr/comms.py:321-370](src/tplr/comms.py)\n- [src/tplr/neurons.py:199-284](src/tplr/neurons.py)\n- [neurons/validator.py:758-813](neurons/validator.py)\n\n## Summary\n\nThe Templar system architecture provides a robust framework for decentralized training of large language models. Key architectural features include:\n\n1. **Decentralized Node Structure**: Separate roles for miners, validators, and aggregators\n2. **Efficient Gradient Sharing**: DCT-based compression for bandwidth optimization\n3. **Distributed Storage**: Cloudflare R2 for reliable data persistence\n4. **Blockchain Integration**: Bittensor network for coordination and incentives\n5. **Window-Based Processing**: Synchronized training cycles across all nodes\n6. **Checkpoint Management**: Model preservation and recovery mechanisms\n\nThis architecture enables collaborative training across diverse compute resources while maintaining model consistency and providing appropriate incentives for participation.",
    "resolved_links": [
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/aggregator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/aggregator.py",
        "original_deepwiki_href": "neurons/aggregator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "pyproject.toml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/pyproject.toml",
        "original_deepwiki_href": "pyproject.toml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/chain.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/chain.py",
        "original_deepwiki_href": "src/tplr/chain.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/compress.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/compress.py",
        "original_deepwiki_href": "src/tplr/compress.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/neurons.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/neurons.py",
        "original_deepwiki_href": "src/tplr/neurons.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/simulator/loki-test.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/simulator/loki-test.py",
        "original_deepwiki_href": "telemetry/simulator/loki-test.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_comms.py",
        "original_deepwiki_href": "tests/test_comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_model_comparison.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_model_comparison.py",
        "original_deepwiki_href": "tests/test_model_comparison.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "uv.lock",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/uv.lock",
        "original_deepwiki_href": "uv.lock",
        "context": "collapsible_aside_link"
      },
      {
        "text": "Incentive Design",
        "href": "/incentive-design#1.2",
        "original_deepwiki_href": "#1.2",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Network Layer\"\n        BN[\"Bittensor Network\"]\n        MG[\"Metagraph\"]\n    end\n\n    subgraph \"Node Layer\"\n        M[\"Miners\"]\n        V[\"Validators\"]\n        A[\"AggregationServer\"]\n    end\n\n    subgraph \"Storage Layer\"\n        R2[\"Cloudflare R2 Storage\"]\n        subgraph \"Buckets\"\n            GB[\"Gradients Bucket\"]\n            DB[\"Dataset Bucket\"]\n            AB[\"Aggregator Bucket\"]\n            CP[\"Checkpoint Storage\"]\n        end\n    end\n\n    subgraph \"Communication Layer\"\n        CM[\"Comms Module\"]\n        CH[\"Chain Manager\"]\n    end\n\n    M <--> BN\n    V <--> BN\n    BN <--> MG\n\n    M <--> CM\n    V <--> CM\n    A <--> CM\n    \n    CM <--> CH\n    CH <--> BN\n\n    GB <--> CM\n    DB <--> CM\n    AB <--> CM\n    CP <--> CM\n\n    style Network fill:#f9f9f9\n    style Node fill:#f9f9f9\n    style Storage fill:#f9f9f9\n    style Communication fill:#f9f9f9",
      "graph TD\n    subgraph \"Miner\"\n        M_Train[\"Model Training\"]\n        M_Grad[\"Gradient Computation\"]\n        M_Comp[\"Gradient Compression\"]\n        M_Post[\"Gradient Posting\"]\n    end\n\n    subgraph \"Validator\"\n        V_Gath[\"Gradient Gathering\"]\n        V_Eval[\"Gradient Evaluation\"]\n        V_Weight[\"Weight Setting\"]\n        V_Sync[\"Model Synchronization\"]\n    end\n\n    subgraph \"Aggregator\"\n        A_Gath[\"Gradient Collection\"]\n        A_Agg[\"Gradient Aggregation\"]\n        A_Post[\"Aggregation Posting\"]\n    end\n\n    M_Train --> M_Grad --> M_Comp --> M_Post\n    V_Gath --> V_Eval --> V_Weight --> V_Sync\n    A_Gath --> A_Agg --> A_Post\n\n    M_Post -.-> V_Gath\n    M_Post -.-> A_Gath\n    A_Post -.-> V_Sync",
      "flowchart TD\n    subgraph \"Miner Processing\"\n        MT[\"Model Training\"] --> GC[\"Gradient Computation\"]\n        GC --> WD[\"Weight Decay\"]\n        WD --> MM[\"Momentum Update\"]\n        MM --> DCTS[\"DCT Transform\"]\n        DCTS --> COMP[\"Top-K Compression\"]\n        COMP --> UP[\"Upload to R2\"]\n    end\n\n    subgraph \"Validator Processing\"\n        DL[\"Download Gradients\"] --> DECOMP[\"Decompress\"]\n        DECOMP --> EVAL[\"Evaluate Improvement\"]\n        EVAL --> SCORE[\"Calculate Score\"]\n        SCORE --> WT[\"Set Weights\"]\n    end\n\n    subgraph \"Aggregator Processing\"\n        AG_DL[\"Download Gradients\"] --> AG_WT[\"Apply Weights\"]\n        AG_WT --> AG_COMB[\"Combine Gradients\"]\n        AG_COMB --> AG_UP[\"Upload Aggregation\"]\n    end\n\n    UP --> DL\n    UP --> AG_DL\n    AG_UP --> EVAL\n    WT --> AG_WT",
      "flowchart LR\n    subgraph \"DCT Compression Pipeline\"\n        direction LR\n        GRAD[\"Original Gradient\"] --> ENCODE[\"DCT Transform\\nTransformDCT.encode()\"]\n        ENCODE --> COMPRESS[\"Top-K Selection\\nCompressDCT.compress()\"]\n        COMPRESS --> TRANSMIT[\"Transmit\\nidxs + vals\"]\n    end\n\n    subgraph \"DCT Decompression Pipeline\"\n        direction LR\n        RECEIVE[\"Receive\\nidxs + vals\"] --> DECOMPRESS[\"Reconstruction\\nCompressDCT.decompress()\"]\n        DECOMPRESS --> DECODE[\"Inverse DCT\\nTransformDCT.decode()\"]\n        DECODE --> RECONST[\"Reconstructed Gradient\"]\n    end\n\n    TRANSMIT --> RECEIVE",
      "classDiagram\n    class Comms {\n        +wallet: Wallet\n        +bucket: Bucket\n        +session: Session\n        +client_semaphore: Semaphore\n        +put(state_dict, uid, window, key)\n        +get(uid, window, key)\n        +gather(uids, window, key)\n        +load_checkpoint(model, optimizer, scheduler)\n        +save_checkpoint(model, optimizer, scheduler)\n        +post_peer_list(peers, window)\n        +get_peer_list()\n    }\n\n    class ChainManager {\n        +commitments: Dict\n        +peers: PeerArray\n        +eval_peers: Dict\n        +fetch_commitments()\n        +get_commitment(uid)\n        +try_commit(wallet, bucket)\n        +update_peers_with_buckets()\n    }\n\n    class Bucket {\n        +name: str\n        +account_id: str\n        +access_key_id: str\n        +secret_access_key: str\n    }\n\n    Comms --|> ChainManager : inherits\n    Comms --> Bucket : uses",
      "graph TD\n    subgraph \"R2 Storage\"\n        GB[\"Gradients Bucket\"]\n        DB[\"Dataset Bucket\"]\n        AB[\"Aggregator Bucket\"]\n        CP[\"Checkpoint Storage\"]\n    end\n\n    subgraph \"Gradient Files\"\n        GRAD_FILE[\"gradient-{window}-{uid}-v{version}.pt\"]\n    end\n\n    subgraph \"Dataset Files\"\n        DATA_FILE[\"page-{number}.parquet\"]\n    end\n\n    subgraph \"Aggregation Files\"\n        AGG_FILE[\"aggregation-{window}.pt\"]\n    end\n\n    subgraph \"Checkpoint Files\"\n        CKP_FILE[\"checkpoint-{window}-v{version}.pt\"]\n    end\n\n    GB --> GRAD_FILE\n    DB --> DATA_FILE\n    AB --> AGG_FILE\n    CP --> CKP_FILE",
      "flowchart TD\n    subgraph \"Templar System\"\n        M[\"Miners\"]\n        V[\"Validators\"]\n        A[\"Aggregation Server\"]\n    end\n\n    subgraph \"Bittensor Network\"\n        SUB[\"Subtensor\"]\n        MG[\"Metagraph\"]\n        WT[\"Weight Setting\"]\n        STS[\"Stakes\"]\n    end\n\n    M -->|\"Register Hotkeys\"| SUB\n    V -->|\"Register Hotkeys\"| SUB\n    V -->|\"Set Weights\"| WT\n    SUB -->|\"Update\"| MG\n    STS -->|\"Influence\"| MG\n    MG -->|\"Determine Rewards\"| M\n    MG -->|\"Determine Influence\"| V",
      "sequenceDiagram\n    participant M as Miner\n    participant R2 as R2 Storage\n    participant V as Validator\n    participant A as Aggregator\n    participant BT as Bittensor\n\n    Note over M,BT: Window N\n    \n    M->>M: Train model on dataset\n    M->>M: Prepare gradients\n    M->>R2: Upload compressed gradients\n    \n    V->>R2: Gather gradients\n    V->>V: Evaluate gradients\n    V->>BT: Set weights on chain\n    \n    A->>R2: Collect gradients\n    A->>A: Aggregate gradients\n    A->>R2: Store aggregated gradients\n    \n    Note over M,BT: Window N+1\n    \n    M->>R2: Load aggregated gradients\n    M->>M: Update model parameters\n    V->>R2: Load aggregated gradients\n    V->>V: Update model parameters",
      "flowchart TD\n    subgraph \"Validator\"\n        VP[\"Peer Selection\"]\n        VR[\"OpenSkill Ratings\"]\n        VW[\"Weight Setting\"]\n    end\n\n    subgraph \"Peer Management\"\n        PL[\"Peer List Generation\"]\n        PR[\"Peer Repository\"]\n        PC[\"Peer Commitment\"]\n    end\n\n    subgraph \"Nodes\"\n        M[\"Miners\"]\n        V[\"Other Validators\"]\n    end\n\n    VR -->|\"Influence\"| VP\n    VP -->|\"Generate\"| PL\n    PL -->|\"Store\"| PR\n    M -->|\"Register\"| PC\n    V -->|\"Register\"| PC\n    PC -->|\"Inform\"| PR\n    PR -->|\"Provide\"| VP",
      "flowchart TB\n    subgraph \"Checkpoint Creation\"\n        ST[\"Model State\"]\n        OPT[\"Optimizer State\"]\n        SCH[\"Scheduler State\"]\n        MOM[\"Momentum\"]\n        META[\"Metadata\"]\n    end\n\n    subgraph \"Checkpoint Management\"\n        S[\"Save Checkpoint\"]\n        L[\"Load Checkpoint\"]\n        V[\"Version Control\"]\n    end\n\n    subgraph \"Model Synchronization\"\n        CU[\"Catchup Process\"]\n        AG[\"Aggregation Loading\"]\n        SY[\"Sync Verification\"]\n    end\n\n    ST --> S\n    OPT --> S\n    SCH --> S\n    MOM --> S\n    META --> S\n    \n    S --> V\n    V --> L\n    \n    L --> CU\n    AG --> CU\n    CU --> SY"
    ],
    "potential_frontmatter": {
      "title": "System Architecture"
    }
  },
  "/tplr-ai/templar/1.2-incentive-design": {
    "original_deepwiki_href": "/tplr-ai/templar/1.2-incentive-design",
    "title": "Incentive Design",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/1.2-incentive-design",
    "level": 1,
    "target_astro_path": "/incentive-design",
    "main_markdown_content": "# Incentive Design\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [README.md](README.md)\n- [docs/miner.md](docs/miner.md)\n- [docs/validator.md](docs/validator.md)\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n\n</details>\n\n\n\nThis document explains the incentive mechanisms that drive the distributed training process in the Templar framework. It covers how miners are motivated to contribute quality gradients and how validators evaluate and reward these contributions. For information about the overall system architecture, see [System Architecture](#1.1).\n\n## Overview of Incentive Mechanism\n\nTemplar's incentive mechanism aligns the interests of individual miners with the collective goal of improving model performance. The system uses an evaluation-based approach where validators assess the quality of miners' gradient contributions by measuring their impact on model loss.\n\n```mermaid\nflowchart TD\n    subgraph \"Incentive Flow\"\n        M[\"Miners\"] -->|\"Submit Gradients\"| V[\"Validators\"]\n        V -->|\"Evaluate Quality\"| SC[\"Score Calculation\"]\n        SC -->|\"OpenSkill Rating\"| WA[\"Weight Assignment\"]\n        WA -->|\"Set on Blockchain\"| BT[\"Bittensor Network\"]\n        BT -->|\"TAO Rewards\"| M\n    end\n```\n\nSources: [neurons/validator.py:373-437](), [neurons/miner.py:228-329]()\n\nThe incentive flow creates a reinforcement loop: miners producing higher quality gradients receive better scores, leading to higher weights on the blockchain and greater TAO rewards, encouraging continued quality contributions.\n\n## Miner Incentive Structure\n\nMiners are incentivized to generate high-quality gradients through the following mechanisms:\n\n1. **Direct performance evaluation**: Miners' contributions are scored based on their ability to improve model performance\n2. **Window-based training cycles**: Each miner works on assigned data for a specific window\n3. **Gradient sharing system**: Miners benefit from both their contributions and the collective improvement\n\n```mermaid\nflowchart LR\n    subgraph \"Miner Operations\"\n        TD[\"Training Data\"] -->|\"Train Model\"| GC[\"Gradient Computation\"]\n        GC -->|\"Transform & Compress\"| GS[\"Gradient Sharing\"]\n        GS -->|\"R2 Storage Upload\"| VS[\"Validator Scoring\"]\n        VS -->|\"Evaluate Improvement\"| SR[\"Score & Rank\"]\n        SR -->|\"Set Weights\"| RW[\"TAO Rewards\"]\n    end\n```\n\nSources: [neurons/miner.py:228-329](), [neurons/validator.py:486-515]()\n\n### How Miners Maximize Rewards\n\nMiners aim to maximize their rewards by:\n\n1. Computing accurate gradients that lead to model improvement\n2. Maintaining model synchronization with the network\n3. Consistently contributing across training windows\n\nThe optimal strategy for miners is one that genuinely improves the model performance as measured by the validators.\n\n## Validator Evaluation System\n\nValidators employ a sophisticated evaluation system to measure the quality of miners' contributions and assign appropriate weights.\n\n### Loss Improvement Calculation\n\nThe core of the evaluation is measuring how a miner's gradient improves model performance:\n\n1. Compute loss before applying gradient: `L_before`\n2. Apply miner's gradient to model\n3. Compute loss after applying gradient: `L_after`\n4. Calculate improvement score: `s_i = L_before - L_after`\n\n```mermaid\nsequenceDiagram\n    participant M as \"Miner\"\n    participant V as \"Validator\"\n    participant B as \"Blockchain\"\n    \n    M->>V: Submit Compressed Gradient\n    V->>V: Load Assigned Data\n    V->>V: Compute Loss Before (L_before)\n    V->>V: Apply Miner's Gradient\n    V->>V: Compute Loss After (L_after)\n    V->>V: Score = L_before - L_after\n    V->>V: Update OpenSkill Rating\n    V->>V: Calculate Final Weight\n    V->>B: Set Weight on Blockchain\n    B->>M: Distribute TAO Rewards\n```\n\nSources: [neurons/validator.py:486-515](), [neurons/validator.py:356-445]()\n\n### OpenSkill Rating System\n\nValidators use the PlackettLuce model from the OpenSkill library to maintain a probabilistic skill rating for each miner:\n\n```mermaid\nflowchart TD\n    subgraph \"OpenSkill Rating System\"\n        MS[\"Miner Scores\"] -->|\"Collected for Window\"| GC[\"Group & Compare\"]\n        GC -->|\"Update Ratings\"| PL[\"PlackettLuce Model\"]\n        PL -->|\"Update Mu & Sigma\"| MR[\"Miner Ratings\"]\n        MR -->|\"Calculate Ordinal\"| OS[\"Ordinal Score\"]\n        OS -->|\"Multiply with Binary Score\"| FS[\"Final Score\"]\n        BS[\"Binary Moving Average\"] -->|\"Filter Non-negative\"| FS\n        SS[\"Sync Score\"] -->|\"Model Synchronization Quality\"| FS\n    end\n```\n\nSources: [neurons/validator.py:356-437]()\n\nThe OpenSkill system has these key properties:\n\n- **Mu ()**: Represents the estimated skill level of a miner\n- **Sigma ()**: Represents the uncertainty in the skill estimate\n- **Ordinal**: A conservative estimate of skill ( - k) that accounts for uncertainty\n- **Parameters**:\n  - Beta: 20 (controls the dynamics of rating updates)\n  - Tau: 0.1 (dynamic factor that prevents ratings from stagnating)\n\n### Binary Scores and Sync Quality\n\nIn addition to gradient quality, validators track:\n\n1. **Binary Indicator Scores**: Whether miner updates improve or harm the model\n2. **Sync Scores**: How well miners' models stay synchronized with the network\n\nThese factors are combined with the OpenSkill ordinal to produce the final score.\n\n## Weight Normalization and Assignment\n\nValidator weights are calculated using a power normalization approach to ensure a fair distribution:\n\n```mermaid\nflowchart LR\n    subgraph \"Weight Assignment Process\"\n        FS[\"Final Scores\"] -->|\"Filter Positive\"| PS[\"Positive Scores\"]\n        PS -->|\"Power Normalization\"| NW[\"Normalized Weights\"]\n        NW -->|\"Set on Blockchain\"| BW[\"Blockchain Weights\"]\n        BW -->|\"Determine\"| RD[\"Reward Distribution\"]\n    end\n```\n\nSources: [neurons/validator.py:446-488]()\n\nThe weight normalization process:\n\n1. Creates a mask for peers that have been evaluated\n2. Creates a mask for evaluated peers with positive scores\n3. Applies power normalization to only the positive scores\n4. Verifies that weights sum to approximately 1.0\n\nThis approach ensures that:\n- Only positive contributions receive rewards\n- Higher-quality contributions receive proportionally larger rewards\n- The distribution of rewards is balanced across contributors\n\n## Reward Allocation and Penalties\n\n### Reward Allocation\n\nMiners who contribute to model improvement receive weights proportional to their contribution quality. The moving average smooths temporary fluctuations, creating a stable reward mechanism.\n\n### Penalties for Inactivity and Poor Performance\n\nValidators implement several penalty mechanisms:\n\n| Penalty Type | Condition | Reduction Rate |\n|--------------|-----------|----------------|\n| Inactivity | Peer inactive for a window | 25% per window |\n| Missing Gradient | Failed to submit gradient | 75% |\n| Poor Sync | Model out of sync with network | 75% |\n| Long-term Inactivity | Inactive > 25 windows | Complete reset |\n\nSources: [neurons/validator.py:702-770](), [neurons/validator.py:877-912]()\n\n## Security Considerations\n\nThe incentive design addresses several potential security concerns:\n\n1. **Sybil Resistance**: Creating multiple identities offers no advantage as rewards are based on contribution quality, not peer count\n2. **Free-Riding Prevention**: Miners only receive rewards for genuine, measurable contributions\n3. **Nash Equilibrium**: The optimal strategy is honest participation and genuine improvement\n4. **Collusion Resistance**: Evaluation is based on objective model improvement metrics\n\n## Implementation Details\n\n### Key Parameters\n\nThe incentive system is configured with these parameters from hparams.json:\n\n| Parameter | Value | Function |\n|-----------|-------|----------|\n| gradient_score_ma_alpha | 0.6 | Weight for gradient score moving average |\n| binary_score_ma_alpha | 0.05 | Weight for binary indicator score moving average |\n| final_score_ma_alpha | 0.75 | Weight for final score moving average |\n| power_normalisation | 2.0 | Exponent for power normalization of weights |\n| openskill_beta | 20 | Controls dynamics of rating updates |\n| openskill_tau | 0.1 | Prevents ratings from stagnating |\n| reset_inactivity_windows | 25 | Windows before peer score is fully reset |\n\nSources: [hparams.json:14-17](), [hparams.json:40](), [hparams.json:50-51](), [hparams.json:47]()\n\n### Code Implementation\n\nThe core validation and scoring system is implemented in validator.py, with key functions:\n\n```mermaid\nclassDiagram\n    class Validator {\n        evaluate_model_on_batches()\n        update_openskill_ratings()\n        evaluate_miner_sync()\n        update_weights()\n    }\n    \n    class ScoreCalculation {\n        gradient_scores\n        binary_indicator_scores\n        sync_scores\n        final_scores\n        binary_moving_averages\n    }\n    \n    class WeightNormalization {\n        min_power_normalization()\n        positive_mask\n        weights\n    }\n    \n    Validator --> ScoreCalculation\n    ScoreCalculation --> WeightNormalization\n    WeightNormalization --> \"Bittensor Network\"\n```\n\nSources: [neurons/validator.py:356-437](), [neurons/validator.py:446-488](), [neurons/validator.py:489-515]()\n\n## Alignment with Templar's Goals\n\nThe incentive design aligns with Templar's core goals by:\n\n1. **Encouraging Quality**: Rewards are proportional to model improvement\n2. **Promoting Collaboration**: Miners benefit from the collective improvement of the model\n3. **Ensuring Robustness**: Multiple validation metrics create a more reliable evaluation\n4. **Supporting Decentralization**: Independent validators assess contributions fairly\n5. **Enabling Heterogeneity**: Miners with varying hardware can contribute meaningfully\n\nIn summary, Templar's incentive design creates a self-regulating ecosystem where honest participation and genuine model improvement are the most rewarding strategies.\n\nSources: [neurons/validator.py:356-488](), [neurons/miner.py:228-329]()",
    "resolved_links": [
      {
        "text": "README.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/README.md",
        "original_deepwiki_href": "README.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/miner.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/miner.md",
        "original_deepwiki_href": "docs/miner.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/validator.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/validator.md",
        "original_deepwiki_href": "docs/validator.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py:373-437",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:228-329",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:486-515",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:356-445",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:356-437",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:446-488",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:702-770",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:877-912",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:14-17",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:40",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:50-51",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:47",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:489-515",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:356-488",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "System Architecture",
        "href": "/system-architecture#1.1",
        "original_deepwiki_href": "#1.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Incentive Flow\"\n        M[\"Miners\"] -->|\"Submit Gradients\"| V[\"Validators\"]\n        V -->|\"Evaluate Quality\"| SC[\"Score Calculation\"]\n        SC -->|\"OpenSkill Rating\"| WA[\"Weight Assignment\"]\n        WA -->|\"Set on Blockchain\"| BT[\"Bittensor Network\"]\n        BT -->|\"TAO Rewards\"| M\n    end",
      "flowchart LR\n    subgraph \"Miner Operations\"\n        TD[\"Training Data\"] -->|\"Train Model\"| GC[\"Gradient Computation\"]\n        GC -->|\"Transform & Compress\"| GS[\"Gradient Sharing\"]\n        GS -->|\"R2 Storage Upload\"| VS[\"Validator Scoring\"]\n        VS -->|\"Evaluate Improvement\"| SR[\"Score & Rank\"]\n        SR -->|\"Set Weights\"| RW[\"TAO Rewards\"]\n    end",
      "sequenceDiagram\n    participant M as \"Miner\"\n    participant V as \"Validator\"\n    participant B as \"Blockchain\"\n    \n    M->>V: Submit Compressed Gradient\n    V->>V: Load Assigned Data\n    V->>V: Compute Loss Before (L_before)\n    V->>V: Apply Miner's Gradient\n    V->>V: Compute Loss After (L_after)\n    V->>V: Score = L_before - L_after\n    V->>V: Update OpenSkill Rating\n    V->>V: Calculate Final Weight\n    V->>B: Set Weight on Blockchain\n    B->>M: Distribute TAO Rewards",
      "flowchart TD\n    subgraph \"OpenSkill Rating System\"\n        MS[\"Miner Scores\"] -->|\"Collected for Window\"| GC[\"Group & Compare\"]\n        GC -->|\"Update Ratings\"| PL[\"PlackettLuce Model\"]\n        PL -->|\"Update Mu & Sigma\"| MR[\"Miner Ratings\"]\n        MR -->|\"Calculate Ordinal\"| OS[\"Ordinal Score\"]\n        OS -->|\"Multiply with Binary Score\"| FS[\"Final Score\"]\n        BS[\"Binary Moving Average\"] -->|\"Filter Non-negative\"| FS\n        SS[\"Sync Score\"] -->|\"Model Synchronization Quality\"| FS\n    end",
      "flowchart LR\n    subgraph \"Weight Assignment Process\"\n        FS[\"Final Scores\"] -->|\"Filter Positive\"| PS[\"Positive Scores\"]\n        PS -->|\"Power Normalization\"| NW[\"Normalized Weights\"]\n        NW -->|\"Set on Blockchain\"| BW[\"Blockchain Weights\"]\n        BW -->|\"Determine\"| RD[\"Reward Distribution\"]\n    end",
      "classDiagram\n    class Validator {\n        evaluate_model_on_batches()\n        update_openskill_ratings()\n        evaluate_miner_sync()\n        update_weights()\n    }\n    \n    class ScoreCalculation {\n        gradient_scores\n        binary_indicator_scores\n        sync_scores\n        final_scores\n        binary_moving_averages\n    }\n    \n    class WeightNormalization {\n        min_power_normalization()\n        positive_mask\n        weights\n    }\n    \n    Validator --> ScoreCalculation\n    ScoreCalculation --> WeightNormalization\n    WeightNormalization --> \"Bittensor Network\""
    ],
    "potential_frontmatter": {
      "title": "Incentive Design"
    }
  },
  "/tplr-ai/templar/2-miners": {
    "original_deepwiki_href": "/tplr-ai/templar/2-miners",
    "title": "Miners",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/2-miners",
    "level": 0,
    "target_astro_path": "/miners",
    "main_markdown_content": "# Miners\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [README.md](README.md)\n- [docs/miner.md](docs/miner.md)\n- [docs/validator.md](docs/validator.md)\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n\n</details>\n\n\n\nThis document provides a detailed explanation of miners in the Templar decentralized training framework. Miners are computational nodes responsible for training language models on assigned data and sharing their gradients with the network. For information about how validators evaluate miners' contributions, see [Validators](#3).\n\n## Miner Architecture and Positioning\n\nMiners are a core component of Templar's distributed training infrastructure. They work alongside validators and the aggregation server to collaboratively train large language models across distributed nodes.\n\n### Miner Position in Templar Architecture\n\n```mermaid\ngraph TD\n    subgraph \"Bittensor Network\"\n        BT[\"bt.subtensor\"]\n        MG[\"metagraph\"]\n    end\n    \n    subgraph \"Miner Node\"\n        ML[\"LlamaForCausalLM Model\"]\n        OP[\"SGD Optimizer\"]\n        TR[\"TransformDCT\"]\n        CP[\"CompressDCT\"]\n        CO[\"Comms Module\"]\n        SC[\"LR Scheduler\"]\n        WL[\"Wallet\"]\n    end\n    \n    subgraph \"External Components\"\n        R2[\"R2 Storage\"]\n        DS[\"Dataset Loader\"]\n        CK[\"Checkpoints\"]\n        PE[\"Peer Miners\"]\n        VL[\"Validators\"]\n    end\n    \n    BT <--\"Block events\"--> CO\n    WL --\"Authentication\"--> BT\n    ML --\"Forward/Backward pass\"--> OP\n    OP --\"Gradients\"--> TR\n    TR --\"Encoded gradients\"--> CP\n    CP --\"Compressed gradients\"--> CO\n    CO --\"Upload gradients\"--> R2\n    R2 --\"Peer gradients\"--> CO\n    DS --\"Training data\"--> ML\n    CO --\"Load/Save model state\"--> CK\n    SC --\"Update learning rate\"--> OP\n    R2 --\"Evaluate gradients\"--> VL\n    VL --\"Set weights\"--> BT\n    BT --\"Rewards\"--> WL\n```\n\nSources: [neurons/miner.py:65-226]()\n\n## Miner Implementation\n\nThe miner implementation is structured around the `Miner` class, which coordinates training, gradient processing, and communication.\n\n### Key Components\n\n1. **Model**: `LlamaForCausalLM` - The foundational language model being trained\n2. **Optimizer**: `SGD` with momentum for updating model parameters\n3. **Transformers**: `TransformDCT` and `CompressDCT` for gradient compression\n4. **Communications**: `Comms` module for gradient sharing via R2 storage\n5. **Scheduler**: Learning rate scheduler combining warm-up and cosine annealing\n\nSources: [neurons/miner.py:107-226]()\n\n## Miner Lifecycle\n\nThe following sequence diagram illustrates the complete lifecycle of a miner during operation:\n\n```mermaid\nsequenceDiagram\n    participant M as Miner\n    participant R2 as R2 Storage\n    participant P as Peers\n    participant B as Blockchain\n    participant AS as Aggregation Server\n    \n    Note over M: Initialization\n    M->>B: Register with metagraph\n    M->>AS: Get start_window\n    \n    Note over M: Synchronization\n    M->>R2: Load latest checkpoint\n    alt checkpoint found\n        R2->>M: Return model, optimizer, momentum\n    else no checkpoint\n        Note over M: Initialize model from scratch\n    end\n    M->>AS: Catch up with aggregator (if needed)\n    \n    loop For each window\n        B->>M: Block listener detects new window\n        M->>B: Update peers (tplr.neurons.update_peers)\n        M->>R2: Load dataset pages (R2DatasetLoader.next_pages)\n        \n        Note over M: Training\n        loop For each batch\n            Note over M: Forward pass (compute loss)\n            Note over M: Backward pass (compute gradients)\n        end\n        \n        Note over M: Gradient Processing\n        Note over M: Apply momentum update\n        Note over M: Compress gradients with DCT and top-k\n        M->>R2: Upload compressed gradients (comms.put)\n        \n        Note over M: Peer Gradient Exchange\n        M->>R2: Request peer gradients (comms.gather)\n        R2->>M: Return compressed peer gradients\n        \n        Note over M: Model Update\n        Note over M: Decompress peer gradients\n        Note over M: Apply aggregated gradients\n        Note over M: Step optimizer and scheduler\n        \n        alt global_step % checkpoint_frequency == 0\n            M->>R2: Save checkpoint\n        end\n        \n        Note over M: Metrics & Logging\n        M->>WandB: Log metrics\n        M->>InfluxDB: Log system metrics\n    end\n```\n\nSources: [neurons/miner.py:229-755]()\n\n## Training Process\n\nThe miner's primary responsibility is to train the language model on assigned data and share the resulting gradients. Here's how the training process works:\n\n### Dataset Assignment\n\nFor each window, miners receive specific dataset pages:\n\n```python\npages = await tplr.r2_dataset.R2DatasetLoader.next_pages(\n    offset=step_window * self.hparams.pages_per_window,\n    n_pages=self.hparams.pages_per_window,\n    seed=self.uid,  # Each miner gets unique data based on UID\n)\n```\n\nThe data assignment is deterministic - miners with the same UID will always receive the same pages for a given window number.\n\nSources: [neurons/miner.py:339-355]()\n\n### Gradient Computation and Accumulation\n\nMiners process batches of data, compute loss, and accumulate gradients:\n\n```python\nfor i, batch in enumerate(loader):\n    input_ids = torch.tensor(batch, dtype=torch.long).to(self.model.device)\n    tokens_this_batch = input_ids.numel()\n    window_tokens += tokens_this_batch\n    labels = input_ids.clone()\n    labels = torch.where(\n        labels == self.tokenizer.pad_token_id, -100, labels\n    )\n\n    with autocast(device_type=self.model.device.type, dtype=torch.bfloat16):\n        outputs = self.model(input_ids=input_ids, labels=labels)\n\n    total_loss += outputs.loss.item()\n    outputs.loss.backward()\n    n_batches += 1\n```\n\nSources: [neurons/miner.py:360-384]()\n\n## Gradient Processing and Sharing\n\nAfter computing gradients, miners process and share them with the network:\n\n### Gradient Processing Flow\n\n```mermaid\nflowchart TD\n    GR[\"Raw Gradients\"] --> MU[\"momentum = *momentum + *gradient\"]\n    MU --> EN[\"transformer.encode() - DCT Transform\"]\n    EN --> CP[\"compressor.compress() - Top-K Selection\"]\n    CP --> UP[\"comms.put() - Upload to R2\"]\n    UP --> PR[\"comms.gather() - Get Peer Gradients\"]\n    PR --> DC[\"compressor.batch_decompress() - Reconstruct\"]\n    DC --> AG[\"transformer.decode() - Inverse DCT\"]\n    AG --> MO[\"p.grad.copy_(new_grad) - Apply Gradients\"]\n    MO --> SG[\"p.grad.sign_() - Use Only Direction\"]\n    SG --> OP[\"optimizer.step() - Update Model\"]\n    OP --> SC[\"scheduler.step() - Update LR\"]\n```\n\nSources: [neurons/miner.py:399-402](), [neurons/miner.py:560-601]()\n\n### Compression Techniques\n\nMiners use two key techniques to compress gradients efficiently:\n\n1. **DCT Transformation**: Converts gradients to frequency domain using Discrete Cosine Transform\n2. **Top-K Selection**: Only keeps the K most significant coefficients, drastically reducing data size\n\nThis compression is essential for efficient sharing over the internet, allowing miners to exchange gradient information without prohibitive bandwidth requirements.\n\nSources: [neurons/miner.py:131-147]()\n\n## Communication System\n\nThe communication system enables miners to interact with R2 storage, validators, and other miners:\n\n### Gradient Exchange via R2\n\n```python\n# Upload own gradients\nput_completion_time = await self.comms.put(\n    state_dict=processed_state_dict,\n    uid=str(self.uid),\n    window=step_window,\n    key=\"gradient\",\n    global_step=self.global_step,\n    local=False,\n    stale_retention=100,\n)\n\n# Gather gradients from peers\ngather_result = await self.comms.gather(\n    my_uid=self.uid,\n    uids=self.comms.peers,\n    window=step_window,\n    key=\"gradient\",\n    timeout=35,\n    device=\"cpu\",\n    local=False,\n    stale_retention=100,\n    totalks=self.totalks,\n    time_min=time_min,\n    time_max=time_max,\n)\n```\n\nSources: [neurons/miner.py:417-427](), [neurons/miner.py:489-501]()\n\n## Model Synchronization\n\nMiners synchronize their model with the network using checkpoints:\n\n1. **Initial Synchronization**: When starting, miners load the latest checkpoint\n2. **Catch-up Procedure**: If behind, miners catch up with the aggregation server\n3. **Periodic Checkpoints**: Save model state every `checkpoint_frequency` windows\n\n```python\nif self.global_step % self.hparams.checkpoint_frequency == 0:\n    asyncio.create_task(\n        self.comms.save_checkpoint(\n            model=self.model,\n            optimizer=self.optimizer,\n            scheduler=self.scheduler,\n            momentum=self.momentum,\n            global_step=self.global_step,\n            current_window=self.current_window,\n            start_window=self.start_window,\n        )\n    )\n```\n\nSources: [neurons/miner.py:732-747]()\n\n## Configuration Parameters\n\nMiners are configured through both command-line parameters and hyperparameter settings:\n\n### Command-Line Parameters\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `--netuid` | Bittensor network UID | 268 |\n| `--device` | Computing device | \"cuda\" |\n| `--debug` | Enable debug logging | False |\n| `--trace` | Enable trace logging | False |\n| `--test` | Test mode (use all peers) | False |\n| `--local` | Use toy model for local testing | False |\n\nSources: [neurons/miner.py:67-106]()\n\n### Hyperparameters\n\nKey hyperparameters from `hparams.json`:\n\n| Parameter | Value | Description |\n|-----------|-------|-------------|\n| `sequence_length` | 2048 | Maximum sequence length for training |\n| `pages_per_window` | 6 | Number of data pages per window |\n| `batch_size` | 6 | Batch size for training |\n| `learning_rate` | 4e-4 | Initial learning rate |\n| `blocks_per_window` | 7 | Number of blockchain blocks per window |\n| `momentum_decay` | 0.999 | Decay rate for momentum |\n| `topk_compression` | 32 | Top-K value for gradient compression |\n| `target_chunk` | 64 | Chunk size for DCT transform |\n| `checkpoint_frequency` | 100 | Windows between checkpoint saves |\n\nSources: [hparams.json:1-53]()\n\n## Performance Monitoring\n\nMiners track various metrics to monitor performance:\n\n```python\nself.wandb.log(\n    {\n        # Training metrics\n        \"miner/loss\": total_loss / n_batches if n_batches > 0 else 0,\n        \"miner/tokens_per_sec\": tokens_per_sec,\n        \"miner/batch_duration\": duration,\n        \"miner/total_tokens\": self.total_tokens_processed,\n        \"miner/batch_tokens\": window_tokens,\n        \"miner/global_step\": self.global_step,\n        # Resource metrics\n        \"miner/gpu_memory_allocated\": torch.cuda.memory_allocated() / 1024**2,\n        \"miner/gpu_memory_cached\": torch.cuda.memory_reserved() / 1024**2,\n        # Network metrics\n        \"miner/gather_peers\": len(self.comms.peers),\n        \"miner/effective_batch_size\": len(self.comms.peers) * self.hparams.batch_size,\n        # Optimization metrics\n        \"miner/learning_rate\": self.scheduler.get_last_lr()[0],\n        # Gradient statistics\n        \"miner/mean_grad_norm\": sum(grad_norms) / len(grad_norms) if grad_norms else 0,\n        \"miner/max_grad_norm\": max(grad_norms) if grad_norms else 0,\n        \"miner/min_grad_norm\": min(grad_norms) if grad_norms else 0,\n        \"miner/grad_norm_std\": torch.tensor(grad_norms).std().item() if grad_norms else 0,\n        \"miner/mean_weight_norm\": sum(weight_norms) / len(weight_norms),\n        \"miner/mean_momentum_norm\": sum(momentum_norms) / len(momentum_norms),\n    },\n    step=self.global_step,\n)\n```\n\nSources: [neurons/miner.py:518-552]()\n\n## Hardware Requirements\n\nTo run a miner effectively, you need:\n\n- **GPU**: NVIDIA H100 with 80GB VRAM recommended\n- **Storage**: 100GB+ for model and data\n- **Network**: Stable internet connection with good bandwidth\n\nSources: [docs/miner.md:369-373]()\n\n## Integration with Validators\n\nMiners work in tandem with validators, who:\n\n1. Gather and evaluate miners' gradients\n2. Compute scores based on improvement in loss\n3. Set weights on the blockchain\n4. Determine reward distribution\n\nFor more details on validators and the evaluation process, see [Validators](#3) and [Weight Setting](#3.1).\n\nSources: [neurons/validator.py:489-516]()\n\n## Running a Miner\n\nFor detailed setup and running instructions, refer to the documentation in [docs/miner.md](). This includes:\n\n1. Installing dependencies\n2. Setting up R2 bucket credentials\n3. Configuring Bittensor wallet\n4. Running via Docker or directly with Python\n5. Monitoring performance and troubleshooting\n\nSources: [docs/miner.md:32-302]()",
    "resolved_links": [
      {
        "text": "README.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/README.md",
        "original_deepwiki_href": "README.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/miner.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/miner.md",
        "original_deepwiki_href": "docs/miner.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/validator.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/validator.md",
        "original_deepwiki_href": "docs/validator.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py:65-226",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:107-226",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:229-755",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:339-355",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:360-384",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:399-402",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:560-601",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:131-147",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:417-427",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:489-501",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:732-747",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:67-106",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:1-53",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:518-552",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "docs/miner.md:369-373",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:489-516",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "docs/miner.md:32-302",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Validators",
        "href": "/validators#3",
        "original_deepwiki_href": "#3",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Validators",
        "href": "/validators#3",
        "original_deepwiki_href": "#3",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Weight Setting",
        "href": "/validators/weight-setting#3.1",
        "original_deepwiki_href": "#3.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Bittensor Network\"\n        BT[\"bt.subtensor\"]\n        MG[\"metagraph\"]\n    end\n    \n    subgraph \"Miner Node\"\n        ML[\"LlamaForCausalLM Model\"]\n        OP[\"SGD Optimizer\"]\n        TR[\"TransformDCT\"]\n        CP[\"CompressDCT\"]\n        CO[\"Comms Module\"]\n        SC[\"LR Scheduler\"]\n        WL[\"Wallet\"]\n    end\n    \n    subgraph \"External Components\"\n        R2[\"R2 Storage\"]\n        DS[\"Dataset Loader\"]\n        CK[\"Checkpoints\"]\n        PE[\"Peer Miners\"]\n        VL[\"Validators\"]\n    end\n    \n    BT <--\"Block events\"--> CO\n    WL --\"Authentication\"--> BT\n    ML --\"Forward/Backward pass\"--> OP\n    OP --\"Gradients\"--> TR\n    TR --\"Encoded gradients\"--> CP\n    CP --\"Compressed gradients\"--> CO\n    CO --\"Upload gradients\"--> R2\n    R2 --\"Peer gradients\"--> CO\n    DS --\"Training data\"--> ML\n    CO --\"Load/Save model state\"--> CK\n    SC --\"Update learning rate\"--> OP\n    R2 --\"Evaluate gradients\"--> VL\n    VL --\"Set weights\"--> BT\n    BT --\"Rewards\"--> WL",
      "sequenceDiagram\n    participant M as Miner\n    participant R2 as R2 Storage\n    participant P as Peers\n    participant B as Blockchain\n    participant AS as Aggregation Server\n    \n    Note over M: Initialization\n    M->>B: Register with metagraph\n    M->>AS: Get start_window\n    \n    Note over M: Synchronization\n    M->>R2: Load latest checkpoint\n    alt checkpoint found\n        R2->>M: Return model, optimizer, momentum\n    else no checkpoint\n        Note over M: Initialize model from scratch\n    end\n    M->>AS: Catch up with aggregator (if needed)\n    \n    loop For each window\n        B->>M: Block listener detects new window\n        M->>B: Update peers (tplr.neurons.update_peers)\n        M->>R2: Load dataset pages (R2DatasetLoader.next_pages)\n        \n        Note over M: Training\n        loop For each batch\n            Note over M: Forward pass (compute loss)\n            Note over M: Backward pass (compute gradients)\n        end\n        \n        Note over M: Gradient Processing\n        Note over M: Apply momentum update\n        Note over M: Compress gradients with DCT and top-k\n        M->>R2: Upload compressed gradients (comms.put)\n        \n        Note over M: Peer Gradient Exchange\n        M->>R2: Request peer gradients (comms.gather)\n        R2->>M: Return compressed peer gradients\n        \n        Note over M: Model Update\n        Note over M: Decompress peer gradients\n        Note over M: Apply aggregated gradients\n        Note over M: Step optimizer and scheduler\n        \n        alt global_step % checkpoint_frequency == 0\n            M->>R2: Save checkpoint\n        end\n        \n        Note over M: Metrics & Logging\n        M->>WandB: Log metrics\n        M->>InfluxDB: Log system metrics\n    end",
      "flowchart TD\n    GR[\"Raw Gradients\"] --> MU[\"momentum = *momentum + *gradient\"]\n    MU --> EN[\"transformer.encode() - DCT Transform\"]\n    EN --> CP[\"compressor.compress() - Top-K Selection\"]\n    CP --> UP[\"comms.put() - Upload to R2\"]\n    UP --> PR[\"comms.gather() - Get Peer Gradients\"]\n    PR --> DC[\"compressor.batch_decompress() - Reconstruct\"]\n    DC --> AG[\"transformer.decode() - Inverse DCT\"]\n    AG --> MO[\"p.grad.copy_(new_grad) - Apply Gradients\"]\n    MO --> SG[\"p.grad.sign_() - Use Only Direction\"]\n    SG --> OP[\"optimizer.step() - Update Model\"]\n    OP --> SC[\"scheduler.step() - Update LR\"]"
    ],
    "potential_frontmatter": {
      "title": "Miners"
    }
  },
  "/tplr-ai/templar/2.1-gradient-processing": {
    "original_deepwiki_href": "/tplr-ai/templar/2.1-gradient-processing",
    "title": "Gradient Processing",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/2.1-gradient-processing",
    "level": 1,
    "target_astro_path": "/miners/gradient-processing",
    "main_markdown_content": "# Gradient Processing\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/chain.py](src/tplr/chain.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n- [src/tplr/compress.py](src/tplr/compress.py)\n- [src/tplr/neurons.py](src/tplr/neurons.py)\n- [tests/test_model_comparison.py](tests/test_model_comparison.py)\n\n</details>\n\n\n\nThis page explains how miners in the Templar framework process and share gradients, including momentum, weight decay, and the compression techniques used to efficiently distribute updates across the network. For information about how validators evaluate these gradients, see [Weight Setting](#3.1).\n\n## Gradient Processing Pipeline Overview\n\nGradient processing is a critical component of the decentralized training process in Templar. Miners compute gradients during local training, process them through a series of transformations, and then share these compressed representations with validators and other miners via the Cloudflare R2 storage system.\n\n```mermaid\nflowchart TD\n    subgraph \"Miner Gradient Processing\"\n        A[\"Local Training Loop\"] --> B[\"Gradient Computation\"]\n        B --> C[\"Weight Decay Application\"]\n        C --> D[\"Momentum Update\"]\n        D --> E[\"DCT Transform\"]\n        E --> F[\"Top-K Compression\"]\n        F --> G[\"Upload to R2 Storage\"]\n    end\n    \n    subgraph \"Validator Processing\"\n        H[\"Download from R2 Storage\"] --> I[\"Decompress Gradients\"]\n        I --> J[\"Evaluate Improvements\"]\n        J --> K[\"Set Weights on Chain\"]\n    end\n    \n    G --> H\n```\n\nSources: [neurons/miner.py:399-402](). [neurons/validator.py:827-838](). [src/tplr/neurons.py:40-124]().\n\n## Technical Components\n\nThe gradient processing system consists of several key components that work together to optimize, compress, and distribute model updates:\n\n```mermaid\nclassDiagram\n    class TransformDCT {\n        +target_chunk: int\n        +shape_dict: dict\n        +f_dict: dict\n        +b_dict: dict\n        +encode(x): tensor\n        +decode(x): tensor\n    }\n    \n    class CompressDCT {\n        +compress(x, topk): tuple\n        +decompress(p, idx, val, xshape, totalk): tensor\n        +batch_decompress(p, idx, val, xshape, totalk): tensor\n    }\n    \n    class prepare_gradient_dict {\n        <<function>>\n    }\n    \n    prepare_gradient_dict --> TransformDCT: uses\n    prepare_gradient_dict --> CompressDCT: uses\n```\n\nSources: [src/tplr/compress.py:35-178](). [src/tplr/neurons.py:40-124]().\n\n## Momentum and Weight Decay Implementation\n\nDuring training, miners apply weight decay and momentum updates to gradients before compression. This process helps stabilize training and improve convergence.\n\n### Weight Decay\n\nWeight decay helps prevent overfitting by regularizing model parameters. It is applied directly to the parameters before updating the momentum:\n\n```mermaid\nflowchart LR\n    A[\"Parameter p\"] --> B[\"p.data.mul_(1.0 - lr * weight_decay)\"]\n    B --> C[\"Parameter p'\"]\n```\n\n### Momentum Update\n\nMomentum helps accelerate gradients in the relevant direction and dampens oscillations. In Templar, momentum is:\n1. First scaled by a decay factor to reduce the influence of older gradients\n2. Then updated with the current gradient scaled by the learning rate\n3. For the first iteration, momentum is set directly to the gradient to avoid cold starts\n\n```mermaid\nflowchart TD\n    A[\"First Iteration?\"] -- \"Yes\" --> B[\"momentum = grad * lr\"]\n    A -- \"No\" --> C[\"momentum *= momentum_decay\"]\n    C --> D[\"momentum += grad * lr\"]\n    B --> E[\"Proceed to Compression\"]\n    D --> E\n```\n\nSources: [src/tplr/neurons.py:80-97](). [neurons/miner.py:80-97]().\n\n## DCT-Based Gradient Compression\n\nThe Templar system uses Discrete Cosine Transform (DCT) based compression to efficiently share gradients across the network.\n\n### Transformation Process\n\n```mermaid\nflowchart LR\n    subgraph \"Encoding\"\n        A[\"Original Gradient\"] --> B[\"Split into Chunks\"]\n        B --> C[\"Apply DCT Transform\"]\n        C --> D[\"Keep Top-K Values\"]\n        D --> E[\"Compress to (indices, values)\"]\n    end\n    \n    subgraph \"Decoding\"\n        F[\"(indices, values)\"] --> G[\"Reconstruct Sparse Matrix\"]\n        G --> H[\"Apply Inverse DCT\"]\n        H --> I[\"Reassemble Chunks\"]\n        I --> J[\"Reconstructed Gradient\"]\n    end\n    \n    E -- \"Transfer\" --> F\n```\n\nThe `TransformDCT` class handles the encoding and decoding process, while `CompressDCT` manages the selection of top-K components and creates compressed representations.\n\nSources: [src/tplr/compress.py:35-178](). [src/tplr/neurons.py:100-112]().\n\n### Compression Parameters\n\nTwo key hyperparameters control the compression process:\n\n| Parameter | Description | Default Value |\n|-----------|-------------|---------------|\n| `target_chunk` | Size of chunks for DCT transform | 64 |\n| `topk_compression` | Number of DCT coefficients to keep | 32 |\n\nThe combination of these parameters allows for significant compression while preserving essential gradient information.\n\nSources: [hparams.json:12-13](). [neurons/miner.py:132-134]().\n\n## prepare_gradient_dict Function\n\nThe `prepare_gradient_dict` function is the central component that orchestrates the entire gradient processing pipeline:\n\n```mermaid\nflowchart TD\n    A[\"Model Parameters & Gradients\"] --> B[\"Apply Weight Decay\"]\n    B --> C[\"Update Momentum\"]\n    C --> D[\"Transform via DCT\"]\n    D --> E[\"Compress with Top-K Selection\"]\n    E --> F[\"Create Gradient Dictionary\"]\n    F --> G[\"Attach Metadata\"]\n    G --> H[\"Return for Communication\"]\n```\n\nThis function:\n1. Applies weight decay to model parameters\n2. Updates momentum tensors with current gradients\n3. Transforms and compresses using DCT\n4. Creates a dictionary containing compressed gradient data\n5. Attaches metadata like the current window and pages information\n\nSources: [src/tplr/neurons.py:40-124]().\n\n## Implementation Details\n\n### TransformDCT\n\nThe `TransformDCT` class handles the mathematical transformation of gradients using Discrete Cosine Transform. It:\n\n1. Initializes by generating DCT basis matrices for all parameter shapes\n2. Encodes parameters by transforming them into the frequency domain\n3. Decodes parameters by transforming from frequency domain back to spatial domain\n\nThe DCT transformation concentrates most of the signal energy in fewer coefficients, allowing for effective compression by discarding less important components.\n\nSources: [src/tplr/compress.py:35-120]().\n\n### CompressDCT\n\nThe `CompressDCT` class handles the actual compression by:\n\n1. Taking DCT-transformed tensors and selecting the top-K components by magnitude\n2. Storing only the indices and values of these components\n3. Providing methods to reconstruct the original tensor from the compressed representation\n\nSources: [src/tplr/compress.py:123-178]().\n\n## Gradient Data Flow\n\nThe flow of gradient data through the system illustrates how miners and validators interact through gradients:\n\n```mermaid\nsequenceDiagram\n    participant Miner\n    participant R2Storage as \"R2 Gradient Bucket\"\n    participant Validator\n    \n    Miner->>Miner: Train model & compute gradients\n    Miner->>Miner: Apply weight decay\n    Miner->>Miner: Update momentum\n    Miner->>Miner: Compress gradients (DCT + Top-K)\n    Miner->>R2Storage: Upload compressed gradients\n    \n    Validator->>R2Storage: Download compressed gradients\n    Validator->>Validator: Decompress gradients\n    Validator->>Validator: Evaluate model improvements\n    Validator->>Validator: Update miner scores\n```\n\nEach gradient upload contains:\n- Compressed parameter indices and values for each layer\n- Metadata about the current window and training pages\n- Timestamp information for proper synchronization\n\nSources: [neurons/miner.py:415-426](). [neurons/validator.py:827-859]().\n\n## Integration with Communication System\n\nGradients are shared via the Comms system, which handles all data exchange in Templar:\n\n```mermaid\nflowchart TD\n    A[\"Miner\"] --> B[\"prepare_gradient_dict()\"]\n    B --> C[\"Processed Gradient Dict\"]\n    C --> D[\"comms.put()\"]\n    D --> E[\"R2 Storage\"]\n    \n    F[\"Validator\"] --> G[\"comms.gather()\"]\n    G --> E\n    G --> H[\"Gathered Gradients\"]\n    H --> I[\"Evaluate Improvement\"]\n```\n\nThe gradient dictionary follows a structured format with special keys:\n- Parameter names with \"idxs\" suffix containing compressed indices\n- Parameter names with \"vals\" suffix containing compressed values\n- \"metadata\" key with window and page information\n\nSources: [neurons/miner.py:399-426](). [src/tplr/comms.py:324-373]().\n\n## Special Handling During Early Training\n\nThe gradient processing includes special handling for the initial training iterations:\n\n1. In the first iteration, the momentum is set directly to the gradient scaled by the learning rate\n2. For the first 5 iterations, the system skips subtracting transmitted gradients from the momentum \n\nThis approach helps stabilize early training and enables faster initial convergence.\n\nSources: [src/tplr/neurons.py:91-112]().\n\n## Gradient Compression Performance\n\nThe DCT-based compression technique achieves significant reduction in communication overhead:\n\n| Parameter | Raw Size (MB) | Compressed (KB) | Compression Ratio |\n|-----------|---------------|-----------------|-------------------|\n| Large models | 100s-1000s | 10s | ~100x-1000x |\n| Target parameters | Full model | topk per tensor | Proportional to topk value |\n| Retained information | 100% | Significant | Based on frequency spectrum |\n\nThe compression approach prioritizes the most important gradient components by leveraging the sparsity that emerges when transforming to the frequency domain using DCT.\n\nSources: [hparams.json:12-13](). [src/tplr/compress.py:100-112]().\n\n## Model Updates in Miners\n\nAfter receiving and decompressing gradients from other miners, the miner applies these updates to the model:\n\n1. The gathered gradients are decompressed and transformed back to parameter space\n2. The decompressed gradients are assigned to the `.grad` attribute of model parameters\n3. The optimizer's `step()` method is called to apply the updates using the configured learning rate\n4. The scheduler updates the learning rate for the next iteration\n\nSources: [neurons/miner.py:559-600]().",
    "resolved_links": [
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/chain.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/chain.py",
        "original_deepwiki_href": "src/tplr/chain.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/compress.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/compress.py",
        "original_deepwiki_href": "src/tplr/compress.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/neurons.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/neurons.py",
        "original_deepwiki_href": "src/tplr/neurons.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_model_comparison.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_model_comparison.py",
        "original_deepwiki_href": "tests/test_model_comparison.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py:399-402",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:827-838",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:40-124",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/compress.py:35-178",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:80-97",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:80-97",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:100-112",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:12-13",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:132-134",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/compress.py:35-120",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/compress.py:123-178",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:415-426",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:827-859",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:399-426",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:324-373",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:91-112",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/compress.py:100-112",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:559-600",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Weight Setting",
        "href": "/validators/weight-setting#3.1",
        "original_deepwiki_href": "#3.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Miner Gradient Processing\"\n        A[\"Local Training Loop\"] --> B[\"Gradient Computation\"]\n        B --> C[\"Weight Decay Application\"]\n        C --> D[\"Momentum Update\"]\n        D --> E[\"DCT Transform\"]\n        E --> F[\"Top-K Compression\"]\n        F --> G[\"Upload to R2 Storage\"]\n    end\n    \n    subgraph \"Validator Processing\"\n        H[\"Download from R2 Storage\"] --> I[\"Decompress Gradients\"]\n        I --> J[\"Evaluate Improvements\"]\n        J --> K[\"Set Weights on Chain\"]\n    end\n    \n    G --> H",
      "classDiagram\n    class TransformDCT {\n        +target_chunk: int\n        +shape_dict: dict\n        +f_dict: dict\n        +b_dict: dict\n        +encode(x): tensor\n        +decode(x): tensor\n    }\n    \n    class CompressDCT {\n        +compress(x, topk): tuple\n        +decompress(p, idx, val, xshape, totalk): tensor\n        +batch_decompress(p, idx, val, xshape, totalk): tensor\n    }\n    \n    class prepare_gradient_dict {\n        <<function>>\n    }\n    \n    prepare_gradient_dict --> TransformDCT: uses\n    prepare_gradient_dict --> CompressDCT: uses",
      "flowchart LR\n    A[\"Parameter p\"] --> B[\"p.data.mul_(1.0 - lr * weight_decay)\"]\n    B --> C[\"Parameter p'\"]",
      "flowchart TD\n    A[\"First Iteration?\"] -- \"Yes\" --> B[\"momentum = grad * lr\"]\n    A -- \"No\" --> C[\"momentum *= momentum_decay\"]\n    C --> D[\"momentum += grad * lr\"]\n    B --> E[\"Proceed to Compression\"]\n    D --> E",
      "flowchart LR\n    subgraph \"Encoding\"\n        A[\"Original Gradient\"] --> B[\"Split into Chunks\"]\n        B --> C[\"Apply DCT Transform\"]\n        C --> D[\"Keep Top-K Values\"]\n        D --> E[\"Compress to (indices, values)\"]\n    end\n    \n    subgraph \"Decoding\"\n        F[\"(indices, values)\"] --> G[\"Reconstruct Sparse Matrix\"]\n        G --> H[\"Apply Inverse DCT\"]\n        H --> I[\"Reassemble Chunks\"]\n        I --> J[\"Reconstructed Gradient\"]\n    end\n    \n    E -- \"Transfer\" --> F",
      "flowchart TD\n    A[\"Model Parameters & Gradients\"] --> B[\"Apply Weight Decay\"]\n    B --> C[\"Update Momentum\"]\n    C --> D[\"Transform via DCT\"]\n    D --> E[\"Compress with Top-K Selection\"]\n    E --> F[\"Create Gradient Dictionary\"]\n    F --> G[\"Attach Metadata\"]\n    G --> H[\"Return for Communication\"]",
      "sequenceDiagram\n    participant Miner\n    participant R2Storage as \"R2 Gradient Bucket\"\n    participant Validator\n    \n    Miner->>Miner: Train model & compute gradients\n    Miner->>Miner: Apply weight decay\n    Miner->>Miner: Update momentum\n    Miner->>Miner: Compress gradients (DCT + Top-K)\n    Miner->>R2Storage: Upload compressed gradients\n    \n    Validator->>R2Storage: Download compressed gradients\n    Validator->>Validator: Decompress gradients\n    Validator->>Validator: Evaluate model improvements\n    Validator->>Validator: Update miner scores",
      "flowchart TD\n    A[\"Miner\"] --> B[\"prepare_gradient_dict()\"]\n    B --> C[\"Processed Gradient Dict\"]\n    C --> D[\"comms.put()\"]\n    D --> E[\"R2 Storage\"]\n    \n    F[\"Validator\"] --> G[\"comms.gather()\"]\n    G --> E\n    G --> H[\"Gathered Gradients\"]\n    H --> I[\"Evaluate Improvement\"]"
    ],
    "potential_frontmatter": {
      "title": "Gradient Processing"
    }
  },
  "/tplr-ai/templar/3-validators": {
    "original_deepwiki_href": "/tplr-ai/templar/3-validators",
    "title": "Validators",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/3-validators",
    "level": 0,
    "target_astro_path": "/validators",
    "main_markdown_content": "# Validators\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [README.md](README.md)\n- [docs/miner.md](docs/miner.md)\n- [docs/validator.md](docs/validator.md)\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n- [tests/test_checkpoints.py](tests/test_checkpoints.py)\n- [tests/test_evaluator.py](tests/test_evaluator.py)\n- [tests/test_prepare_gradient_dict.py](tests/test_prepare_gradient_dict.py)\n\n</details>\n\n\n\nValidators are a critical component of the Templar decentralized training framework. They are responsible for evaluating miners' gradient contributions, assessing their quality, and setting weights on the Bittensor blockchain to determine reward distribution. This page details the architecture, functionality, and operation of validators within the Templar system.\n\nFor information about the miners that validators evaluate, see [Miners](#2). For details on how validators set weights on the blockchain, see [Weight Setting](#3.1).\n\n## Validator Architecture\n\nValidators maintain model state, evaluate gradients from miners, and update weights on the Bittensor blockchain. The architectural design enables efficient evaluation of multiple miners while maintaining system integrity.\n\n```mermaid\ngraph TD\n    subgraph \"Validator Core Components\"\n        VM[\"Model (LlamaForCausalLM)\"]\n        VO[\"Optimizer (SGD)\"]\n        VS[\"Scheduler\"]\n        VT[\"Momentum Tracker\"]\n        VR[\"OpenSkill Rating System\"]\n    end\n\n    subgraph \"Evaluation System\"\n        GE[\"Gradient Evaluation\"]\n        SS[\"Sync Score Calculation\"]\n        BS[\"Binary Score Tracking\"]\n        FS[\"Final Score Calculation\"]\n        WN[\"Weight Normalization\"]\n    end\n\n    subgraph \"Communication\"\n        CM[\"Comms Module\"]\n        CG[\"Gradient Gathering\"]\n        CB[\"Blockchain Integration\"]\n        CP[\"Checkpoint Management\"]\n    end\n\n    VM --> GE\n    VO --> GE\n    VS --> GE\n    VT --> GE\n    GE --> VR\n    \n    CG --> GE\n    SS --> FS\n    BS --> FS\n    VR --> FS\n    FS --> WN\n    WN --> CB\n\n    CM <--> CG\n    CM <--> CB\n    CM <--> CP\n```\n\nSources: [neurons/validator.py:85-267](), [neurons/validator.py:355-480]()\n\n## Validator Initialization\n\nValidators initialize with a model identical to miners, along with compression systems for efficient gradient processing, and integration with the Bittensor network.\n\n```mermaid\nsequenceDiagram\n    participant V as \"Validator\"\n    participant BT as \"Bittensor Network\"\n    participant R2 as \"R2 Storage\"\n    participant M as \"Model & Components\"\n    \n    V->>BT: Initialize wallet and subtensor\n    V->>BT: Get metagraph and UID\n    V->>M: Initialize LLaMA model\n    V->>M: Setup DCT compression\n    V->>M: Initialize optimizer & scheduler\n    V->>M: Setup momentum tracking\n    V->>V: Initialize OpenSkill ratings\n    V->>R2: Setup communication module\n    V->>R2: Create & commit to buckets\n    V->>V: Initialize scoring system\n    V->>BT: Verify registration\n```\n\nThe Validator class is initialized with several key components:\n\n1. **Bittensor Network Integration**: Wallet, subtensor, and metagraph objects for blockchain interaction\n2. **Model**: LlamaForCausalLM instance identical to what miners use\n3. **Compression**: DCT transformation and compression for efficient gradient handling\n4. **Optimizer and Momentum**: SGD optimizer and momentum tracking for gradient evaluation\n5. **Rating System**: OpenSkill-based rating system for evaluating miner contributions\n6. **Storage Integration**: R2 bucket communication for gradient exchange\n\nSources: [neurons/validator.py:126-267]()\n\n## Validation Workflow\n\nThe validator's main operation revolves around evaluating miner gradients by checking how they affect model performance.\n\n```mermaid\nflowchart TD\n    subgraph \"Validator Operation Cycle\"\n        direction TB\n        A[\"Sync Window Start\"] --> B[\"Update Peers\"]\n        B --> C[\"Gather Gradients\"]\n        C --> D[\"Evaluate Miner Sync\"]\n        D --> E[\"Evaluate Gradients\"]\n        E --> F[\"Update Ratings\"]\n        F --> G[\"Calculate Scores\"]\n        G --> H[\"Set Weights on Chain\"]\n        H --> I[\"Next Window\"]\n        I --> A\n    end\n\n    subgraph \"Gradient Evaluation\"\n        direction TB\n        E1[\"Select Miner\"] --> E2[\"Get Dataset Pages\"]\n        E2 --> E3[\"Measure Loss Before\"]\n        E3 --> E4[\"Apply Miner Gradient\"]\n        E4 --> E5[\"Measure Loss After\"]\n        E5 --> E6[\"Calculate Improvement\"]\n        E6 --> E7[\"Store Evaluation Result\"]\n    end\n\n    subgraph \"Weight Setting\"\n        direction TB\n        G1[\"Binary Score Update\"] --> G2[\"Sync Score Update\"]\n        G2 --> G3[\"Apply OpenSkill Ratings\"]\n        G3 --> G4[\"Apply Power Normalization\"]\n        G4 --> G5[\"Finalize Weights\"]\n    end\n\n    E --> E1\n    G --> G1\n```\n\nSources: [neurons/validator.py:516-635](). [neurons/validator.py:695-787](), [neurons/validator.py:374-445]()\n\n## Gradient Evaluation Process\n\nValidators assess miners by measuring the improvement in model performance after applying their gradients:\n\n1. **Gather Miner Gradients**: Validators collect compressed gradients from miners for the current window\n2. **Decompress Gradients**: Transform the compressed gradients back to usable form\n3. **Evaluate Improvement**: Apply the gradients to the model and measure improvement in loss\n4. **Calculate Scores**: Determine quality scores based on the measured improvement\n5. **Update Ratings**: Update miner ratings using the OpenSkill system\n\n```mermaid\ngraph TD\n    subgraph \"Gradient Evaluation Flow\"\n        Begin[\"Start Evaluation\"] --> GatherGrad[\"Gather Miner Gradients\"]\n        GatherGrad --> Decompress[\"Decompress Gradients\"]\n        Decompress --> EvalBeforeLoss[\"Evaluate Loss Before\"]\n        EvalBeforeLoss --> ApplyGrad[\"Apply Gradients to Model\"]\n        ApplyGrad --> EvalAfterLoss[\"Evaluate Loss After\"]\n        EvalAfterLoss --> CalcImprovement[\"Calculate Improvement\\nLossBefore - LossAfter\"]\n        CalcImprovement --> UpdateScore[\"Update Miner Score\"]\n        UpdateScore --> OpenSkill[\"Update OpenSkill Rating\"]\n        OpenSkill --> SyncEval[\"Evaluate Model Sync\"]\n        SyncEval --> FinalScore[\"Calculate Final Score\"]\n    end\n```\n\nKey components of the evaluation process:\n\n- **Loss Calculation**: `evaluate_model_on_batches()` calculates loss on the same dataset used by the miner\n- **Improvement Metric**: Improvement is measured as the difference between loss before and after applying gradients\n- **Batch Sampling**: Validators sample a subset of batches to efficiently evaluate performance\n- **OpenSkill Rating**: The PlackettLuce model updates ratings based on relative performance\n\nSources: [neurons/validator.py:489-514](), [neurons/validator.py:374-445]()\n\n## Scoring Mechanisms\n\nValidators use multiple scoring components to evaluate miners:\n\n### OpenSkill Rating System\n\nThe OpenSkill rating system provides a probabilistic skill rating that accounts for uncertainty and relative performance between peers:\n\n```python\n# Each miner has an OpenSkill rating maintained by validators\nopenskill_mu = float(self.openskill_ratings[uid].mu)         # Mean skill\nopenskill_sigma = float(self.openskill_ratings[uid].sigma)   # Uncertainty\nopenskill_ordinal = float(self.openskill_ratings[uid].ordinal()) # Combined score\n```\n\nValidators update these ratings based on gradient evaluation results, using the PlackettLuce model where higher gradient scores indicate better performance.\n\n### Score Components\n\nMultiple scoring components are combined for the final weight calculation:\n\n1. **Gradient Scores**: Direct measurement of loss improvement\n2. **Binary Indicator Scores**: Tracks whether contributions are consistently positive\n3. **Sync Scores**: Measures how well miners stay synchronized with the global model\n4. **Final Scores**: Combination of all metrics that determines weights\n\n```mermaid\ngraph TD\n    subgraph \"Score Calculation System\"\n        GS[\"Gradient Score\\nLoss Improvement Measurement\"] --> BMA[\"Binary Moving Average\\nPositive Contribution Tracking\"]\n        SYS[\"Sync Score\\nModel Synchronization Quality\"] --> FS[\"Final Score Calculation\"]\n        BMA --> FS\n        OSR[\"OpenSkill Rating\\nRelative Performance\"] --> FS\n        FS --> WN[\"Weight Normalization\\nPower Normalization\"]\n        WN --> SW[\"Set Weights on Blockchain\"]\n    end\n```\n\nThe final score calculation combines:\n\n```python\n# Final score formula\nself.final_scores[uid] = (\n    openskill_ordinal * \n    max(0, self.binary_moving_averages[uid].item()) * \n    sync_score\n)\n```\n\nSources: [neurons/validator.py:374-445](), [neurons/validator.py:356-380]()\n\n## Handling Inactivity and Penalties\n\nValidators manage peer inactivity through a sophisticated penalty system:\n\n```mermaid\nflowchart TD\n    subgraph \"Inactivity Management\"\n        CheckActivity[\"Check Miner Activity\"] --> IsActive{\"Is Miner Active?\"}\n        IsActive -->|Yes| RemoveFromInactive[\"Remove from Inactive List\"]\n        IsActive -->|No| TrackInactive[\"Track Inactivity Period\"]\n        \n        TrackInactive --> LongInactive{\"Inactive > Reset\\nThreshold?\"}\n        LongInactive -->|Yes| ResetPeer[\"Reset Peer\\nZero All Scores\"]\n        LongInactive -->|No| ApplyPenalty[\"Apply Inactivity Penalty\\n25% Score Reduction\"]\n        \n        subgraph \"Additional Penalties\"\n            MG[\"Missing Gradient\\n75% Score Reduction\"]\n            SS[\"Sync Score Violation\\n75% Score Reduction\"]\n        end\n    end\n```\n\nKey inactivity handling mechanisms:\n\n1. **Tracking System**: Validators track when miners become inactive\n2. **Graduated Penalties**: Scores are reduced by 25% per window of inactivity\n3. **Complete Reset**: After extended inactivity (25 windows), scores are completely reset\n4. **Additional Penalties**: \n   - Missing gradients during gather: 75% score reduction\n   - Poor model synchronization: 75% score reduction\n\nSources: [neurons/validator.py:302-315](), [neurons/validator.py:706-733]()\n\n## Checkpoint Management\n\nValidators are responsible for managing checkpoints that maintain the global model state:\n\n```mermaid\ngraph TD\n    subgraph \"Checkpoint Management\"\n        SL[\"Save Logic\"] --> FC[\"Frequency Check\\nEvery checkpoint_frequency Windows\"]\n        FC -->|\"Yes\"| SC[\"Save Checkpoint\"]\n        FC -->|\"No\"| Skip[\"Skip Saving\"]\n        \n        LL[\"Load Logic\"] --> FE[\"Find Existing Checkpoint\"]\n        FE --> LoadCP[\"Load Checkpoint\"]\n        LoadCP --> SyncCheck[\"Check If Behind Current Window\"]\n        SyncCheck -->|\"Yes\"| Catchup[\"Catch Up with Aggregation Server\"]\n        SyncCheck -->|\"No\"| Continue[\"Continue Normal Operation\"]\n    end\n```\n\nThe checkpoint system ensures:\n\n1. **State Persistence**: Model parameters, optimizer state, and momentum are preserved\n2. **Consistent Startup**: Validators can recover from the last saved state\n3. **Synchronization**: Validators that fall behind can catch up to the current window\n4. **Global Consistency**: All validators operate on a consistent model state\n\nSources: [neurons/validator.py:576-623]()\n\n## Peer Management and Evaluation\n\nValidators strategically manage which miners to evaluate and interact with:\n\n```mermaid\nflowchart TD\n    subgraph \"Peer Management System\"\n        IP[\"Initial Peer Selection\"] --> RPS[\"Regular Peer Selection\"]\n        RPS --> PP[\"Post Peer List\"]\n        PP --> EP[\"Evaluate Peers\"]\n        \n        subgraph \"Selection Strategy\"\n            TS[\"Topk Selection\\nHighest-weighted peers\"]\n            RS[\"Random Selection\\nExploration\"]\n            PS[\"Prioritized Sampling\\nFair evaluation\"]\n        end\n    end\n```\n\nValidators employ strategies to:\n\n1. **Balance Exploration and Exploitation**: Sample both high-performing and untested miners\n2. **Ensure Fair Evaluation**: Distribute evaluation opportunities evenly\n3. **Maintain Network Health**: Regularly replace peers to prevent network stagnation\n4. **Post Peer Lists**: Share selected peers with the network via R2 storage\n\nSources: [neurons/validator.py:642-704]()\n\n## Communication System\n\nThe validator's communication system handles interaction with the blockchain, storage systems, and other network components:\n\n```mermaid\nflowchart TD\n    subgraph \"Validator Communication\"\n        CM[\"Comms Module\"] --> R2[\"R2 Storage Integration\"]\n        CM --> BT[\"Bittensor Blockchain\"]\n        CM --> AS[\"Aggregation Server\"]\n        \n        R2 --> GradientsB[\"Gradients Bucket\"]\n        R2 --> CheckpointsB[\"Checkpoints Bucket\"]\n        R2 --> PeersB[\"Peer Lists Storage\"]\n        \n        GradientsB --> GG[\"Gradient Gathering\"]\n        CheckpointsB --> CPM[\"Checkpoint Management\"]\n        PeersB --> PLM[\"Peer List Management\"]\n        \n        BT --> WS[\"Weight Setting\"]\n        BT --> MM[\"Metagraph Monitoring\"]\n    end\n```\n\nKey communication functions include:\n\n1. **Gradient Exchange**: Gathering miner gradients from R2 storage\n2. **Checkpoint Management**: Loading and saving model checkpoints\n3. **Peer List Posting**: Sharing selected peers for evaluation\n4. **Blockchain Integration**: Setting weights and monitoring network state\n5. **Aggregation Server Integration**: Synchronizing with global model state\n\nSources: [neurons/validator.py:831-860](), [src/tplr/comms.py:64-682]()\n\n## Environment Requirements\n\nValidators have specific hardware and software requirements:\n\n| Component | Requirement | Notes |\n|-----------|-------------|-------|\n| GPU       | NVIDIA H100 (recommended) | Minimum 80GB VRAM |\n| Storage   | 200GB+ SSD  | For model and evaluation data |\n| RAM       | 32GB+       | For efficient processing |\n| Network   | High bandwidth | For state synchronization |\n| Software  | PyTorch, Bittensor | With CUDA support |\n\nAdditionally, validators require Cloudflare R2 bucket configuration for gradient exchange and checkpoint management.\n\nSources: [docs/validator.md:306-313]()\n\n## Configuration and Setup\n\nValidators are configured via command-line arguments and environment variables:\n\n```python\n# Key configuration options\nparser.add_argument(\"--netuid\", type=int, default=268, help=\"Bittensor network UID.\")\nparser.add_argument(\"--device\", type=str, default=\"cuda\", help=\"Device for training\")\nparser.add_argument(\"--store-gathers\", action=\"store_true\", help=\"Store gathered gradients\")\nparser.add_argument(\"--test\", action=\"store_true\", help=\"Test mode - use all peers\")\nparser.add_argument(\"--local\", action=\"store_true\", help=\"Local run with toy model\")\n```\n\nEnvironment variables control R2 storage credentials, network configuration, and monitoring settings.\n\nThe Validator can also be deployed using Docker Compose for easier management.\n\nSources: [neurons/validator.py:86-124](), [docs/validator.md:116-150]()\n\n## Related Systems\n\nThe validator integrates with several other Templar systems:\n\n1. **Miners**: The nodes that validators evaluate ([Miners](#2))\n2. **Aggregation Server**: Provides synchronized model state ([Aggregation Server](#4))\n3. **Bittensor Network**: Blockchain for weight setting ([Chain Integration](#6.2))\n4. **R2 Storage**: Communication medium for gradient exchange ([R2 Storage](#7.1))\n5. **Monitoring**: Performance tracking via WandB and InfluxDB ([Monitoring and Telemetry](#9))\n\n## Conclusion\n\nValidators are a cornerstone of the Templar framework, providing the critical evaluation mechanism that drives the incentive system. By accurately assessing miner contributions, validators ensure that high-quality gradients are rewarded, maintaining the integrity and performance of the collectively trained model.\n\nThe validator's sophisticated scoring and rating systems, combined with efficient communication and checkpoint management, create a robust framework for decentralized model training that aligns individual incentives with collective performance goals.",
    "resolved_links": [
      {
        "text": "README.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/README.md",
        "original_deepwiki_href": "README.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/miner.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/miner.md",
        "original_deepwiki_href": "docs/miner.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/validator.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/validator.md",
        "original_deepwiki_href": "docs/validator.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_checkpoints.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_checkpoints.py",
        "original_deepwiki_href": "tests/test_checkpoints.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_evaluator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_evaluator.py",
        "original_deepwiki_href": "tests/test_evaluator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_prepare_gradient_dict.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_prepare_gradient_dict.py",
        "original_deepwiki_href": "tests/test_prepare_gradient_dict.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py:85-267",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:355-480",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:126-267",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:516-635",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:695-787",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:374-445",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:489-514",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:356-380",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:302-315",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:706-733",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:576-623",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:642-704",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:831-860",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:64-682",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "docs/validator.md:306-313",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:86-124",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "docs/validator.md:116-150",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Miners",
        "href": "/miners#2",
        "original_deepwiki_href": "#2",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Weight Setting",
        "href": "/validators/weight-setting#3.1",
        "original_deepwiki_href": "#3.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Miners",
        "href": "/miners#2",
        "original_deepwiki_href": "#2",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Aggregation Server",
        "href": "/aggregation-server#4",
        "original_deepwiki_href": "#4",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Chain Integration",
        "href": "/communication-system/chain-integration#6.2",
        "original_deepwiki_href": "#6.2",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "R2 Storage",
        "href": "/data-management/r2-storage#7.1",
        "original_deepwiki_href": "#7.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Monitoring and Telemetry",
        "href": "/monitoring-and-telemetry#9",
        "original_deepwiki_href": "#9",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Validator Core Components\"\n        VM[\"Model (LlamaForCausalLM)\"]\n        VO[\"Optimizer (SGD)\"]\n        VS[\"Scheduler\"]\n        VT[\"Momentum Tracker\"]\n        VR[\"OpenSkill Rating System\"]\n    end\n\n    subgraph \"Evaluation System\"\n        GE[\"Gradient Evaluation\"]\n        SS[\"Sync Score Calculation\"]\n        BS[\"Binary Score Tracking\"]\n        FS[\"Final Score Calculation\"]\n        WN[\"Weight Normalization\"]\n    end\n\n    subgraph \"Communication\"\n        CM[\"Comms Module\"]\n        CG[\"Gradient Gathering\"]\n        CB[\"Blockchain Integration\"]\n        CP[\"Checkpoint Management\"]\n    end\n\n    VM --> GE\n    VO --> GE\n    VS --> GE\n    VT --> GE\n    GE --> VR\n    \n    CG --> GE\n    SS --> FS\n    BS --> FS\n    VR --> FS\n    FS --> WN\n    WN --> CB\n\n    CM <--> CG\n    CM <--> CB\n    CM <--> CP",
      "sequenceDiagram\n    participant V as \"Validator\"\n    participant BT as \"Bittensor Network\"\n    participant R2 as \"R2 Storage\"\n    participant M as \"Model & Components\"\n    \n    V->>BT: Initialize wallet and subtensor\n    V->>BT: Get metagraph and UID\n    V->>M: Initialize LLaMA model\n    V->>M: Setup DCT compression\n    V->>M: Initialize optimizer & scheduler\n    V->>M: Setup momentum tracking\n    V->>V: Initialize OpenSkill ratings\n    V->>R2: Setup communication module\n    V->>R2: Create & commit to buckets\n    V->>V: Initialize scoring system\n    V->>BT: Verify registration",
      "flowchart TD\n    subgraph \"Validator Operation Cycle\"\n        direction TB\n        A[\"Sync Window Start\"] --> B[\"Update Peers\"]\n        B --> C[\"Gather Gradients\"]\n        C --> D[\"Evaluate Miner Sync\"]\n        D --> E[\"Evaluate Gradients\"]\n        E --> F[\"Update Ratings\"]\n        F --> G[\"Calculate Scores\"]\n        G --> H[\"Set Weights on Chain\"]\n        H --> I[\"Next Window\"]\n        I --> A\n    end\n\n    subgraph \"Gradient Evaluation\"\n        direction TB\n        E1[\"Select Miner\"] --> E2[\"Get Dataset Pages\"]\n        E2 --> E3[\"Measure Loss Before\"]\n        E3 --> E4[\"Apply Miner Gradient\"]\n        E4 --> E5[\"Measure Loss After\"]\n        E5 --> E6[\"Calculate Improvement\"]\n        E6 --> E7[\"Store Evaluation Result\"]\n    end\n\n    subgraph \"Weight Setting\"\n        direction TB\n        G1[\"Binary Score Update\"] --> G2[\"Sync Score Update\"]\n        G2 --> G3[\"Apply OpenSkill Ratings\"]\n        G3 --> G4[\"Apply Power Normalization\"]\n        G4 --> G5[\"Finalize Weights\"]\n    end\n\n    E --> E1\n    G --> G1",
      "graph TD\n    subgraph \"Gradient Evaluation Flow\"\n        Begin[\"Start Evaluation\"] --> GatherGrad[\"Gather Miner Gradients\"]\n        GatherGrad --> Decompress[\"Decompress Gradients\"]\n        Decompress --> EvalBeforeLoss[\"Evaluate Loss Before\"]\n        EvalBeforeLoss --> ApplyGrad[\"Apply Gradients to Model\"]\n        ApplyGrad --> EvalAfterLoss[\"Evaluate Loss After\"]\n        EvalAfterLoss --> CalcImprovement[\"Calculate Improvement\\nLossBefore - LossAfter\"]\n        CalcImprovement --> UpdateScore[\"Update Miner Score\"]\n        UpdateScore --> OpenSkill[\"Update OpenSkill Rating\"]\n        OpenSkill --> SyncEval[\"Evaluate Model Sync\"]\n        SyncEval --> FinalScore[\"Calculate Final Score\"]\n    end",
      "graph TD\n    subgraph \"Score Calculation System\"\n        GS[\"Gradient Score\\nLoss Improvement Measurement\"] --> BMA[\"Binary Moving Average\\nPositive Contribution Tracking\"]\n        SYS[\"Sync Score\\nModel Synchronization Quality\"] --> FS[\"Final Score Calculation\"]\n        BMA --> FS\n        OSR[\"OpenSkill Rating\\nRelative Performance\"] --> FS\n        FS --> WN[\"Weight Normalization\\nPower Normalization\"]\n        WN --> SW[\"Set Weights on Blockchain\"]\n    end",
      "flowchart TD\n    subgraph \"Inactivity Management\"\n        CheckActivity[\"Check Miner Activity\"] --> IsActive{\"Is Miner Active?\"}\n        IsActive -->|Yes| RemoveFromInactive[\"Remove from Inactive List\"]\n        IsActive -->|No| TrackInactive[\"Track Inactivity Period\"]\n        \n        TrackInactive --> LongInactive{\"Inactive > Reset\\nThreshold?\"}\n        LongInactive -->|Yes| ResetPeer[\"Reset Peer\\nZero All Scores\"]\n        LongInactive -->|No| ApplyPenalty[\"Apply Inactivity Penalty\\n25% Score Reduction\"]\n        \n        subgraph \"Additional Penalties\"\n            MG[\"Missing Gradient\\n75% Score Reduction\"]\n            SS[\"Sync Score Violation\\n75% Score Reduction\"]\n        end\n    end",
      "graph TD\n    subgraph \"Checkpoint Management\"\n        SL[\"Save Logic\"] --> FC[\"Frequency Check\\nEvery checkpoint_frequency Windows\"]\n        FC -->|\"Yes\"| SC[\"Save Checkpoint\"]\n        FC -->|\"No\"| Skip[\"Skip Saving\"]\n        \n        LL[\"Load Logic\"] --> FE[\"Find Existing Checkpoint\"]\n        FE --> LoadCP[\"Load Checkpoint\"]\n        LoadCP --> SyncCheck[\"Check If Behind Current Window\"]\n        SyncCheck -->|\"Yes\"| Catchup[\"Catch Up with Aggregation Server\"]\n        SyncCheck -->|\"No\"| Continue[\"Continue Normal Operation\"]\n    end",
      "flowchart TD\n    subgraph \"Peer Management System\"\n        IP[\"Initial Peer Selection\"] --> RPS[\"Regular Peer Selection\"]\n        RPS --> PP[\"Post Peer List\"]\n        PP --> EP[\"Evaluate Peers\"]\n        \n        subgraph \"Selection Strategy\"\n            TS[\"Topk Selection\\nHighest-weighted peers\"]\n            RS[\"Random Selection\\nExploration\"]\n            PS[\"Prioritized Sampling\\nFair evaluation\"]\n        end\n    end",
      "flowchart TD\n    subgraph \"Validator Communication\"\n        CM[\"Comms Module\"] --> R2[\"R2 Storage Integration\"]\n        CM --> BT[\"Bittensor Blockchain\"]\n        CM --> AS[\"Aggregation Server\"]\n        \n        R2 --> GradientsB[\"Gradients Bucket\"]\n        R2 --> CheckpointsB[\"Checkpoints Bucket\"]\n        R2 --> PeersB[\"Peer Lists Storage\"]\n        \n        GradientsB --> GG[\"Gradient Gathering\"]\n        CheckpointsB --> CPM[\"Checkpoint Management\"]\n        PeersB --> PLM[\"Peer List Management\"]\n        \n        BT --> WS[\"Weight Setting\"]\n        BT --> MM[\"Metagraph Monitoring\"]\n    end"
    ],
    "potential_frontmatter": {
      "title": "Validators"
    }
  },
  "/tplr-ai/templar/3.1-weight-setting": {
    "original_deepwiki_href": "/tplr-ai/templar/3.1-weight-setting",
    "title": "Weight Setting",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/3.1-weight-setting",
    "level": 1,
    "target_astro_path": "/validators/weight-setting",
    "main_markdown_content": "# Weight Setting\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/chain.py](src/tplr/chain.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n- [src/tplr/compress.py](src/tplr/compress.py)\n- [src/tplr/neurons.py](src/tplr/neurons.py)\n- [tests/test_model_comparison.py](tests/test_model_comparison.py)\n\n</details>\n\n\n\nThis document explains how validators evaluate miner-produced gradients and set weights on the Bittensor blockchain in the Templar decentralized training framework. Weight setting is the critical mechanism that determines the rewards miners receive for their contributions to model training, ensuring that validators can appropriately incentivize high-quality gradient contributions.\n\n## Overview of Weight Setting Process\n\nWeight setting in Templar involves multiple interconnected evaluation mechanisms that assess different aspects of miner performance. The process combines gradient quality assessment, model synchronization verification, and consistency tracking to produce final weights.\n\n```mermaid\nflowchart TB\n    subgraph \"Weight Setting Process\"\n        direction TB\n        A[\"Gradient Evaluation\"] --> B[\"Score Calculation\"]\n        B --> C[\"OpenSkill Rating Update\"]\n        C --> D[\"Weight Normalization\"]\n        D --> E[\"Set Weights on Chain\"]\n    end\n\n    subgraph \"Score Components\"\n        direction TB\n        G1[\"Gradient Scores\"] --> F[\"Final Scores\"]\n        G2[\"Sync Scores\"] --> F\n        G3[\"Binary Indicator Scores\"] --> F\n    end\n\n    A --- G1\n    B --- G2\n    B --- G3\n    F --- C\n```\n\nSources: [neurons/validator.py:355-455](). [neurons/validator.py:489-514]()\n\n## Score Components and Calculation\n\nValidators in Templar use several types of scores to comprehensively evaluate miner performance:\n\n| Score Type | Purpose | Implementation |\n|------------|---------|----------------|\n| Gradient Scores | Evaluate the quality of gradients | Measures improvement in loss after applying gradients |\n| Sync Scores | Verify model synchronization | Calculates how closely a miner's model matches the global model |\n| Binary Indicator Scores | Track consistency | Binary indicator of whether a miner is contributing positively |\n| Final Scores | Determine weights | Combination of all scores for final weighting |\n\nThe calculation of these scores involves testing miner-submitted gradients on validation data and measuring the resulting improvement in model performance.\n\n```mermaid\nflowchart LR\n    subgraph \"Gradient Evaluation Process\"\n        direction LR\n        A[\"Miner Gradient\"] --> B[\"Apply to Model\"]\n        B --> C[\"Evaluate on Data Batches\"]\n        C --> D[\"Measure Loss Improvement\"]\n        D --> E[\"Calculate Gradient Score\"]\n    end\n```\n\nSources: [neurons/validator.py:489-514](). [neurons/validator.py:914-1028]()\n\n## OpenSkill Rating System\n\nTemplar uses the OpenSkill rating system with a PlackettLuce model to maintain probabilistic skill ratings for each miner. This system accounts for uncertainty and relative performance among peers.\n\n```mermaid\nflowchart TB\n    subgraph \"OpenSkill Rating Update\"\n        direction TB\n        A[\"Collect Window Scores\"] --> B[\"Create Teams from UIDs\"]\n        B --> C[\"Rate Using PlackettLuce Model\"]\n        C --> D[\"Update Miner Ratings\"]\n        D --> E[\"Calculate Ordinal Values\"]\n        E --> F[\"Update Final Scores\"]\n    end\n```\n\nKey parameters for the OpenSkill rating system are controlled by hyperparameters:\n- `openskill_beta`: Controls the dynamics of rating changes (default: 20)\n- `openskill_tau`: Controls the uncertainty in ratings (default: 0.1)\n\nSources: [neurons/validator.py:356-445](). [hparams.json:50-51]()\n\n## Weight Normalization\n\nAfter calculating final scores for each miner, the validator normalizes these scores into weights that sum to 1.0. This uses a min-power normalization approach that emphasizes higher-performing miners.\n\n```mermaid\nflowchart TB\n    subgraph \"Weight Normalization\"\n        direction TB\n        A[\"Final Scores\"] --> B[\"Filter Positive Scores\"]\n        B --> C[\"Apply Power Normalization\"]\n        C --> D[\"Verify Sum  1.0\"]\n        D --> E[\"Normalized Weights\"]\n    end\n```\n\nThe power normalization is controlled by the `power_normalisation` hyperparameter (default: 2.0), which determines how much the system should favor higher-scoring miners.\n\nKey implementation details:\n- Only miners with positive scores receive non-zero weights\n- The power normalization function is applied to ensure weights sum to 1.0\n- The implementation checks that the sum of weights is approximately 1.0\n\nSources: [neurons/validator.py:446-488](). [hparams.json:40]()\n\n## Model Evaluation Mechanism\n\nThe validator assesses gradient quality by measuring how much a miner's gradient improves model performance on evaluation data batches:\n\n```mermaid\nsequenceDiagram\n    participant V as \"Validator\"\n    participant M as \"Model\"\n    participant D as \"Evaluation Data\"\n    \n    V->>M: Measure initial loss (loss_before)\n    V->>M: Apply miner gradient\n    V->>M: Measure new loss (loss_after)\n    V->>V: Calculate improvement = loss_before - loss_after\n    V->>V: Calculate relative improvement = improvement / loss_before\n    V->>V: Update gradient score\n```\n\nSources: [neurons/validator.py:489-514](). [neurons/validator.py:914-1028]()\n\n## Inactivity Handling\n\nValidators apply penalties to miners who become inactive or fail to submit gradients in a particular window:\n\n```mermaid\nflowchart TB\n    subgraph \"Inactivity Management\"\n        direction TB\n        A[\"Monitor Peer Activity\"] --> B[\"Detect Inactive Peers\"]\n        B --> C[\"Apply Inactivity Penalty\"]\n        B --> D[\"Apply Missing Gradient Penalty\"]\n        B --> E[\"Apply Sync Score Penalty\"]\n        C & D & E --> F[\"Reset Peers After Extended Inactivity\"]\n    end\n```\n\nInactivity penalties are configured with several parameters:\n- `inactivity_slash_rate`: 25% score reduction per window for inactive miners\n- `missing_gradient_slash_rate`: 75% score reduction for miners failing to submit gradients\n- `sync_score_slash_rate`: 75% score reduction for miners with poor synchronization\n- `reset_inactivity_windows`: Number of windows after which an inactive miner is fully reset (default: 25)\n\nSources: [neurons/validator.py:302-316](). [neurons/validator.py:697-769](). [hparams.json:48]()\n\n## Integration with Synchronization Verification\n\nValidators also evaluate how well miners stay synchronized with the global model state by comparing model parameters:\n\n```mermaid\nclassDiagram\n    class SyncVerification {\n        +compare_model_with_debug_dict()\n        +l2_norm\n        +avg_l2_norm\n        +avg_abs_diff\n        +max_diff\n        +avg_steps_behind\n        +max_steps_behind\n    }\n    \n    class SyncScoreCalculation {\n        +evaluate_miner_sync()\n        +sync_scores\n        +sync_max_steps_behind\n    }\n    \n    SyncVerification --> SyncScoreCalculation\n```\n\nThe synchronization verification process:\n1. Loads debug dictionaries containing parameter samples from miners\n2. Calculates various distance metrics between miner and expected model parameters\n3. Computes \"steps behind\" metrics to quantify synchronization lag\n4. Updates sync scores based on these metrics\n\nSources: [neurons/validator.py:875-892](). [src/tplr/neurons.py:403-476]()\n\n## Implementation in Code\n\nThe weight setting functionality is primarily implemented in the `Validator` class in `neurons/validator.py`. Key methods include:\n\n- `update_openskill_ratings()`: Updates miner ratings using the OpenSkill system\n- `update_weights()`: Normalizes scores into weights\n- `evaluate_model_on_batches()`: Evaluates model performance on data batches\n- `reset_peer()`: Handles resetting peers after extended inactivity\n- `evaluate_miner_sync()`: Evaluates miner model synchronization\n\nThe process is controlled by hyperparameters defined in `hparams.json`, including:\n- `openskill_beta` and `openskill_tau` for rating configuration\n- `power_normalisation` for weight normalization\n- `sync_max_steps_behind` for synchronization thresholds\n- Various slash rates for penalties\n\nSources: [neurons/validator.py:356-445](). [neurons/validator.py:446-488](). [neurons/validator.py:302-316](). [hparams.json:40-52]()\n\n## Architecture Integration\n\n```mermaid\nflowchart TB\n    subgraph \"Templar System\"\n        direction TB\n        A[\"Miners\"] -->|\"Submit Gradients\"| B[\"Validator\"]\n        B -->|\"Evaluate Gradients\"| C[\"Score Calculation\"]\n        C --> D[\"Weight Setting\"]\n        D -->|\"Set Weights\"| E[\"Bittensor Blockchain\"]\n        E -->|\"Determines Rewards\"| A\n    end\n```\n\nThe weight setting process forms a critical feedback loop in the Templar architecture:\n1. Miners compute and submit gradients\n2. Validators evaluate these gradients\n3. Validators set weights on the blockchain based on evaluations\n4. Miner rewards are determined by these weights\n5. Miners are incentivized to improve their gradient quality\n\nSources: [neurons/validator.py](). [neurons/miner.py:229-755]()\n\n## Technical Details\n\nThe weight setting function `update_weights()` creates a mask for evaluated peers with positive scores and applies power normalization only to those positive scores:\n\n```python\ndef update_weights(self) -> None:\n    \"\"\"\n    Update the weights for all evaluated peers using min power normalization.\n    This method:\n    1. Creates a mask for peers that have been evaluated\n    2. Creates a mask for evaluated peers with positive scores\n    3. Applies power normalization to only the positive scores\n    4. Verifies that weights sum to approximately 1.0\n    This approach only assigns weights to peers with positive scores.\n    \"\"\"\n```\n\nThis implementation ensures that only miners contributing positively to the model training receive rewards, creating a robust incentive mechanism for the decentralized training process.\n\nSources: [neurons/validator.py:446-488]()",
    "resolved_links": [
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/chain.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/chain.py",
        "original_deepwiki_href": "src/tplr/chain.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/compress.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/compress.py",
        "original_deepwiki_href": "src/tplr/compress.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/neurons.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/neurons.py",
        "original_deepwiki_href": "src/tplr/neurons.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_model_comparison.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_model_comparison.py",
        "original_deepwiki_href": "tests/test_model_comparison.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py:355-455",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:489-514",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:914-1028",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:356-445",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:50-51",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:446-488",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:40",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:302-316",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:697-769",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:48",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:875-892",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:403-476",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:40-52",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:229-755",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TB\n    subgraph \"Weight Setting Process\"\n        direction TB\n        A[\"Gradient Evaluation\"] --> B[\"Score Calculation\"]\n        B --> C[\"OpenSkill Rating Update\"]\n        C --> D[\"Weight Normalization\"]\n        D --> E[\"Set Weights on Chain\"]\n    end\n\n    subgraph \"Score Components\"\n        direction TB\n        G1[\"Gradient Scores\"] --> F[\"Final Scores\"]\n        G2[\"Sync Scores\"] --> F\n        G3[\"Binary Indicator Scores\"] --> F\n    end\n\n    A --- G1\n    B --- G2\n    B --- G3\n    F --- C",
      "flowchart LR\n    subgraph \"Gradient Evaluation Process\"\n        direction LR\n        A[\"Miner Gradient\"] --> B[\"Apply to Model\"]\n        B --> C[\"Evaluate on Data Batches\"]\n        C --> D[\"Measure Loss Improvement\"]\n        D --> E[\"Calculate Gradient Score\"]\n    end",
      "flowchart TB\n    subgraph \"OpenSkill Rating Update\"\n        direction TB\n        A[\"Collect Window Scores\"] --> B[\"Create Teams from UIDs\"]\n        B --> C[\"Rate Using PlackettLuce Model\"]\n        C --> D[\"Update Miner Ratings\"]\n        D --> E[\"Calculate Ordinal Values\"]\n        E --> F[\"Update Final Scores\"]\n    end",
      "flowchart TB\n    subgraph \"Weight Normalization\"\n        direction TB\n        A[\"Final Scores\"] --> B[\"Filter Positive Scores\"]\n        B --> C[\"Apply Power Normalization\"]\n        C --> D[\"Verify Sum  1.0\"]\n        D --> E[\"Normalized Weights\"]\n    end",
      "sequenceDiagram\n    participant V as \"Validator\"\n    participant M as \"Model\"\n    participant D as \"Evaluation Data\"\n    \n    V->>M: Measure initial loss (loss_before)\n    V->>M: Apply miner gradient\n    V->>M: Measure new loss (loss_after)\n    V->>V: Calculate improvement = loss_before - loss_after\n    V->>V: Calculate relative improvement = improvement / loss_before\n    V->>V: Update gradient score",
      "flowchart TB\n    subgraph \"Inactivity Management\"\n        direction TB\n        A[\"Monitor Peer Activity\"] --> B[\"Detect Inactive Peers\"]\n        B --> C[\"Apply Inactivity Penalty\"]\n        B --> D[\"Apply Missing Gradient Penalty\"]\n        B --> E[\"Apply Sync Score Penalty\"]\n        C & D & E --> F[\"Reset Peers After Extended Inactivity\"]\n    end",
      "classDiagram\n    class SyncVerification {\n        +compare_model_with_debug_dict()\n        +l2_norm\n        +avg_l2_norm\n        +avg_abs_diff\n        +max_diff\n        +avg_steps_behind\n        +max_steps_behind\n    }\n    \n    class SyncScoreCalculation {\n        +evaluate_miner_sync()\n        +sync_scores\n        +sync_max_steps_behind\n    }\n    \n    SyncVerification --> SyncScoreCalculation",
      "flowchart TB\n    subgraph \"Templar System\"\n        direction TB\n        A[\"Miners\"] -->|\"Submit Gradients\"| B[\"Validator\"]\n        B -->|\"Evaluate Gradients\"| C[\"Score Calculation\"]\n        C --> D[\"Weight Setting\"]\n        D -->|\"Set Weights\"| E[\"Bittensor Blockchain\"]\n        E -->|\"Determines Rewards\"| A\n    end"
    ],
    "potential_frontmatter": {
      "title": "Weight Setting"
    }
  },
  "/tplr-ai/templar/4-aggregation-server": {
    "original_deepwiki_href": "/tplr-ai/templar/4-aggregation-server",
    "title": "Aggregation Server",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/4-aggregation-server",
    "level": 0,
    "target_astro_path": "/aggregation-server",
    "main_markdown_content": "# Aggregation Server\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [README.md](README.md)\n- [docs/miner.md](docs/miner.md)\n- [docs/validator.md](docs/validator.md)\n- [neurons/aggregator.py](neurons/aggregator.py)\n- [src/tplr/chain.py](src/tplr/chain.py)\n- [src/tplr/compress.py](src/tplr/compress.py)\n- [src/tplr/neurons.py](src/tplr/neurons.py)\n- [telemetry/simulator/loki-test.py](telemetry/simulator/loki-test.py)\n- [tests/test_model_comparison.py](tests/test_model_comparison.py)\n\n</details>\n\n\n\nThe Aggregation Server is a critical component in the Templar distributed training framework that collects gradients from miners, aggregates them, and makes them available to all network participants. This central coordination allows the system to maintain consistent model state across decentralized nodes, facilitating efficient convergence during distributed training.\n\nFor information about gradient processing by miners, see [Gradient Processing](#2.1). For details on how validators use aggregated gradients, see [Weight Setting](#3.1).\n\n## System Overview\n\nThe Aggregation Server serves as a central aggregation point in Templar's architecture, bridging the operations of miners and validators while ensuring model consistency.\n\n```mermaid\ngraph TD\n    subgraph \"Templar Network Components\"\n        M[\"Miners\"]\n        V[\"Validators\"]\n        AS[\"AggregationServer\"]\n        BN[\"Bittensor Network\"]\n    end\n    \n    subgraph \"Storage Infrastructure\"\n        R2[\"Cloudflare R2 Storage\"]\n        subgraph \"R2 Buckets\"\n            AG[\"Aggregator Bucket\"]\n            GR[\"Gradients Bucket\"]\n            DB[\"Dataset Bucket\"]\n        end\n    end\n    \n    M -- \"Submit gradients\" --> GR\n    AS -- \"Gather gradients\" --> GR\n    AS -- \"Store aggregated state\" --> AG\n    V -- \"Fetch aggregated state\" --> AG\n    M -- \"Fetch aggregated state\" --> AG\n    \n    BN -- \"Sync metagraph data\" --> AS\n    BN -- \"Window signals\" --> AS\n    BN -- \"Block timing\" --> AS\n```\n\nSources: [neurons/aggregator.py:40-155](). [README.md:52-56]().\n\n## Architectural Components\n\nThe Aggregation Server implementation consists of several key components that work together to process gradients in a synchronized manner.\n\n```mermaid\nclassDiagram\n    class AggregationServer {\n        +model: LlamaForCausalLM\n        +transformer: TransformDCT\n        +compressor: CompressDCT\n        +comms: Comms\n        +current_block: int\n        +current_window: int\n        +metagraph: Metagraph\n        +metrics_logger: MetricsLogger\n        +get_current_window()\n        +process_window()\n        +run()\n        +block_listener()\n    }\n    \n    class Comms {\n        +bucket: Bucket\n        +gather()\n        +put()\n        +get_peer_list()\n    }\n    \n    class TransformDCT {\n        +encode()\n        +decode()\n    }\n    \n    class CompressDCT {\n        +compress()\n        +decompress()\n        +batch_decompress()\n    }\n    \n    AggregationServer --> TransformDCT: \"uses for gradient transformation\"\n    AggregationServer --> CompressDCT: \"uses for gradient compression\"\n    AggregationServer --> Comms: \"uses for data exchange\"\n```\n\nSources: [neurons/aggregator.py:40-155](). [src/tplr/compress.py:35-124]().\n\n## Initialization and Configuration\n\nThe Aggregation Server initializes a lightweight model instance for gradient processing, sets up communication channels, and configures compression parameters.\n\n### Configuration Setup\nThe server uses a standard argument parser with additional Bittensor-specific arguments:\n\n```mermaid\ngraph TD\n    AC[\"agg_config()\"] --> AP[\"ArgumentParser\"]\n    AP --> |\"Add arguments\"| NA[\"Network arguments<br>--netuid, --device, etc.\"]\n    AP --> |\"Add arguments\"| BA[\"Bittensor arguments<br>subtensor, wallet, logging\"]\n    AP --> BC[\"bt.config(parser)\"]\n    BC --> CF[\"config object\"]\n```\n\nSources: [neurons/aggregator.py:41-69]().\n\n### Core Components Initialization\n\nDuring initialization, the Aggregation Server:\n\n1. Creates a model instance for processing gradients (using `LlamaForCausalLM`)\n2. Initializes compression tools (`TransformDCT` and `CompressDCT`)\n3. Configures communication channels (`Comms`)\n4. Sets up telemetry (WandB and InfluxDB)\n5. Establishes blockchain connectivity\n\nSources: [neurons/aggregator.py:72-155]().\n\n## The Aggregation Process\n\nThe server operates in synchronized windows aligned with Bittensor's block timing system. The process follows these key steps:\n\n```mermaid\nsequenceDiagram\n    participant AS as AggregationServer\n    participant MN as Miners\n    participant R2 as R2 Storage\n    participant BT as Bittensor\n    \n    Note over AS: run() method starts\n    \n    loop For each window\n        BT->>AS: Block signals via block_listener\n        AS->>AS: Update current_window\n        \n        Note over AS: process_window() begins\n        AS->>BT: Query timestamp for window\n        BT->>AS: Return timestamp\n        AS->>AS: Calculate time bounds for valid gradients\n        \n        AS->>AS: Update peers via update_peers()\n        \n        MN->>R2: Upload gradients during window\n        \n        AS->>R2: gather() gradients from selected peers\n        Note over AS: Get gradients within time bounds\n        \n        opt For each valid gradient\n            AS->>AS: batch_decompress() gradients\n            AS->>AS: Transform via TransformDCT\n            AS->>AS: Pack into binary tensor\n        end\n        \n        AS->>R2: Store aggregated state in aggregator bucket\n        AS->>AS: Log metrics to WandB/InfluxDB\n        \n        Note over AS: Wait for next window\n    end\n```\n\nSources: [neurons/aggregator.py:162-424](). [src/tplr/neurons.py:127-197]().\n\n## Gradient Processing Details\n\nThe server employs a sophisticated gradient processing pipeline that uses DCT (Discrete Cosine Transform) for efficient compression and aggregation.\n\n### Gradient Gathering\n\nThe `process_window` method gathers gradients from miners using time-bounded collection:\n\n1. Determines the current window and time bounds for valid gradients\n2. Selects peers for gradient collection based on network parameters\n3. Uses the `comms.gather()` method to collect gradients from the selected peers\n\nSources: [neurons/aggregator.py:209-291]().\n\n### Gradient Processing\n\nOnce gradients are gathered, they are processed as follows:\n\n```mermaid\ngraph TD\n    G[\"gather() function<br>collects miner gradients\"] --> P[\"process_start<br>Process gathered gradients\"]\n    P --> |\"For each parameter\"| I[\"Extract idxs/vals<br>from gather_result\"]\n    I --> D[\"batch_decompress()<br>Reconstruct gradients\"]\n    D --> T[\"transformer.decode()<br>Inverse DCT transform\"]\n    T --> S[\"sign() method<br>Convert to binary representation\"]\n    S --> B[\"pack_binary_tensor()<br>Pack as compact binary\"]\n    B --> ST[\"Store in processed_state_dict\"]\n    ST --> R2[\"Put in R2 aggregator bucket<br>with window metadata\"]\n```\n\nSources: [neurons/aggregator.py:292-372](). [src/tplr/neurons.py:478-516]().\n\n## Synchronization with Nodes\n\nMiners and validators synchronize with the aggregation server through the `catchup_with_aggregation_server()` function in the `tplr.neurons` module. This ensures all nodes converge to a consistent model state.\n\n### Catchup Process Flow\n\n```mermaid\ngraph TD\n    CS[\"catchup_with_aggregation_server()\"] --> CW[\"Calculate windows to catch up<br>checkpoint_window  target_window\"]\n    CW --> |\"For each window\"| LA[\"load_aggregation() from server\"]\n    LA --> PD[\"process_loaded_data()<br>Unpack compressed tensors\"]\n    PD --> |\"For each parameter\"| AT[\"Apply gradients to model parameters\"]\n    AT --> OS[\"optimizer.step()<br>scheduler.step()\"]\n    OS --> DD[\"Compare with debug_dict<br>to verify synchronization\"]\n    DD --> GS[\"Update global_step\"]\n```\n\nSources: [src/tplr/neurons.py:199-368]().\n\n### Data Loading and Processing\n\nWhen nodes fetch data from the aggregation server, they:\n\n1. Load the aggregated state for a specific window\n2. Process and unpack the binary tensor representation\n3. Apply the gradients to their local model parameters\n4. Verify synchronization through model comparison\n\nSources: [src/tplr/neurons.py:371-477]().\n\n## Block Listening and Window Synchronization\n\nThe Aggregation Server stays synchronized with the blockchain through a block listener thread that monitors new blocks and updates the current window.\n\n```mermaid\ngraph TD\n    BL[\"block_listener() thread\"] --> SB[\"Subscribe to block headers\"]\n    SB --> HF[\"handler() function<br>processes block events\"]\n    HF --> UB[\"Update current_block\"]\n    UB --> CW[\"Calculate new_window from block\"]\n    CW --> |\"If window changed\"| UW[\"Update current_window\"]\n    UW --> NC[\"Notify comms system<br>comms.current_window = current_window\"]\n```\n\nSources: [neurons/aggregator.py:489-527]().\n\n## Error Handling and Resilience\n\nThe server implements several error handling mechanisms to ensure continuous operation:\n\n1. Retry logic for blockchain connections with exponential backoff\n2. Graceful handling of missing or invalid gradients\n3. Exception catching in the main processing loop \n4. Fallback time window calculation if blockchain timestamps are unavailable\n\nSources: [neurons/aggregator.py:425-486]().\n\n## Running the Aggregation Server\n\nThe Aggregation Server is designed to run as a standalone service and can be started using:\n\n```bash\npython neurons/aggregator.py --netuid <netuid> --device <device>\n```\n\nThe server uses `uvloop` for improved performance and runs an asynchronous event loop to process windows continuously.\n\nSources: [neurons/aggregator.py:529-532]().\n\n## Integration with Other System Components\n\nThe Aggregation Server integrates closely with both miners and validators in the Templar system:\n\n### Miner Integration\n\nMiners:\n1. Submit their gradients to the gradients bucket\n2. Periodically synchronize with the Aggregation Server to get the latest model state\n3. Apply aggregated gradients to their local model during catchup periods\n\nSources: [docs/miner.md:446-461]().\n\n### Validator Integration\n\nValidators:\n1. Evaluate miner contributions based on the current model state\n2. Synchronize with the Aggregation Server to maintain a consistent reference model\n3. Use the aggregated state to ensure fair evaluation of miner gradients\n\nSources: [docs/validator.md:387-398]().\n\n## Monitoring and Telemetry\n\nThe Aggregation Server provides comprehensive monitoring and telemetry:\n\n1. **Weights & Biases**: Logs aggregation metrics, success rates, and timing information\n2. **InfluxDB**: Detailed performance metrics with tagging by window and iteration\n3. **Loki Logging**: Structured logging for operational events and error tracing\n\nKey metrics tracked include:\n- Aggregation success rate\n- Number of peers selected and successfully aggregated\n- Processing time for gathering, processing, and storing\n- Skipped UIDs and error counts\n\nSources: [neurons/aggregator.py:374-414](). [telemetry/simulator/loki-test.py:18-45]().\n\n## Conclusion\n\nThe Aggregation Server is a critical component in the Templar framework that enables efficient distributed training by providing a consistent aggregation mechanism for gradients across the network. By centralizing the aggregation process while maintaining the decentralized nature of the training system, it helps achieve convergence in model training while reducing communication overhead through its compression techniques.",
    "resolved_links": [
      {
        "text": "README.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/README.md",
        "original_deepwiki_href": "README.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/miner.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/miner.md",
        "original_deepwiki_href": "docs/miner.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/validator.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/validator.md",
        "original_deepwiki_href": "docs/validator.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/aggregator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/aggregator.py",
        "original_deepwiki_href": "neurons/aggregator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/chain.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/chain.py",
        "original_deepwiki_href": "src/tplr/chain.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/compress.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/compress.py",
        "original_deepwiki_href": "src/tplr/compress.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/neurons.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/neurons.py",
        "original_deepwiki_href": "src/tplr/neurons.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/simulator/loki-test.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/simulator/loki-test.py",
        "original_deepwiki_href": "telemetry/simulator/loki-test.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_model_comparison.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_model_comparison.py",
        "original_deepwiki_href": "tests/test_model_comparison.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/aggregator.py:40-155",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "README.md:52-56",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/compress.py:35-124",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:41-69",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:72-155",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:162-424",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:127-197",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:209-291",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:292-372",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:478-516",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:199-368",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:371-477",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:489-527",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:425-486",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:529-532",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "docs/miner.md:446-461",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "docs/validator.md:387-398",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/aggregator.py:374-414",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/simulator/loki-test.py:18-45",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Gradient Processing",
        "href": "/miners/gradient-processing#2.1",
        "original_deepwiki_href": "#2.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Weight Setting",
        "href": "/validators/weight-setting#3.1",
        "original_deepwiki_href": "#3.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Templar Network Components\"\n        M[\"Miners\"]\n        V[\"Validators\"]\n        AS[\"AggregationServer\"]\n        BN[\"Bittensor Network\"]\n    end\n    \n    subgraph \"Storage Infrastructure\"\n        R2[\"Cloudflare R2 Storage\"]\n        subgraph \"R2 Buckets\"\n            AG[\"Aggregator Bucket\"]\n            GR[\"Gradients Bucket\"]\n            DB[\"Dataset Bucket\"]\n        end\n    end\n    \n    M -- \"Submit gradients\" --> GR\n    AS -- \"Gather gradients\" --> GR\n    AS -- \"Store aggregated state\" --> AG\n    V -- \"Fetch aggregated state\" --> AG\n    M -- \"Fetch aggregated state\" --> AG\n    \n    BN -- \"Sync metagraph data\" --> AS\n    BN -- \"Window signals\" --> AS\n    BN -- \"Block timing\" --> AS",
      "classDiagram\n    class AggregationServer {\n        +model: LlamaForCausalLM\n        +transformer: TransformDCT\n        +compressor: CompressDCT\n        +comms: Comms\n        +current_block: int\n        +current_window: int\n        +metagraph: Metagraph\n        +metrics_logger: MetricsLogger\n        +get_current_window()\n        +process_window()\n        +run()\n        +block_listener()\n    }\n    \n    class Comms {\n        +bucket: Bucket\n        +gather()\n        +put()\n        +get_peer_list()\n    }\n    \n    class TransformDCT {\n        +encode()\n        +decode()\n    }\n    \n    class CompressDCT {\n        +compress()\n        +decompress()\n        +batch_decompress()\n    }\n    \n    AggregationServer --> TransformDCT: \"uses for gradient transformation\"\n    AggregationServer --> CompressDCT: \"uses for gradient compression\"\n    AggregationServer --> Comms: \"uses for data exchange\"",
      "graph TD\n    AC[\"agg_config()\"] --> AP[\"ArgumentParser\"]\n    AP --> |\"Add arguments\"| NA[\"Network arguments<br>--netuid, --device, etc.\"]\n    AP --> |\"Add arguments\"| BA[\"Bittensor arguments<br>subtensor, wallet, logging\"]\n    AP --> BC[\"bt.config(parser)\"]\n    BC --> CF[\"config object\"]",
      "sequenceDiagram\n    participant AS as AggregationServer\n    participant MN as Miners\n    participant R2 as R2 Storage\n    participant BT as Bittensor\n    \n    Note over AS: run() method starts\n    \n    loop For each window\n        BT->>AS: Block signals via block_listener\n        AS->>AS: Update current_window\n        \n        Note over AS: process_window() begins\n        AS->>BT: Query timestamp for window\n        BT->>AS: Return timestamp\n        AS->>AS: Calculate time bounds for valid gradients\n        \n        AS->>AS: Update peers via update_peers()\n        \n        MN->>R2: Upload gradients during window\n        \n        AS->>R2: gather() gradients from selected peers\n        Note over AS: Get gradients within time bounds\n        \n        opt For each valid gradient\n            AS->>AS: batch_decompress() gradients\n            AS->>AS: Transform via TransformDCT\n            AS->>AS: Pack into binary tensor\n        end\n        \n        AS->>R2: Store aggregated state in aggregator bucket\n        AS->>AS: Log metrics to WandB/InfluxDB\n        \n        Note over AS: Wait for next window\n    end",
      "graph TD\n    G[\"gather() function<br>collects miner gradients\"] --> P[\"process_start<br>Process gathered gradients\"]\n    P --> |\"For each parameter\"| I[\"Extract idxs/vals<br>from gather_result\"]\n    I --> D[\"batch_decompress()<br>Reconstruct gradients\"]\n    D --> T[\"transformer.decode()<br>Inverse DCT transform\"]\n    T --> S[\"sign() method<br>Convert to binary representation\"]\n    S --> B[\"pack_binary_tensor()<br>Pack as compact binary\"]\n    B --> ST[\"Store in processed_state_dict\"]\n    ST --> R2[\"Put in R2 aggregator bucket<br>with window metadata\"]",
      "graph TD\n    CS[\"catchup_with_aggregation_server()\"] --> CW[\"Calculate windows to catch up<br>checkpoint_window  target_window\"]\n    CW --> |\"For each window\"| LA[\"load_aggregation() from server\"]\n    LA --> PD[\"process_loaded_data()<br>Unpack compressed tensors\"]\n    PD --> |\"For each parameter\"| AT[\"Apply gradients to model parameters\"]\n    AT --> OS[\"optimizer.step()<br>scheduler.step()\"]\n    OS --> DD[\"Compare with debug_dict<br>to verify synchronization\"]\n    DD --> GS[\"Update global_step\"]",
      "graph TD\n    BL[\"block_listener() thread\"] --> SB[\"Subscribe to block headers\"]\n    SB --> HF[\"handler() function<br>processes block events\"]\n    HF --> UB[\"Update current_block\"]\n    UB --> CW[\"Calculate new_window from block\"]\n    CW --> |\"If window changed\"| UW[\"Update current_window\"]\n    UW --> NC[\"Notify comms system<br>comms.current_window = current_window\"]"
    ],
    "potential_frontmatter": {
      "title": "Aggregation Server"
    }
  },
  "/tplr-ai/templar/5-evaluator": {
    "original_deepwiki_href": "/tplr-ai/templar/5-evaluator",
    "title": "Evaluator",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/5-evaluator",
    "level": 0,
    "target_astro_path": "/evaluator",
    "main_markdown_content": "# Evaluator\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [pytest.ini](pytest.ini)\n- [scripts/evaluator-setup/compose.yml](scripts/evaluator-setup/compose.yml)\n- [scripts/evaluator.py](scripts/evaluator.py)\n- [tests/test_checkpoints.py](tests/test_checkpoints.py)\n- [tests/test_evaluator.py](tests/test_evaluator.py)\n- [tests/test_influx_integration.py](tests/test_influx_integration.py)\n- [tests/test_prepare_gradient_dict.py](tests/test_prepare_gradient_dict.py)\n\n</details>\n\n\n\nThe Evaluator is an autonomous service in the Templar framework that continuously assesses model performance by running standardized benchmark tasks on the latest checkpoints. It operates independently from miners and validators, providing objective measurements of model capabilities throughout the training process.\n\nSources: [scripts/evaluator.py:1-40]()\n\n## Overview\n\nThe Evaluator performs the following key functions:\n\n1. Monitors for new model checkpoints by window number\n2. Downloads and loads the latest checkpoint\n3. Executes standardized benchmark tasks (e.g., ARC, MMLU, Winogrande)\n4. Logs evaluation results to InfluxDB for monitoring and analysis\n5. Manages resources efficiently for continuous operation\n\nUnlike miners that generate gradients or validators that assess gradient quality, the Evaluator focuses exclusively on measuring the end-to-end capabilities of the current model against established benchmarks.\n\n```mermaid\nflowchart TD\n    subgraph \"Evaluator Service\"\n        Monitor[\"Monitor Checkpoints\"] --> Detect[\"Detect New Checkpoint\"]\n        Detect --> Load[\"Load Latest Model\"]\n        Load --> Evaluate[\"Run Benchmarks\"]\n        Evaluate --> Log[\"Log Results\"]\n        Log --> Cleanup[\"Clean Resources\"]\n        Cleanup --> Monitor\n    end\n\n    subgraph \"External Components\"\n        R2[\"Checkpoint Storage\"]\n        InfluxDB[\"InfluxDB Metrics\"]\n        LMEval[\"LM Evaluation Harness\"]\n    end\n\n    Load <--> R2\n    Evaluate <--> LMEval\n    Log --> InfluxDB\n```\n\nSources: [scripts/evaluator.py:125-147](), [scripts/evaluator.py:559-568]()\n\n## Architecture\n\nThe Evaluator operates as a standalone service that interacts with the Templar checkpoint storage system and metrics infrastructure. It leverages the Language Model Evaluation Harness (lm-eval) to execute standardized benchmarks.\n\n```mermaid\nclassDiagram\n    class Evaluator {\n        -config: bt.Config\n        -netuid: int\n        -model: LlamaForCausalLM\n        -metrics_logger: MetricsLogger\n        -last_eval_window: int\n        -comms: tplr.comms.Comms\n        +__init__()\n        +update_state()\n        +load_latest_model()\n        +_run_lm_eval()\n        +_process_results()\n        +_evaluate()\n        +run()\n        +cleanup()\n    }\n\n    class Comms {\n        +get_latest_checkpoint()\n        +get_commitments()\n        +update_peers_with_buckets()\n        +get_start_window()\n    }\n\n    class MetricsLogger {\n        +log()\n    }\n\n    class LlamaForCausalLM {\n        +save_pretrained()\n        +load_state_dict()\n    }\n\n    Evaluator --> Comms : uses\n    Evaluator --> MetricsLogger : logs metrics via\n    Evaluator --> LlamaForCausalLM : evaluates\n```\n\nSources: [scripts/evaluator.py:125-198]()\n\n## Evaluation Workflow\n\n### Checkpoint Detection and Loading\n\nThe Evaluator continuously monitors the blockchain for the latest checkpoint by window number. When a new checkpoint is detected, it downloads and loads the model weights.\n\n```mermaid\nsequenceDiagram\n    participant Evaluator\n    participant Comms as \"Comms Module\"\n    participant R2 as \"R2 Storage\"\n    participant Model as \"LLaMA Model\"\n    \n    Evaluator->>Comms: update_state()\n    Evaluator->>Comms: get_start_window()\n    Comms-->>Evaluator: current_window\n    \n    alt new checkpoint available\n        Evaluator->>Comms: get_latest_checkpoint(version)\n        Comms->>R2: fetch latest checkpoint\n        R2-->>Comms: checkpoint data\n        Comms-->>Evaluator: checkpoint_data, metadata\n        \n        Evaluator->>Model: load_state_dict(checkpoint_data[\"model_state_dict\"])\n        Evaluator->>Evaluator: Store momentum data\n    else no new checkpoint\n        Evaluator->>Evaluator: Wait for next interval\n    end\n```\n\nSources: [scripts/evaluator.py:211-282](), [tests/test_evaluator.py:59-83]()\n\n### Benchmark Execution\n\nWhen a new checkpoint is loaded, the Evaluator executes a series of benchmark tasks using the LM Evaluation Harness (lm-eval). Different tasks can be configured and executed on a schedule.\n\n```mermaid\nflowchart TD\n    subgraph \"Evaluator._evaluate()\"\n        LoadModel[\"Load Latest Model\"] --> SaveTemp[\"Save Model to Temp Location\"]\n        SaveTemp --> RunTasks[\"Run Benchmark Tasks\"]\n        RunTasks --> ProcessResults[\"Process Results\"]\n        ProcessResults --> CleanupTemp[\"Clean Up Temp Files\"]\n    end\n    \n    subgraph \"Benchmark Tasks\"\n        RegularTasks[\"Regular Tasks\\narc_challenge, arc_easy\\npiqa, winogrande, etc.\"]\n        MMLU[\"MMLU (Full)\\nPeriodically on 4th run\"]\n    end\n    \n    RunTasks --> RegularTasks\n    RunTasks --> MMLU\n    \n    RegularTasks --> |\"_run_lm_eval()\"| LMEval[\"lm-eval Command\"]\n    MMLU --> |\"_run_lm_eval() with few-shot\"| LMEval\n    \n    LMEval --> Results[\"Results JSON\"]\n    Results --> |\"_process_results()\"| Metrics[\"Parse Metrics\"]\n    Metrics --> InfluxDB[\"Log to InfluxDB\"]\n```\n\nSources: [scripts/evaluator.py:446-557]()\n\n### Results Processing\n\nAfter each benchmark run, the Evaluator processes the results by:\n1. Parsing the JSON output from lm-eval\n2. Extracting relevant metrics (accuracy scores)\n3. Logging both individual task results and summary metrics to InfluxDB\n\nThe system prioritizes certain metrics in a specific order (e.g., `acc_norm` over `acc`) based on their relevance and reliability.\n\nSources: [scripts/evaluator.py:338-441]()\n\n## Benchmark Tasks\n\nThe Evaluator supports multiple benchmark tasks that assess different capabilities of the language model:\n\n| Task | Description | Metric | Execution Mode |\n|------|-------------|--------|---------------|\n| arc_challenge | AI2 Reasoning Challenge (hard) | acc/acc_norm | Zero-shot |\n| arc_easy | AI2 Reasoning Challenge (easy) | acc/acc_norm | Zero-shot |\n| winogrande | Winograd Schema Challenge | acc/acc_norm | Zero-shot |\n| piqa | Physical Interaction QA | acc/acc_norm | Zero-shot |\n| hellaswag | Commonsense NLI | acc/acc_norm | Zero-shot |\n| openbookqa | Open Book Question Answering | acc/acc_norm | Zero-shot |\n| mmlu | Massive Multitask Language Understanding | acc/acc_norm | Both zero-shot and 5-shot |\n\nFor MMLU specifically, the Evaluator can run it in two modes:\n- Regular zero-shot evaluation with other tasks\n- Periodic 5-shot evaluation (every 4th run) with different configuration\n\nSources: [scripts/evaluator.py:89-94](), [scripts/evaluator.py:493-545]()\n\n### Benchmark Execution Details\n\nThe Evaluator runs benchmarks by:\n1. Saving the model to a temporary location\n2. Executing the lm-eval command with appropriate parameters\n3. Collecting and parsing results from the output JSON\n\n```mermaid\nflowchart LR\n    subgraph \"Evaluator._run_lm_eval\"\n        BuildCmd[\"Build lm-eval Command\"] --> RunCmd[\"Execute Command\"]\n        RunCmd --> TrackTime[\"Track Runtime\"]\n        TrackTime --> ReturnResults[\"Return Results\"]\n    end\n    \n    subgraph \"Command Parameters\"\n        Model[\"--model hf\"]\n        ModelArgs[\"--model_args pretrained=path\"]\n        Tasks[\"--tasks task1,task2\"]\n        Device[\"--device cuda:x\"]\n        BatchSize[\"--batch_size 8\"]\n        Output[\"--output_path path\"]\n        FewShot[\"--num_fewshot (optional)\"]\n        Limit[\"--limit (optional)\"]\n    end\n    \n    BuildCmd --> Model\n    BuildCmd --> ModelArgs\n    BuildCmd --> Tasks\n    BuildCmd --> Device\n    BuildCmd --> BatchSize\n    BuildCmd --> Output\n    BuildCmd --> FewShot\n    BuildCmd --> Limit\n```\n\nSources: [scripts/evaluator.py:284-336]()\n\n## Configuration Options\n\nThe Evaluator provides several configuration options to customize its behavior:\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| --netuid | Bittensor network UID | 3 |\n| --actual_batch_size | Evaluation batch size | 8 |\n| --device | Device to use for evaluation | cuda:7 |\n| --tasks | Comma-separated list of tasks | arc_challenge,arc_easy,openbookqa,winogrande,piqa,hellaswag,mmlu |\n| --checkpoint_path | Path to save/load checkpoints | checkpoints/ |\n| --eval_interval | Seconds between evaluations | 600 (10 mins) |\n| --uid | Override the wallet's UID | None |\n| --skip-gaps | Skip gaps in the evaluation process | False |\n\nSources: [scripts/evaluator.py:61-122]()\n\n## Deployment\n\nThe Evaluator is designed to run as a continuous service. It can be deployed using Docker via the provided compose file.\n\n### Docker Deployment\n\nThe repository includes a Docker Compose configuration for deploying the Evaluator:\n\n```yaml\n# Key elements from the compose.yml file:\n# - Uses the Templar container image\n# - Maps Bittensor wallet directory\n# - Sets up required environment variables\n# - Configures GPU access\n# - Sets up logging with journald\n# - Includes watchtower for automatic updates\n```\n\nSources: [scripts/evaluator-setup/compose.yml:1-33]()\n\n### Environment Requirements\n\nThe Evaluator requires several environment variables:\n\n- `R2_DATASET_ACCOUNT_ID`: R2 dataset account identifier\n- `R2_DATASET_BUCKET_NAME`: R2 storage bucket name\n- `R2_DATASET_READ_ACCESS_KEY_ID`: R2 read access key\n- `R2_DATASET_READ_SECRET_ACCESS_KEY`: R2 secret access key\n- `INFLUXDB_TOKEN`: InfluxDB API token (optional)\n\nSources: [scripts/evaluator.py:15-25]()\n\n## Metrics Logging\n\nThe Evaluator logs detailed metrics to InfluxDB:\n\n1. **Benchmark Metrics**: Runtime performance and execution details\n2. **Task Results**: Individual scores for each benchmark task\n3. **Summary Metrics**: Aggregated statistics across all tasks\n\n```mermaid\nflowchart TD\n    subgraph \"Metrics Collection\"\n        Benchmark[\"Benchmark Metrics\\n- Runtime\\n- Exit codes\"]\n        TaskScores[\"Task Scores\\n- acc/acc_norm by task\"]\n        Summary[\"Summary Metrics\\n- Number of tasks\\n- Window/block info\"]\n    end\n    \n    subgraph \"MetricsLogger\"\n        Log[\"log() method\"]\n        Tags[\"Metric Tags\\n- window\\n- block\\n- global_step\\n- task\"]\n        Fields[\"Metric Fields\\n- scores\\n- runtime\\n- count\"]\n    end\n    \n    subgraph \"Storage\"\n        InfluxDB[\"InfluxDB\\nTime-series database\"]\n    end\n    \n    Benchmark --> Log\n    TaskScores --> Log\n    Summary --> Log\n    \n    Log --> Tags\n    Log --> Fields\n    \n    Log --> InfluxDB\n```\n\nSources: [scripts/evaluator.py:368-441]()\n\n## Integration with Other Systems\n\nThe Evaluator integrates with several other components of the Templar framework:\n\n1. **Comms System**: For checkpoint retrieval and blockchain interaction\n2. **Metrics System**: For logging evaluation results\n3. **Storage System**: For accessing model checkpoints\n\nIt operates independently of miners and validators but provides crucial feedback on the quality of the model being trained by the network.\n\nSources: [scripts/evaluator.py:184-196]()",
    "resolved_links": [
      {
        "text": "pytest.ini",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/pytest.ini",
        "original_deepwiki_href": "pytest.ini",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/evaluator-setup/compose.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/evaluator-setup/compose.yml",
        "original_deepwiki_href": "scripts/evaluator-setup/compose.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/evaluator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/evaluator.py",
        "original_deepwiki_href": "scripts/evaluator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_checkpoints.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_checkpoints.py",
        "original_deepwiki_href": "tests/test_checkpoints.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_evaluator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_evaluator.py",
        "original_deepwiki_href": "tests/test_evaluator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_influx_integration.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_influx_integration.py",
        "original_deepwiki_href": "tests/test_influx_integration.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_prepare_gradient_dict.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_prepare_gradient_dict.py",
        "original_deepwiki_href": "tests/test_prepare_gradient_dict.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/evaluator.py:1-40",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:125-147",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:559-568",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:125-198",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:211-282",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_evaluator.py:59-83",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:446-557",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:338-441",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:89-94",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:493-545",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:284-336",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:61-122",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator-setup/compose.yml:1-33",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:15-25",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:368-441",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/evaluator.py:184-196",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Evaluator Service\"\n        Monitor[\"Monitor Checkpoints\"] --> Detect[\"Detect New Checkpoint\"]\n        Detect --> Load[\"Load Latest Model\"]\n        Load --> Evaluate[\"Run Benchmarks\"]\n        Evaluate --> Log[\"Log Results\"]\n        Log --> Cleanup[\"Clean Resources\"]\n        Cleanup --> Monitor\n    end\n\n    subgraph \"External Components\"\n        R2[\"Checkpoint Storage\"]\n        InfluxDB[\"InfluxDB Metrics\"]\n        LMEval[\"LM Evaluation Harness\"]\n    end\n\n    Load <--> R2\n    Evaluate <--> LMEval\n    Log --> InfluxDB",
      "classDiagram\n    class Evaluator {\n        -config: bt.Config\n        -netuid: int\n        -model: LlamaForCausalLM\n        -metrics_logger: MetricsLogger\n        -last_eval_window: int\n        -comms: tplr.comms.Comms\n        +__init__()\n        +update_state()\n        +load_latest_model()\n        +_run_lm_eval()\n        +_process_results()\n        +_evaluate()\n        +run()\n        +cleanup()\n    }\n\n    class Comms {\n        +get_latest_checkpoint()\n        +get_commitments()\n        +update_peers_with_buckets()\n        +get_start_window()\n    }\n\n    class MetricsLogger {\n        +log()\n    }\n\n    class LlamaForCausalLM {\n        +save_pretrained()\n        +load_state_dict()\n    }\n\n    Evaluator --> Comms : uses\n    Evaluator --> MetricsLogger : logs metrics via\n    Evaluator --> LlamaForCausalLM : evaluates",
      "sequenceDiagram\n    participant Evaluator\n    participant Comms as \"Comms Module\"\n    participant R2 as \"R2 Storage\"\n    participant Model as \"LLaMA Model\"\n    \n    Evaluator->>Comms: update_state()\n    Evaluator->>Comms: get_start_window()\n    Comms-->>Evaluator: current_window\n    \n    alt new checkpoint available\n        Evaluator->>Comms: get_latest_checkpoint(version)\n        Comms->>R2: fetch latest checkpoint\n        R2-->>Comms: checkpoint data\n        Comms-->>Evaluator: checkpoint_data, metadata\n        \n        Evaluator->>Model: load_state_dict(checkpoint_data[\"model_state_dict\"])\n        Evaluator->>Evaluator: Store momentum data\n    else no new checkpoint\n        Evaluator->>Evaluator: Wait for next interval\n    end",
      "flowchart TD\n    subgraph \"Evaluator._evaluate()\"\n        LoadModel[\"Load Latest Model\"] --> SaveTemp[\"Save Model to Temp Location\"]\n        SaveTemp --> RunTasks[\"Run Benchmark Tasks\"]\n        RunTasks --> ProcessResults[\"Process Results\"]\n        ProcessResults --> CleanupTemp[\"Clean Up Temp Files\"]\n    end\n    \n    subgraph \"Benchmark Tasks\"\n        RegularTasks[\"Regular Tasks\\narc_challenge, arc_easy\\npiqa, winogrande, etc.\"]\n        MMLU[\"MMLU (Full)\\nPeriodically on 4th run\"]\n    end\n    \n    RunTasks --> RegularTasks\n    RunTasks --> MMLU\n    \n    RegularTasks --> |\"_run_lm_eval()\"| LMEval[\"lm-eval Command\"]\n    MMLU --> |\"_run_lm_eval() with few-shot\"| LMEval\n    \n    LMEval --> Results[\"Results JSON\"]\n    Results --> |\"_process_results()\"| Metrics[\"Parse Metrics\"]\n    Metrics --> InfluxDB[\"Log to InfluxDB\"]",
      "flowchart LR\n    subgraph \"Evaluator._run_lm_eval\"\n        BuildCmd[\"Build lm-eval Command\"] --> RunCmd[\"Execute Command\"]\n        RunCmd --> TrackTime[\"Track Runtime\"]\n        TrackTime --> ReturnResults[\"Return Results\"]\n    end\n    \n    subgraph \"Command Parameters\"\n        Model[\"--model hf\"]\n        ModelArgs[\"--model_args pretrained=path\"]\n        Tasks[\"--tasks task1,task2\"]\n        Device[\"--device cuda:x\"]\n        BatchSize[\"--batch_size 8\"]\n        Output[\"--output_path path\"]\n        FewShot[\"--num_fewshot (optional)\"]\n        Limit[\"--limit (optional)\"]\n    end\n    \n    BuildCmd --> Model\n    BuildCmd --> ModelArgs\n    BuildCmd --> Tasks\n    BuildCmd --> Device\n    BuildCmd --> BatchSize\n    BuildCmd --> Output\n    BuildCmd --> FewShot\n    BuildCmd --> Limit",
      "flowchart TD\n    subgraph \"Metrics Collection\"\n        Benchmark[\"Benchmark Metrics\\n- Runtime\\n- Exit codes\"]\n        TaskScores[\"Task Scores\\n- acc/acc_norm by task\"]\n        Summary[\"Summary Metrics\\n- Number of tasks\\n- Window/block info\"]\n    end\n    \n    subgraph \"MetricsLogger\"\n        Log[\"log() method\"]\n        Tags[\"Metric Tags\\n- window\\n- block\\n- global_step\\n- task\"]\n        Fields[\"Metric Fields\\n- scores\\n- runtime\\n- count\"]\n    end\n    \n    subgraph \"Storage\"\n        InfluxDB[\"InfluxDB\\nTime-series database\"]\n    end\n    \n    Benchmark --> Log\n    TaskScores --> Log\n    Summary --> Log\n    \n    Log --> Tags\n    Log --> Fields\n    \n    Log --> InfluxDB"
    ],
    "potential_frontmatter": {
      "title": "Evaluator"
    }
  },
  "/tplr-ai/templar/6-communication-system": {
    "original_deepwiki_href": "/tplr-ai/templar/6-communication-system",
    "title": "Communication System",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/6-communication-system",
    "level": 0,
    "target_astro_path": "/communication-system",
    "main_markdown_content": "# Communication System\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [pyproject.toml](pyproject.toml)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n- [tests/test_comms.py](tests/test_comms.py)\n- [uv.lock](uv.lock)\n\n</details>\n\n\n\nThe Communication System in Templar provides a robust data exchange mechanism for distributed training across the network. It manages gradient sharing, checkpoint synchronization, peer coordination, and storage integration to enable effective communication between miners and validators. This page covers the core communication infrastructure, while related topics such as checkpoint specifics and blockchain integration are covered in [Checkpoint Management](#6.1) and [Chain Integration](#6.2).\n\n## Architecture Overview\n\nThe Communication System is built around the `Comms` class, which serves as a centralized interface for all network communication operations. It inherits from `ChainManager` to integrate with the Bittensor blockchain and leverages Cloudflare R2 storage for data persistence.\n\n```mermaid\ngraph TD\n    subgraph \"Communication System Components\"\n        COMMS[\"Comms Class\"]\n        CHAIN[\"ChainManager\"]\n        R2[\"R2 Storage Integration\"]\n        PEER[\"Peer Management\"]\n        GRAD[\"Gradient Exchange\"]\n        CKPT[\"Checkpoint Handling\"]\n    end\n\n    COMMS -->|\"inherits from\"| CHAIN\n    COMMS -->|\"manages\"| R2\n    COMMS -->|\"provides\"| PEER\n    COMMS -->|\"enables\"| GRAD\n    COMMS -->|\"handles\"| CKPT\n\n    subgraph \"Integration Points\"\n        MINERS[\"Miners\"]\n        VALIDATORS[\"Validators\"]\n        BLOCKCHAIN[\"Bittensor Blockchain\"]\n        STORAGE[\"Cloudflare R2 Storage\"]\n    end\n\n    MINERS -->|\"uses\"| COMMS\n    VALIDATORS -->|\"uses\"| COMMS\n    COMMS -->|\"interacts with\"| BLOCKCHAIN\n    COMMS -->|\"stores/retrieves data\"| STORAGE\n```\n\nSources: [src/tplr/comms.py:64-121](). [neurons/miner.py:174-188](). [neurons/validator.py:208-220]().\n\n## Core Functionality\n\n### Initialization and Configuration\n\nThe `Comms` class is initialized with a wallet, configuration, and references to the network context. It sets up connections to R2 storage buckets and prepares for blockchain interactions.\n\n```mermaid\nflowchart LR\n    subgraph \"Comms Initialization\"\n        INIT[\"__init__()\"]\n        WALLET[\"Wallet Authentication\"]\n        CONFIG[\"Configuration\"]\n        BUCKETS[\"Storage Buckets\"]\n        SESSIONS[\"S3 Sessions\"]\n    end\n\n    INIT -->|\"requires\"| WALLET\n    INIT -->|\"processes\"| CONFIG\n    INIT -->|\"configures\"| BUCKETS\n    INIT -->|\"establishes\"| SESSIONS\n\n    subgraph \"Bucket Types\"\n        GRAD[\"Gradients Bucket\"]\n        DATA[\"Dataset Bucket\"]\n        AGG[\"Aggregator Bucket\"]\n    end\n\n    BUCKETS -->|\"creates\"| GRAD\n    BUCKETS -->|\"creates\"| DATA\n    BUCKETS -->|\"creates\"| AGG\n```\n\nSources: [src/tplr/comms.py:64-121](). [src/tplr/comms.py:174-220]().\n\n### Storage Integration\n\nThe Communication System uses Cloudflare R2 for persistent storage of gradients, model checkpoints, and peer information. It manages connections to different buckets and handles data serialization/deserialization.\n\n| Bucket Type | Purpose | Access Control |\n|-------------|---------|----------------|\n| Gradients | Stores gradient updates from miners | Read/Write separated |\n| Dataset | Contains training datasets | Read-only for most users |\n| Aggregator | Stores aggregated model states | Managed access |\n\nThe system provides efficient methods for large file handling through multipart uploads and downloads.\n\nSources: [src/tplr/comms.py:122-169](). [src/tplr/comms.py:322-389](). [src/tplr/comms.py:476-683]().\n\n### Data Exchange\n\n#### Put Operations\n\n```mermaid\nsequenceDiagram\n    participant Neuron as \"Miner/Validator\"\n    participant Comms as \"Comms\"\n    participant S3 as \"R2 Storage\"\n    participant Chain as \"Bittensor Chain\"\n    \n    Neuron->>Comms: put(state_dict, uid, window, key)\n    Comms->>Comms: Prepare data\n    \n    alt local storage\n        Comms->>Comms: Store locally\n    else remote storage\n        Comms->>S3: s3_put_object(key, file_path)\n        alt large file\n            S3->>S3: upload_large_file()\n        end\n    end\n    \n    Comms->>Chain: try_commit(wallet, bucket)\n    Comms->>Neuron: Return completion timestamp\n```\n\nSources: [src/tplr/comms.py:322-371](). [src/tplr/comms.py:476-573](). [neurons/miner.py:417-435]().\n\n#### Get Operations\n\n```mermaid\nsequenceDiagram\n    participant Neuron as \"Miner/Validator\"\n    participant Comms as \"Comms\"\n    participant S3 as \"R2 Storage\"\n    \n    Neuron->>Comms: get(uid, window, key)\n    \n    alt local retrieval\n        Comms->>Comms: Load from local storage\n    else remote retrieval\n        Comms->>S3: s3_get_object(key, bucket)\n        alt large file\n            S3->>S3: download_large_file()\n        end\n        S3->>Comms: Return data\n    end\n    \n    Comms->>Comms: Process data (deserialize)\n    Comms->>Neuron: Return state_dict, global_step\n```\n\nSources: [src/tplr/comms.py:372-474](). [src/tplr/comms.py:574-683]().\n\n### Gradient Gathering\n\nThe gradient gathering process is central to Templar's distributed training approach. Validators collect gradient updates from multiple miners, normalize them, and apply them to update their models.\n\n```mermaid\nflowchart TD\n    subgraph \"Gather Process\"\n        GATHER[\"gather()\"]\n        FETCH[\"Fetch peer gradients\"]\n        NORMALIZE[\"Normalize gradients\"]\n        AGGREGATE[\"Aggregate results\"]\n        SKIPPED[\"Track skipped UIDs\"]\n    end\n\n    GATHER -->|\"1. initiates\"| FETCH\n    FETCH -->|\"2. processes\"| NORMALIZE\n    NORMALIZE -->|\"3. combines\"| AGGREGATE\n    FETCH -->|\"4. records failures\"| SKIPPED\n    AGGREGATE -->|\"5. includes\"| SKIPPED\n\n    subgraph \"Time Management\"\n        TIME_WINDOW[\"Time window filtering\"]\n        TIME_CHECK[\"Check data timestamp\"]\n        TOO_EARLY[\"Reject too early\"]\n        TOO_LATE[\"Reject too late\"]\n    end\n\n    FETCH -->|\"applies\"| TIME_WINDOW\n    TIME_WINDOW -->|\"performs\"| TIME_CHECK\n    TIME_CHECK -->|\"may flag\"| TOO_EARLY\n    TIME_CHECK -->|\"may flag\"| TOO_LATE\n```\n\nSources: [src/tplr/comms.py:684-1118](). [neurons/validator.py:827-846](). [neurons/miner.py:489-501]().\n\n## Peer Management\n\nThe Communication System incorporates sophisticated peer management to ensure efficient and fair participation in the training process.\n\n### Peer Selection and Tracking\n\n```mermaid\nflowchart LR\n    subgraph \"Peer Management\"\n        TRACK[\"track_active_peers()\"]\n        UPDATE[\"update_peers_with_buckets()\"]\n        ACTIVE[\"active_peers set\"]\n        EVAL[\"eval_peers\"]\n        INACTIVE[\"inactive_peers\"]\n    end\n\n    TRACK -->|\"continuously updates\"| ACTIVE\n    UPDATE -->|\"refreshes\"| EVAL\n    UPDATE -->|\"identifies\"| INACTIVE\n\n    subgraph \"Peer Selection Criteria\"\n        BUCKETS[\"Has valid bucket\"]\n        COMMITMENT[\"Has chain commitment\"]\n        RECENT[\"Recently active\"]\n        PERFORMANCE[\"Performance rating\"]\n    end\n\n    BUCKETS -->|\"contributes to\"| EVAL\n    COMMITMENT -->|\"contributes to\"| EVAL\n    RECENT -->|\"contributes to\"| EVAL\n    PERFORMANCE -->|\"affects\"| EVAL\n```\n\nSources: [src/tplr/comms.py:1228-1386](). [neurons/validator.py:695-704](). [neurons/miner.py:477-485]().\n\n### Peer List Management\n\nThe system manages peer lists to coordinate which nodes should communicate with each other during different training windows.\n\n| Method | Purpose | \n|--------|---------|\n| `post_peer_list` | Publishes a list of selected peers for a future window |\n| `get_peer_list` | Retrieves the peer list for the current window |\n| `update_peers_with_buckets` | Refreshes peer information with storage access |\n\nSources: [src/tplr/comms.py:1228-1336](). [neurons/validator.py:678-686]().\n\n## Checkpoint Management\n\nThe Communication System provides mechanisms for saving and loading model checkpoints to enable consistent model state across the network.\n\n```mermaid\nflowchart TD\n    subgraph \"Checkpoint Operations\"\n        SAVE[\"save_checkpoint()\"]\n        LOAD[\"load_checkpoint()\"]\n        GET_LATEST[\"get_latest_checkpoint()\"]\n    end\n\n    SAVE -->|\"stores model state\"| R2[\"R2 Storage\"]\n    LOAD -->|\"requests from\"| GET_LATEST\n    GET_LATEST -->|\"retrieves from\"| R2\n\n    subgraph \"Checkpoint Components\"\n        MODEL[\"Model state_dict\"]\n        OPT[\"Optimizer state\"]\n        SCHED[\"Scheduler state\"]\n        MOM[\"Momentum buffer\"]\n        META[\"Metadata (window, step)\"]\n    end\n\n    SAVE -->|\"includes\"| MODEL\n    SAVE -->|\"includes\"| OPT\n    SAVE -->|\"includes\"| SCHED\n    SAVE -->|\"includes\"| MOM\n    SAVE -->|\"includes\"| META\n```\n\nSources: [src/tplr/comms.py:1489-1566](). [src/tplr/comms.py:1567-1677](). [neurons/miner.py:727-747](). [neurons/validator.py:582-602]().\n\n## Error Handling and Resilience\n\nThe Communication System incorporates several mechanisms to ensure reliable operation in a distributed environment:\n\n1. **Retry Logic**: Automatic retries for network operations with exponential backoff\n2. **Client Reconnection**: Purging and recreation of S3 clients when connection issues occur\n3. **Stale Data Cleanup**: Regular removal of outdated data from both local and remote storage\n4. **Timeout Handling**: Graceful handling of operations that exceed time limits\n5. **Concurrency Control**: Semaphores to limit the number of concurrent operations\n\nSources: [src/tplr/comms.py:366-371](). [src/tplr/comms.py:484-497](). [src/tplr/comms.py:237-258]().\n\n## Integration with Neurons\n\nBoth miners and validators integrate with the Communication System to participate in the distributed training process.\n\n### Miner Integration\n\nMiners use the Communication System to:\n- Retrieve model checkpoints to align with the network state\n- Upload their own gradient updates\n- Gather peer gradients to update their models\n- Share debug information and metrics\n\n```python\n# Miner initialization of Comms\nself.comms = tplr.comms.Comms(\n    wallet=self.wallet,\n    save_location=\"/tmp\",\n    key_prefix=\"model\",\n    config=self.config,\n    netuid=self.config.netuid,\n    metagraph=self.metagraph,\n    hparams=self.hparams,\n    uid=self.uid,\n)\n```\n\nSources: [neurons/miner.py:174-188](). [neurons/miner.py:417-435](). [neurons/miner.py:489-501]().\n\n### Validator Integration\n\nValidators use the Communication System to:\n- Maintain the latest model state via checkpoints\n- Gather gradients from miners for evaluation\n- Post peer lists to coordinate network communication\n- Commit storage information to the blockchain\n\n```python\n# Validator gradient gathering\ngather_result = await self.comms.gather(\n    my_uid=self.uid,\n    uids=self.comms.peers,\n    window=self.sync_window,\n    key=\"gradient\",\n    timeout=35,\n    device=self.config.device,\n    local=False,\n    totalks=self.totalks,\n    time_min=time_min,\n    time_max=time_max,\n)\n```\n\nSources: [neurons/validator.py:208-220](). [neurons/validator.py:678-686](). [neurons/validator.py:827-846]().\n\n## Performance Considerations\n\nThe Communication System is designed for efficiency in a distributed environment:\n\n1. **Chunked Transfers**: Large files are processed in manageable chunks\n2. **Resource Optimization**: Adaptive resource allocation based on available CPU/GPU\n3. **Persistent Connections**: S3 clients are reused to avoid connection overhead\n4. **Concurrent Operations**: Parallel processing of multiple data transfers\n5. **Time Window Filtering**: Implements temporal boundaries for data relevance\n\nSources: [src/tplr/comms.py:476-573](). [src/tplr/comms.py:574-683](). [src/tplr/comms.py:122-147]().\n\n## Configuration\n\nThe Communication System is configured through:\n\n1. **Environment Variables**: R2 credentials and bucket information\n2. **Hyperparameters**: Network settings from the hparams configuration\n3. **Runtime Parameters**: Passed during neuron initialization\n\nKey configuration parameters include:\n\n| Parameter | Purpose | Source |\n|-----------|---------|--------|\n| `active_check_interval` | Frequency for checking peer activity | hparams.json |\n| `recent_windows` | Number of windows to check for activity | hparams.json |\n| `peer_replacement_frequency` | How often to update peer lists | hparams.json |\n| `time_window_delta_seconds` | Temporal boundary for data relevance | hparams.json |\n\nSources: [src/tplr/comms.py:64-121](). [hparams.json:38-46]().\n\n## Summary\n\nThe Communication System is a fundamental component of Templar that enables decentralized training by facilitating efficient data exchange between miners and validators. Through integration with Cloudflare R2 storage and the Bittensor blockchain, it provides a reliable infrastructure for gradient sharing, checkpoint synchronization, and peer coordination.",
    "resolved_links": [
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "pyproject.toml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/pyproject.toml",
        "original_deepwiki_href": "pyproject.toml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_comms.py",
        "original_deepwiki_href": "tests/test_comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "uv.lock",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/uv.lock",
        "original_deepwiki_href": "uv.lock",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py:64-121",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:174-188",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:208-220",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:174-220",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:122-169",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:322-389",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:476-683",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:322-371",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:476-573",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:417-435",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:372-474",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:574-683",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:684-1118",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:827-846",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:489-501",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:1228-1386",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:695-704",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:477-485",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:1228-1336",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:678-686",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:1489-1566",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:1567-1677",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:727-747",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:582-602",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:366-371",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:484-497",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:237-258",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:122-147",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:38-46",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Checkpoint Management",
        "href": "/communication-system/checkpoint-management#6.1",
        "original_deepwiki_href": "#6.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Chain Integration",
        "href": "/communication-system/chain-integration#6.2",
        "original_deepwiki_href": "#6.2",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Communication System Components\"\n        COMMS[\"Comms Class\"]\n        CHAIN[\"ChainManager\"]\n        R2[\"R2 Storage Integration\"]\n        PEER[\"Peer Management\"]\n        GRAD[\"Gradient Exchange\"]\n        CKPT[\"Checkpoint Handling\"]\n    end\n\n    COMMS -->|\"inherits from\"| CHAIN\n    COMMS -->|\"manages\"| R2\n    COMMS -->|\"provides\"| PEER\n    COMMS -->|\"enables\"| GRAD\n    COMMS -->|\"handles\"| CKPT\n\n    subgraph \"Integration Points\"\n        MINERS[\"Miners\"]\n        VALIDATORS[\"Validators\"]\n        BLOCKCHAIN[\"Bittensor Blockchain\"]\n        STORAGE[\"Cloudflare R2 Storage\"]\n    end\n\n    MINERS -->|\"uses\"| COMMS\n    VALIDATORS -->|\"uses\"| COMMS\n    COMMS -->|\"interacts with\"| BLOCKCHAIN\n    COMMS -->|\"stores/retrieves data\"| STORAGE",
      "flowchart LR\n    subgraph \"Comms Initialization\"\n        INIT[\"__init__()\"]\n        WALLET[\"Wallet Authentication\"]\n        CONFIG[\"Configuration\"]\n        BUCKETS[\"Storage Buckets\"]\n        SESSIONS[\"S3 Sessions\"]\n    end\n\n    INIT -->|\"requires\"| WALLET\n    INIT -->|\"processes\"| CONFIG\n    INIT -->|\"configures\"| BUCKETS\n    INIT -->|\"establishes\"| SESSIONS\n\n    subgraph \"Bucket Types\"\n        GRAD[\"Gradients Bucket\"]\n        DATA[\"Dataset Bucket\"]\n        AGG[\"Aggregator Bucket\"]\n    end\n\n    BUCKETS -->|\"creates\"| GRAD\n    BUCKETS -->|\"creates\"| DATA\n    BUCKETS -->|\"creates\"| AGG",
      "sequenceDiagram\n    participant Neuron as \"Miner/Validator\"\n    participant Comms as \"Comms\"\n    participant S3 as \"R2 Storage\"\n    participant Chain as \"Bittensor Chain\"\n    \n    Neuron->>Comms: put(state_dict, uid, window, key)\n    Comms->>Comms: Prepare data\n    \n    alt local storage\n        Comms->>Comms: Store locally\n    else remote storage\n        Comms->>S3: s3_put_object(key, file_path)\n        alt large file\n            S3->>S3: upload_large_file()\n        end\n    end\n    \n    Comms->>Chain: try_commit(wallet, bucket)\n    Comms->>Neuron: Return completion timestamp",
      "sequenceDiagram\n    participant Neuron as \"Miner/Validator\"\n    participant Comms as \"Comms\"\n    participant S3 as \"R2 Storage\"\n    \n    Neuron->>Comms: get(uid, window, key)\n    \n    alt local retrieval\n        Comms->>Comms: Load from local storage\n    else remote retrieval\n        Comms->>S3: s3_get_object(key, bucket)\n        alt large file\n            S3->>S3: download_large_file()\n        end\n        S3->>Comms: Return data\n    end\n    \n    Comms->>Comms: Process data (deserialize)\n    Comms->>Neuron: Return state_dict, global_step",
      "flowchart TD\n    subgraph \"Gather Process\"\n        GATHER[\"gather()\"]\n        FETCH[\"Fetch peer gradients\"]\n        NORMALIZE[\"Normalize gradients\"]\n        AGGREGATE[\"Aggregate results\"]\n        SKIPPED[\"Track skipped UIDs\"]\n    end\n\n    GATHER -->|\"1. initiates\"| FETCH\n    FETCH -->|\"2. processes\"| NORMALIZE\n    NORMALIZE -->|\"3. combines\"| AGGREGATE\n    FETCH -->|\"4. records failures\"| SKIPPED\n    AGGREGATE -->|\"5. includes\"| SKIPPED\n\n    subgraph \"Time Management\"\n        TIME_WINDOW[\"Time window filtering\"]\n        TIME_CHECK[\"Check data timestamp\"]\n        TOO_EARLY[\"Reject too early\"]\n        TOO_LATE[\"Reject too late\"]\n    end\n\n    FETCH -->|\"applies\"| TIME_WINDOW\n    TIME_WINDOW -->|\"performs\"| TIME_CHECK\n    TIME_CHECK -->|\"may flag\"| TOO_EARLY\n    TIME_CHECK -->|\"may flag\"| TOO_LATE",
      "flowchart LR\n    subgraph \"Peer Management\"\n        TRACK[\"track_active_peers()\"]\n        UPDATE[\"update_peers_with_buckets()\"]\n        ACTIVE[\"active_peers set\"]\n        EVAL[\"eval_peers\"]\n        INACTIVE[\"inactive_peers\"]\n    end\n\n    TRACK -->|\"continuously updates\"| ACTIVE\n    UPDATE -->|\"refreshes\"| EVAL\n    UPDATE -->|\"identifies\"| INACTIVE\n\n    subgraph \"Peer Selection Criteria\"\n        BUCKETS[\"Has valid bucket\"]\n        COMMITMENT[\"Has chain commitment\"]\n        RECENT[\"Recently active\"]\n        PERFORMANCE[\"Performance rating\"]\n    end\n\n    BUCKETS -->|\"contributes to\"| EVAL\n    COMMITMENT -->|\"contributes to\"| EVAL\n    RECENT -->|\"contributes to\"| EVAL\n    PERFORMANCE -->|\"affects\"| EVAL",
      "flowchart TD\n    subgraph \"Checkpoint Operations\"\n        SAVE[\"save_checkpoint()\"]\n        LOAD[\"load_checkpoint()\"]\n        GET_LATEST[\"get_latest_checkpoint()\"]\n    end\n\n    SAVE -->|\"stores model state\"| R2[\"R2 Storage\"]\n    LOAD -->|\"requests from\"| GET_LATEST\n    GET_LATEST -->|\"retrieves from\"| R2\n\n    subgraph \"Checkpoint Components\"\n        MODEL[\"Model state_dict\"]\n        OPT[\"Optimizer state\"]\n        SCHED[\"Scheduler state\"]\n        MOM[\"Momentum buffer\"]\n        META[\"Metadata (window, step)\"]\n    end\n\n    SAVE -->|\"includes\"| MODEL\n    SAVE -->|\"includes\"| OPT\n    SAVE -->|\"includes\"| SCHED\n    SAVE -->|\"includes\"| MOM\n    SAVE -->|\"includes\"| META"
    ],
    "potential_frontmatter": {
      "title": "Communication System"
    }
  },
  "/tplr-ai/templar/6.1-checkpoint-management": {
    "original_deepwiki_href": "/tplr-ai/templar/6.1-checkpoint-management",
    "title": "Checkpoint Management",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/6.1-checkpoint-management",
    "level": 1,
    "target_astro_path": "/communication-system/checkpoint-management",
    "main_markdown_content": "# Checkpoint Management\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [pyproject.toml](pyproject.toml)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n- [tests/test_checkpoints.py](tests/test_checkpoints.py)\n- [tests/test_comms.py](tests/test_comms.py)\n- [tests/test_evaluator.py](tests/test_evaluator.py)\n- [tests/test_prepare_gradient_dict.py](tests/test_prepare_gradient_dict.py)\n- [uv.lock](uv.lock)\n\n</details>\n\n\n\n## Purpose and Scope\n\nThis page documents the checkpoint management system in Templar, which is responsible for saving and loading model states, optimizers, schedulers, and momentum values during distributed training. This system is crucial for ensuring training resilience, enabling nodes to recover from failures, synchronize with the network, and resume training from previous states. For information about how checkpoint management interacts with blockchain commitments, see [Chain Integration](#6.2).\n\n## Checkpoint Structure and Contents\n\nA Templar checkpoint contains all the state information needed to fully restore training:\n\n```mermaid\nclassDiagram\n    class Checkpoint {\n        +Dict \"model_state_dict\"\n        +Dict \"optimizer_state_dict\"\n        +Dict \"scheduler_state_dict\"\n        +Dict \"momentum\"\n        +Int \"start_window\"\n        +Int \"current_window\"\n    }\n    \n    class ModelState {\n        +Tensor \"weight_tensors\"\n        +Tensor \"bias_tensors\"\n    }\n    \n    class OptimizerState {\n        +Dict \"state\"\n        +List \"param_groups\"\n    }\n    \n    class SchedulerState {\n        +Int \"last_epoch\"\n        +Float \"base_lrs\"\n    }\n    \n    class Momentum {\n        +Tensor \"param_momentum_tensors\"\n    }\n    \n    Checkpoint --> ModelState : \"contains\"\n    Checkpoint --> OptimizerState : \"contains\"\n    Checkpoint --> SchedulerState : \"contains\"\n    Checkpoint --> Momentum : \"contains\"\n```\n\nSources: [neurons/miner.py:265-282](neurons/miner.py:265-282), [tests/test_checkpoints.py:40-54](tests/test_checkpoints.py:40-54)\n\nEach component serves a specific purpose:\n\n| Component | Description |\n|-----------|-------------|\n| `model_state_dict` | Parameter tensors for the LLaMA model |\n| `optimizer_state_dict` | SGD optimizer state (step counts, parameter-specific states) |\n| `scheduler_state_dict` | Learning rate scheduler state (current epoch, base learning rates) |\n| `momentum` | Momentum tensors for gradient accumulation |\n| `start_window` | Training start window (for global step calculation) |\n| `current_window` | Window at which the checkpoint was saved |\n\nAll tensors in checkpoints are stored on CPU to ensure compatibility when loading across different devices.\n\nSources: [src/tplr/comms.py:924-937](src/tplr/comms.py:924-937)\n\n## Storage System\n\nTemplar uses Cloudflare R2 Storage as the primary checkpoint repository, with local filesystem caching for performance.\n\n```mermaid\ngraph TD\n    subgraph \"Storage\"\n        R2[\"Cloudflare R2 Storage\"]\n        Local[\"Local Cache (/tmp)\"]\n    end\n    \n    subgraph \"Comms.Checkpoint Methods\"\n        Save[\"save_checkpoint()\"]\n        Load[\"load_checkpoint()\"]\n        GetLatest[\"get_latest_checkpoint()\"]\n    end\n    \n    subgraph \"Neurons\"\n        Miner[\"Miner\"]\n        Validator[\"Validator\"]\n    end\n    \n    Miner -->|\"triggers save/load\"| Save\n    Validator -->|\"triggers save/load\"| Load\n    \n    Save -->|\"writes to\"| R2\n    Save -->|\"caches to\"| Local\n    Load -->|\"requests\"| GetLatest\n    GetLatest -->|\"queries\"| R2\n    GetLatest -->|\"falls back to\"| Local\n```\n\nSources: [src/tplr/comms.py:122-148](src/tplr/comms.py:122-148), [neurons/miner.py:730-747](neurons/miner.py:730-747), [neurons/validator.py:582-613](neurons/validator.py:582-613)\n\n### Checkpoint File Naming\n\nCheckpoint files follow this naming convention:\n```\ncheckpoint-{global_step}-{uid}-v{version}.pt\n```\n\nWhere:\n- `global_step`: Training step at which the checkpoint was saved\n- `uid`: Unique identifier of the node that created the checkpoint\n- `version`: Code version (from `tplr.__version__`)\n\nThis convention enables efficient filtering and retrieval of checkpoints by version, step, or node.\n\nSources: [tests/test_checkpoints.py:83-87](tests/test_checkpoints.py:83-87)\n\n## Checkpoint Operations\n\n### Saving Checkpoints\n\nCheckpoints are saved periodically during training based on the `checkpoint_frequency` parameter in `hparams.json`.\n\n```mermaid\nsequenceDiagram\n    participant Neuron as \"Miner/Validator\"\n    participant Comms as \"Comms\"\n    participant R2 as \"R2 Storage\"\n    \n    Note over Neuron: \"Check if global_step % checkpoint_frequency == 0\"\n    \n    Neuron->>Comms: \"save_checkpoint(model, optimizer, scheduler, momentum, ...)\"\n    Comms->>Comms: \"Create checkpoint dictionary\"\n    Comms->>Comms: \"Move all tensors to CPU\"\n    Comms->>R2: \"Upload checkpoint to R2 bucket\"\n    R2-->>Comms: \"Upload confirmation\"\n    Comms-->>Neuron: \"Checkpoint saved\"\n```\n\nThe checkpoint saving process:\n\n1. Creates a checkpoint dictionary containing all state components\n2. Ensures all tensors are moved to CPU for compatibility\n3. Saves the checkpoint to R2 storage with versioning information\n4. Handles large file uploads using multipart upload when necessary\n\nSources: [neurons/miner.py:730-747](neurons/miner.py:730-747), [src/tplr/comms.py:894-949](src/tplr/comms.py:894-949)\n\n### Loading Checkpoints\n\nLoading checkpoints is performed at node startup and involves several steps:\n\n```mermaid\nsequenceDiagram\n    participant Neuron as \"Miner/Validator\"\n    participant Comms as \"Comms\"\n    participant R2 as \"R2 Storage\"\n    \n    Neuron->>Comms: \"load_checkpoint(model, optimizer, scheduler, ...)\"\n    Comms->>R2: \"Get latest checkpoint\"\n    R2-->>Comms: \"Return checkpoint data\"\n    \n    Comms->>Comms: \"Move tensors to target device\"\n    Comms->>Comms: \"Restore model state\"\n    Comms->>Comms: \"Restore optimizer state\"\n    Comms->>Comms: \"Restore scheduler state\"\n    \n    Comms->>Comms: \"Calculate window difference\"\n    \n    alt \"Catch-up needed\"\n        Comms->>Comms: \"Apply catch-up updates\"\n    end\n    \n    Comms-->>Neuron: \"Return (success, momentum, loaded_checkpoint_window, optimizer, scheduler)\"\n```\n\nThe checkpoint loading process:\n\n1. Retrieves the latest compatible checkpoint from R2 storage\n2. Moves tensors to the appropriate device (CPU, CUDA)\n3. Restores model, optimizer, and scheduler states\n4. Determines if catch-up is needed\n5. Applies catch-up updates if necessary\n\nSources: [neurons/miner.py:273-316](neurons/miner.py:273-316), [neurons/validator.py:582-613](neurons/validator.py:582-613), [src/tplr/comms.py:955-1073](src/tplr/comms.py:955-1073)\n\n### Catch-up Mechanism\n\nThe catch-up mechanism brings models up-to-date when loading checkpoints from earlier windows:\n\n```mermaid\ngraph TD\n    LC[\"load_checkpoint()\"] --> CW[\"Calculate window_difference = current_window - checkpoint_window\"]\n    \n    subgraph \"Catch-up Process\"\n        BC[\"Batch windows into manageable chunks\"]\n        AO[\"Apply optimizer steps for each missing window\"]\n        AS[\"Apply scheduler steps for each missing window\"]\n        UG[\"Update global_step\"]\n    end\n    \n    CW -->|\"if window_difference > 0\"| BC\n    BC --> AO\n    AO --> AS\n    AS --> UG\n```\n\nThis ensures learning rates and optimizer states match current training progress when loading an older checkpoint.\n\nSources: [neurons/miner.py:300-316](neurons/miner.py:300-316), [tests/test_checkpoints.py:472-543](tests/test_checkpoints.py:472-543)\n\n## Version Management\n\nTemplar's checkpoint system handles version compatibility through:\n\n1. Version-specific checkpoint files (`v{version}.pt` suffix)\n2. Bootstrap version configuration (`checkpoint_init_version` in hparams.json)\n3. Fallback to local cache when compatible R2 versions are unavailable\n\nDuring startup, miners and validators will attempt to load the latest checkpoint matching their current version. For initial setup, they use the configured bootstrap version.\n\nSources: [neurons/miner.py:167-168](neurons/miner.py:167-168), [neurons/validator.py:201-205](neurons/validator.py:201-205), [hparams.json:52](hparams.json:52)\n\n## Configuration\n\nThe checkpoint system is configured through hyperparameters:\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `checkpoint_frequency` | How often to save checkpoints (in global steps) | 100 |\n| `checkpoint_init_version` | Version to use for initial checkpoint loading | \"0.2.73\" |\n\nSources: [hparams.json:31-52](hparams.json:31-52)\n\n## Implementation Details\n\n### Key Methods\n\nThe checkpoint management system is implemented in the `Comms` class with these core methods:\n\n```mermaid\nclassDiagram\n    class Comms {\n        +async \"save_checkpoint(model, optimizer, scheduler, momentum, global_step, current_window, start_window)\"\n        +async \"load_checkpoint(model, optimizer, scheduler, current_window, device, init_version)\"\n        +async \"get_latest_checkpoint(version)\"\n        -async \"s3_put_object(key, file_path)\"\n        -async \"s3_get_object(key, bucket, timeout)\"\n        -async \"upload_large_file(file_path, key, s3_client)\"\n        -async \"download_large_file(s3_client, bucket, key, file_size, temp_file_path)\"\n    }\n```\n\nThe system handles multiple file sizes with specialized methods for large file transfers, properly managing asynchronous I/O operations.\n\nSources: [src/tplr/comms.py:894-1073](src/tplr/comms.py:894-1073)\n\n### Error Handling\n\nThe checkpoint system includes robust error handling for:\n\n- Network failures during upload/download operations\n- Corrupted checkpoint files\n- Version incompatibilities\n- Missing checkpoint files\n\nIt implements:\n- Retry logic with exponential backoff\n- Local cache fallback\n- Detailed error logging\n- Graceful failure modes that won't crash the application\n\nSources: [src/tplr/comms.py:366-371](src/tplr/comms.py:366-371), [src/tplr/comms.py:423-427](src/tplr/comms.py:423-427)\n\n## Usage Patterns\n\n### In Miner Nodes\n\n```mermaid\ngraph TD\n    MS[\"Miner.run()\"] --> LC[\"Load latest checkpoint\"]\n    LC -->|\"Success\"| UC[\"Catch up if needed\"]\n    LC -->|\"Failure\"| IM[\"Initialize from scratch\"]\n    UC --> TR[\"Train for current window\"]\n    IM --> TR\n    TR --> CF[\"Check if global_step % checkpoint_frequency == 0\"]\n    CF -->|\"Yes\"| SC[\"Save checkpoint\"]\n    CF -->|\"No\"| NW[\"Wait for next window\"]\n    SC --> NW\n    NW --> TR\n```\n\nSources: [neurons/miner.py:267-317](neurons/miner.py:267-317), [neurons/miner.py:730-747](neurons/miner.py:730-747)\n\n### In Validator Nodes\n\n```mermaid\ngraph TD\n    VS[\"Validator.run()\"] --> LC[\"Load latest checkpoint\"]\n    LC -->|\"Success\"| UC[\"Catch up if needed\"]\n    LC -->|\"Failure\"| IM[\"Initialize from scratch\"]\n    UC --> AG[\"Aggregate/evaluate gradients\"]\n    IM --> AG\n    AG --> CF[\"Check if global_step % checkpoint_frequency == 0\"]\n    CF -->|\"Yes\"| SC[\"Save checkpoint\"]\n    CF -->|\"No\"| NW[\"Process next window\"]\n    SC --> NW\n    NW --> AG\n```\n\nSources: [neurons/validator.py:576-620](neurons/validator.py:576-620), [neurons/validator.py:729-735](neurons/validator.py:729-735)\n\n## Evaluator Integration\n\nThe Evaluator service uses the checkpoint system to periodically load the latest model checkpoints and evaluate their performance on benchmarks. It maintains a record of the last evaluated window to prevent duplicate evaluations.\n\n```mermaid\ngraph TD\n    ES[\"Evaluator Service\"] --> GLC[\"get_latest_checkpoint()\"]\n    GLC --> CW[\"Compare checkpoint window to last_eval_window\"]\n    CW -->|\"window > last_eval_window\"| LC[\"Load checkpoint\"]\n    LC --> EM[\"Evaluate model performance\"]\n    EM --> UL[\"Update last_eval_window\"]\n    CW -->|\"window <= last_eval_window\"| SK[\"Skip (already evaluated)\"]\n```\n\nSources: [tests/test_evaluator.py:60-146](tests/test_evaluator.py:60-146)\n\n## Troubleshooting\n\nCommon checkpoint-related issues and solutions:\n\n| Issue | Possible Causes | Solution |\n|-------|----------------|----------|\n| Checkpoint loading fails | Version mismatch, corrupted file | Check version compatibility, verify R2 access |\n| Catch-up process errors | Large window gap, memory issues | Reduce catch-up batch size, ensure sufficient memory |\n| Slow checkpoint saving | Large model size, network issues | Check network connectivity, monitor R2 performance |\n| Missing checkpoint | Process started for first time | Node will initialize from scratch |\n\nSources: [src/tplr/comms.py:423-427](src/tplr/comms.py:423-427), [neurons/miner.py:305-316](neurons/miner.py:305-316)\n\n## Summary\n\nThe checkpoint management system is a critical component of Templar that ensures training resilience and continuity. By periodically saving complete training state and providing efficient loading mechanisms, it enables nodes to recover from failures, sync with the network, and maintain training progress in a distributed environment.\n\nThrough careful version management and the catch-up mechanism, the system ensures that nodes can join or rejoin training seamlessly, maintaining the integrity of the distributed training process.",
    "resolved_links": [
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "pyproject.toml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/pyproject.toml",
        "original_deepwiki_href": "pyproject.toml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_checkpoints.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_checkpoints.py",
        "original_deepwiki_href": "tests/test_checkpoints.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_comms.py",
        "original_deepwiki_href": "tests/test_comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_evaluator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_evaluator.py",
        "original_deepwiki_href": "tests/test_evaluator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_prepare_gradient_dict.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_prepare_gradient_dict.py",
        "original_deepwiki_href": "tests/test_prepare_gradient_dict.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "uv.lock",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/uv.lock",
        "original_deepwiki_href": "uv.lock",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py:265-282",
        "href": "",
        "original_deepwiki_href": "neurons/miner.py:265-282",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_checkpoints.py:40-54",
        "href": "",
        "original_deepwiki_href": "tests/test_checkpoints.py:40-54",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:924-937",
        "href": "",
        "original_deepwiki_href": "src/tplr/comms.py:924-937",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:122-148",
        "href": "",
        "original_deepwiki_href": "src/tplr/comms.py:122-148",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:730-747",
        "href": "",
        "original_deepwiki_href": "neurons/miner.py:730-747",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:582-613",
        "href": "",
        "original_deepwiki_href": "neurons/validator.py:582-613",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_checkpoints.py:83-87",
        "href": "",
        "original_deepwiki_href": "tests/test_checkpoints.py:83-87",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:894-949",
        "href": "",
        "original_deepwiki_href": "src/tplr/comms.py:894-949",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:273-316",
        "href": "",
        "original_deepwiki_href": "neurons/miner.py:273-316",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:955-1073",
        "href": "",
        "original_deepwiki_href": "src/tplr/comms.py:955-1073",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:300-316",
        "href": "",
        "original_deepwiki_href": "neurons/miner.py:300-316",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_checkpoints.py:472-543",
        "href": "",
        "original_deepwiki_href": "tests/test_checkpoints.py:472-543",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:167-168",
        "href": "",
        "original_deepwiki_href": "neurons/miner.py:167-168",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:201-205",
        "href": "",
        "original_deepwiki_href": "neurons/validator.py:201-205",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:52",
        "href": "",
        "original_deepwiki_href": "hparams.json:52",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:31-52",
        "href": "",
        "original_deepwiki_href": "hparams.json:31-52",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:894-1073",
        "href": "",
        "original_deepwiki_href": "src/tplr/comms.py:894-1073",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:366-371",
        "href": "",
        "original_deepwiki_href": "src/tplr/comms.py:366-371",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:423-427",
        "href": "",
        "original_deepwiki_href": "src/tplr/comms.py:423-427",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:267-317",
        "href": "",
        "original_deepwiki_href": "neurons/miner.py:267-317",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:576-620",
        "href": "",
        "original_deepwiki_href": "neurons/validator.py:576-620",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:729-735",
        "href": "",
        "original_deepwiki_href": "neurons/validator.py:729-735",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_evaluator.py:60-146",
        "href": "",
        "original_deepwiki_href": "tests/test_evaluator.py:60-146",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:305-316",
        "href": "",
        "original_deepwiki_href": "neurons/miner.py:305-316",
        "context": "inline_source_link"
      },
      {
        "text": "Chain Integration",
        "href": "/communication-system/chain-integration#6.2",
        "original_deepwiki_href": "#6.2",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "classDiagram\n    class Checkpoint {\n        +Dict \"model_state_dict\"\n        +Dict \"optimizer_state_dict\"\n        +Dict \"scheduler_state_dict\"\n        +Dict \"momentum\"\n        +Int \"start_window\"\n        +Int \"current_window\"\n    }\n    \n    class ModelState {\n        +Tensor \"weight_tensors\"\n        +Tensor \"bias_tensors\"\n    }\n    \n    class OptimizerState {\n        +Dict \"state\"\n        +List \"param_groups\"\n    }\n    \n    class SchedulerState {\n        +Int \"last_epoch\"\n        +Float \"base_lrs\"\n    }\n    \n    class Momentum {\n        +Tensor \"param_momentum_tensors\"\n    }\n    \n    Checkpoint --> ModelState : \"contains\"\n    Checkpoint --> OptimizerState : \"contains\"\n    Checkpoint --> SchedulerState : \"contains\"\n    Checkpoint --> Momentum : \"contains\"",
      "graph TD\n    subgraph \"Storage\"\n        R2[\"Cloudflare R2 Storage\"]\n        Local[\"Local Cache (/tmp)\"]\n    end\n    \n    subgraph \"Comms.Checkpoint Methods\"\n        Save[\"save_checkpoint()\"]\n        Load[\"load_checkpoint()\"]\n        GetLatest[\"get_latest_checkpoint()\"]\n    end\n    \n    subgraph \"Neurons\"\n        Miner[\"Miner\"]\n        Validator[\"Validator\"]\n    end\n    \n    Miner -->|\"triggers save/load\"| Save\n    Validator -->|\"triggers save/load\"| Load\n    \n    Save -->|\"writes to\"| R2\n    Save -->|\"caches to\"| Local\n    Load -->|\"requests\"| GetLatest\n    GetLatest -->|\"queries\"| R2\n    GetLatest -->|\"falls back to\"| Local",
      "sequenceDiagram\n    participant Neuron as \"Miner/Validator\"\n    participant Comms as \"Comms\"\n    participant R2 as \"R2 Storage\"\n    \n    Note over Neuron: \"Check if global_step % checkpoint_frequency == 0\"\n    \n    Neuron->>Comms: \"save_checkpoint(model, optimizer, scheduler, momentum, ...)\"\n    Comms->>Comms: \"Create checkpoint dictionary\"\n    Comms->>Comms: \"Move all tensors to CPU\"\n    Comms->>R2: \"Upload checkpoint to R2 bucket\"\n    R2-->>Comms: \"Upload confirmation\"\n    Comms-->>Neuron: \"Checkpoint saved\"",
      "sequenceDiagram\n    participant Neuron as \"Miner/Validator\"\n    participant Comms as \"Comms\"\n    participant R2 as \"R2 Storage\"\n    \n    Neuron->>Comms: \"load_checkpoint(model, optimizer, scheduler, ...)\"\n    Comms->>R2: \"Get latest checkpoint\"\n    R2-->>Comms: \"Return checkpoint data\"\n    \n    Comms->>Comms: \"Move tensors to target device\"\n    Comms->>Comms: \"Restore model state\"\n    Comms->>Comms: \"Restore optimizer state\"\n    Comms->>Comms: \"Restore scheduler state\"\n    \n    Comms->>Comms: \"Calculate window difference\"\n    \n    alt \"Catch-up needed\"\n        Comms->>Comms: \"Apply catch-up updates\"\n    end\n    \n    Comms-->>Neuron: \"Return (success, momentum, loaded_checkpoint_window, optimizer, scheduler)\"",
      "graph TD\n    LC[\"load_checkpoint()\"] --> CW[\"Calculate window_difference = current_window - checkpoint_window\"]\n    \n    subgraph \"Catch-up Process\"\n        BC[\"Batch windows into manageable chunks\"]\n        AO[\"Apply optimizer steps for each missing window\"]\n        AS[\"Apply scheduler steps for each missing window\"]\n        UG[\"Update global_step\"]\n    end\n    \n    CW -->|\"if window_difference > 0\"| BC\n    BC --> AO\n    AO --> AS\n    AS --> UG",
      "classDiagram\n    class Comms {\n        +async \"save_checkpoint(model, optimizer, scheduler, momentum, global_step, current_window, start_window)\"\n        +async \"load_checkpoint(model, optimizer, scheduler, current_window, device, init_version)\"\n        +async \"get_latest_checkpoint(version)\"\n        -async \"s3_put_object(key, file_path)\"\n        -async \"s3_get_object(key, bucket, timeout)\"\n        -async \"upload_large_file(file_path, key, s3_client)\"\n        -async \"download_large_file(s3_client, bucket, key, file_size, temp_file_path)\"\n    }",
      "graph TD\n    MS[\"Miner.run()\"] --> LC[\"Load latest checkpoint\"]\n    LC -->|\"Success\"| UC[\"Catch up if needed\"]\n    LC -->|\"Failure\"| IM[\"Initialize from scratch\"]\n    UC --> TR[\"Train for current window\"]\n    IM --> TR\n    TR --> CF[\"Check if global_step % checkpoint_frequency == 0\"]\n    CF -->|\"Yes\"| SC[\"Save checkpoint\"]\n    CF -->|\"No\"| NW[\"Wait for next window\"]\n    SC --> NW\n    NW --> TR",
      "graph TD\n    VS[\"Validator.run()\"] --> LC[\"Load latest checkpoint\"]\n    LC -->|\"Success\"| UC[\"Catch up if needed\"]\n    LC -->|\"Failure\"| IM[\"Initialize from scratch\"]\n    UC --> AG[\"Aggregate/evaluate gradients\"]\n    IM --> AG\n    AG --> CF[\"Check if global_step % checkpoint_frequency == 0\"]\n    CF -->|\"Yes\"| SC[\"Save checkpoint\"]\n    CF -->|\"No\"| NW[\"Process next window\"]\n    SC --> NW\n    NW --> AG",
      "graph TD\n    ES[\"Evaluator Service\"] --> GLC[\"get_latest_checkpoint()\"]\n    GLC --> CW[\"Compare checkpoint window to last_eval_window\"]\n    CW -->|\"window > last_eval_window\"| LC[\"Load checkpoint\"]\n    LC --> EM[\"Evaluate model performance\"]\n    EM --> UL[\"Update last_eval_window\"]\n    CW -->|\"window <= last_eval_window\"| SK[\"Skip (already evaluated)\"]"
    ],
    "potential_frontmatter": {
      "title": "Checkpoint Management"
    }
  },
  "/tplr-ai/templar/6.2-chain-integration": {
    "original_deepwiki_href": "/tplr-ai/templar/6.2-chain-integration",
    "title": "Chain Integration",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/6.2-chain-integration",
    "level": 1,
    "target_astro_path": "/communication-system/chain-integration",
    "main_markdown_content": "# Chain Integration\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [ecosystem.config.js](ecosystem.config.js)\n- [hparams.json](hparams.json)\n- [neurons/miner.py](neurons/miner.py)\n- [neurons/validator.py](neurons/validator.py)\n- [src/tplr/__init__.py](src/tplr/__init__.py)\n- [src/tplr/chain.py](src/tplr/chain.py)\n- [src/tplr/comms.py](src/tplr/comms.py)\n- [src/tplr/compress.py](src/tplr/compress.py)\n- [src/tplr/neurons.py](src/tplr/neurons.py)\n- [tests/test_model_comparison.py](tests/test_model_comparison.py)\n\n</details>\n\n\n\n## Purpose and Scope\n\nThis document explains how Templar integrates with the Bittensor blockchain to enable decentralized model training. It covers the core components responsible for blockchain interaction, commitment management, block processing, window tracking, and peer management. For information about model checkpoint management, see [Checkpoint Management](#6.1).\n\n## Chain Architecture Overview\n\nThe following diagram illustrates how Templar interacts with the Bittensor blockchain:\n\n```mermaid\ngraph TD\n    subgraph \"Bittensor Network\"\n        BT[\"Bittensor Chain\"]\n        MG[\"Metagraph\"]\n    end\n    \n    subgraph \"Chain Management\"\n        CM[\"ChainManager\"]\n        CB[\"Commitment Storage\"]\n        BP[\"Block Processing\"]\n        WM[\"Window Management\"]\n        PM[\"Peer Management\"]\n    end\n    \n    subgraph \"Neuron Integration\"\n        MI[\"Miner Integration\"]\n        VI[\"Validator Integration\"]\n        WS[\"Weight Setting\"]\n        PC[\"Peer Coordination\"]\n    end\n    \n    BT <--> CM\n    MG <--> CM\n    \n    CM --> CB\n    CM --> BP\n    CM --> WM\n    CM --> PM\n    \n    CB --> MI\n    CB --> VI\n    BP --> WM\n    WM --> MI\n    WM --> VI\n    PM --> PC\n    VI --> WS\n    WS --> BT\n```\n\nSources: [src/tplr/chain.py:37-487](), [src/tplr/comms.py:64-102]()\n\n## ChainManager Class\n\nThe foundation of Templar's blockchain integration is the `ChainManager` class. It provides methods for committing and retrieving data from the chain, monitoring blocks, and managing peer relationships.\n\n```mermaid\nclassDiagram\n    class ChainManager {\n        +wallet: bt.wallet\n        +netuid: int\n        +metagraph: bt.metagraph\n        +hparams: dict\n        +current_block: int\n        +current_window: int\n        +commitments: dict\n        +peers: array\n        +eval_peers: dict\n        +block_event: asyncio.Event\n        +block_listener(loop)\n        +commit(wallet, bucket)\n        +try_commit(wallet, bucket)\n        +get_commitment(uid)\n        +get_commitments()\n        +update_peers_with_buckets()\n        +start_commitment_fetcher()\n    }\n    \n    ChainManager <|-- Comms\n    \n    class Comms {\n        +wallet: bt.wallet\n        +bucket: Bucket\n        +uid: int\n        +temp_dir: str\n        +get_own_bucket(bucket_type, access_type)\n        +put(state_dict, uid, window, key)\n        +gather(my_uid, uids, window, key)\n        +load_checkpoint(model, optimizer, scheduler)\n        +save_checkpoint(model, optimizer, scheduler)\n    }\n```\n\nSources: [src/tplr/chain.py:37-49](), [src/tplr/comms.py:64-102]()\n\n## Commitment System\n\nTemplar uses chain commitments to securely store and share access information for R2 storage buckets. Each neuron commits its bucket details to the blockchain, allowing other nodes to retrieve this information for data exchange.\n\n### Commitment Format\n\nCommitments follow a fixed format of concatenated strings:\n- `account_id`: 32 characters\n- `access_key_id`: 32 characters \n- `secret_access_key`: 64 characters\n\nTotal length: 128 characters\n\n### Commitment Flow\n\n```mermaid\nsequenceDiagram\n    participant Neuron\n    participant ChainManager\n    participant Subtensor\n    \n    Neuron->>ChainManager: try_commit(wallet, bucket)\n    ChainManager->>Subtensor: get_commitment(netuid, uid)\n    Subtensor-->>ChainManager: Return current commitment\n    \n    alt Commitment exists and matches\n        ChainManager->>Neuron: Use existing commitment\n    else Commitment missing or different\n        ChainManager->>Subtensor: commit(wallet, netuid, concatenated)\n        Subtensor-->>ChainManager: Confirm commitment\n        ChainManager->>Neuron: Log successful commitment\n    end\n    \n    Neuron->>ChainManager: start_commitment_fetcher()\n    loop Periodic updates\n        ChainManager->>Subtensor: query_map(\"Commitments\", \"CommitmentOf\")\n        Subtensor-->>ChainManager: Return all commitments\n        ChainManager->>ChainManager: Parse into Bucket objects\n        ChainManager->>ChainManager: Update commitments dict\n    end\n```\n\nSources: [src/tplr/chain.py:174-233](), [src/tplr/chain.py:304-397]()\n\n## Block and Window Management\n\nTemplar uses blockchain blocks to synchronize the training process across the network. Blocks are grouped into windows based on the `blocks_per_window` parameter, with each window driving a training iteration.\n\n### Block Listener\n\nEach neuron runs a background thread that subscribes to block headers from the Bittensor network. When a new block arrives, it updates the current block number and recalculates the current window if needed.\n\n```mermaid\nflowchart TD\n    A[\"block_listener(loop)\"] -->|\"Subscribe to\"| B[\"subtensor.substrate.subscribe_block_headers\"]\n    B -->|\"New block event\"| C[\"handler(event)\"]\n    C -->|\"Update\"| D[\"current_block = event.header.number\"]\n    D -->|\"Calculate\"| E[\"new_window = current_block / blocks_per_window\"]\n    \n    E -->|\"If changed\"| F[\"current_window = new_window\"]\n    F -->|\"Update\"| G[\"comms.current_window\"]\n    G -->|\"Drives\"| H[\"Training/Validation Loop\"]\n```\n\nSources: [src/tplr/chain.py:143-172](), [neurons/miner.py:757-777](), [neurons/validator.py:522-525]()\n\n### Window-Based Training\n\nThe window concept is central to Templar's training process:\n\n1. **Global Step**: Calculated as `current_window - start_window`, tracking overall training progress\n2. **Window Synchronization**: Miners and validators wait for window transitions to coordinate actions\n3. **Learning Rate Schedule**: Tied to the global step for coordinated optimization\n4. **Start Window Coordination**: Ensures all neurons begin training from the same point\n\n```mermaid\ngraph TD\n    A[\"Block Events\"] -->|\"Trigger window transitions\"| B[\"current_window\"]\n    \n    subgraph \"Miner\"\n        B -->|\"Train for window\"| C[\"Compute gradients\"]\n        C -->|\"Upload to R2\"| D[\"Wait for next window\"]\n        E[\"start_window\"] -->|\"Calculate\"| F[\"global_step = current_window - start_window\"]\n        F -->|\"Update\"| G[\"Optimizer state\"]\n    end\n    \n    subgraph \"Validator\"\n        B -->|\"Evaluate for window\"| H[\"Gather and assess gradients\"]\n        H -->|\"Set weights\"| I[\"Wait for next window\"]\n        E -->|\"Calculate\"| J[\"global_step\"]\n        J -->|\"Update\"| K[\"OpenSkill ratings\"]\n    end\n```\n\nSources: [neurons/miner.py:229-325](), [neurons/validator.py:516-567]()\n\n## Peer Management\n\nThe blockchain integration enables coordinated peer management for training and evaluation.\n\n### Commitment-Based Peer Discovery\n\nTemplar discovers and filters peers by retrieving and processing commitments from the blockchain:\n\n```mermaid\nflowchart TD\n    A[\"fetch_commitments()\"] -->|\"Query chain\"| B[\"get_commitments()\"]\n    B -->|\"Parse raw data\"| C[\"commitments dict\"]\n    C -->|\"Process\"| D[\"update_peers_with_buckets()\"]\n    \n    D -->|\"Map UIDs to buckets\"| E[\"Evaluate peer eligibility\"]\n    E -->|\"Filter by activity\"| F[\"Active peers set\"]\n    F -->|\"Filter by stake\"| G[\"Eval peers dict\"]\n    \n    H[\"Inactive detection\"] -->|\"Track inactive peers\"| I[\"Apply penalties\"]\n```\n\nSources: [src/tplr/chain.py:418-427](), [src/tplr/chain.py:448-487]()\n\n### Peer Selection and Distribution\n\nValidators select and distribute peer lists for coordinated training:\n\n```mermaid\nsequenceDiagram\n    participant Validator\n    participant R2Storage\n    participant Miner\n    \n    Validator->>Validator: select_next_peers()\n    Validator->>R2Storage: post_peer_list(peers, window)\n    \n    Miner->>R2Storage: get_peer_list()\n    R2Storage-->>Miner: peers, update_window\n    \n    Note over Miner,Validator: Peer list effective after window margin\n    \n    Miner->>Miner: Update comms.peers when window reached\n```\n\nSources: [neurons/validator.py:674-686](), [src/tplr/neurons.py:127-197]()\n\n## Code Implementation\n\n### ChainManager Initialization\n\nBoth miners and validators initialize the chain components as part of their setup:\n\n```python\n# In both Miner.__init__ and Validator.__init__\nself.wallet = bt.wallet(config=self.config)\nself.subtensor = bt.subtensor(config=self.config)\nself.metagraph = self.subtensor.metagraph(self.config.netuid)\nif self.wallet.hotkey.ss58_address not in self.metagraph.hotkeys:\n    tplr.logger.error(f\"The wallet {self.wallet} is not registered on subnet: {self.metagraph.netuid}\")\n    sys.exit()\nself.uid = self.metagraph.hotkeys.index(self.wallet.hotkey.ss58_address)\n\n# Initialize Comms with chain components\nself.comms = tplr.comms.Comms(\n    wallet=self.wallet,\n    save_location=\"/tmp\",\n    key_prefix=\"model\",\n    config=self.config,\n    netuid=self.config.netuid,\n    metagraph=self.metagraph,\n    hparams=self.hparams,\n    uid=self.uid,\n)\n```\n\nSources: [neurons/miner.py:107-143](), [neurons/validator.py:134-174]()\n\n### Commitment Management\n\nThe commitment system securely stores and retrieves bucket information:\n\n```python\n# Checking and updating commitments\nself.bucket = self.comms.get_own_bucket(\"gradients\", \"read\")\nself.comms.try_commit(self.wallet, self.bucket)\n\n# Retrieving and parsing commitments\nself.comms.commitments = await self.comms.get_commitments()\n```\n\nThe `try_commit` method checks if the current bucket configuration matches what's on the chain and updates it if needed:\n\n```python\ndef try_commit(self, wallet: Wallet, bucket: Bucket) -> None:\n    # Get existing commitment\n    commitment = self.get_commitment(self.metagraph.hotkeys.index(wallet.hotkey.ss58_address))\n    \n    # Compare with current bucket details\n    if bucket_details_from_env != commitment_str:\n        self.commit(wallet, bucket)\n```\n\nSources: [src/tplr/chain.py:174-233](), [neurons/miner.py:246-247]()\n\n### Block Listener Implementation\n\nThe block listener thread monitors blockchain events:\n\n```python\n# Starting the listener thread\nself.listener = threading.Thread(\n    target=self.block_listener,\n    args=(self.loop,),\n    daemon=True,\n).start()\n```\n\nThe handler updates state based on new blocks:\n\n```python\ndef handler(event):\n    self.current_block = int(event[\"header\"][\"number\"])\n    if int(self.current_block / self.hparams.blocks_per_window) != self.current_window:\n        self.current_window = int(self.current_block / self.hparams.blocks_per_window)\n        self.comms.current_window = self.current_window\n```\n\nSources: [neurons/miner.py:235-240](), [src/tplr/chain.py:155-166]()\n\n## Integration in Neurons\n\n### Miner Chain Integration\n\nMiners use chain integration for:\n\n1. **Block-driven training**: The training loop proceeds based on window transitions\n2. **Start window coordination**: Fetching the global start window from validators\n3. **Peer discovery**: Retrieving and using validator-selected peers\n4. **Bucket commitment**: Sharing storage access information\n\n```mermaid\nflowchart TD\n    A[\"Miner.run()\"] -->|\"Initialize\"| B[\"Block listener thread\"]\n    B -->|\"Monitor blocks\"| C[\"Update current_window\"]\n    \n    D[\"Get start_window\"] -->|\"Coordinate with validators\"| E[\"Calculate global_step\"]\n    \n    F[\"Current window\"] -->|\"Drive\"| G[\"Training loop\"]\n    G -->|\"Process data\"| H[\"Upload gradients\"]\n    H -->|\"Wait for window transition\"| G\n    \n    I[\"Update peers\"] -->|\"From R2\"| J[\"Gather from peers\"]\n    J -->|\"Apply updates\"| K[\"Next window\"]\n```\n\nSources: [neurons/miner.py:229-325](), [neurons/miner.py:757-777]()\n\n### Validator Chain Integration\n\nValidators use chain integration for:\n\n1. **Window coordination**: The validation process syncs with block-derived windows\n2. **Start window publishing**: Setting the global training starting point\n3. **Weight setting**: Evaluating miners and setting chain weights\n4. **Peer management**: Selecting and distributing peer lists\n\n```mermaid\nflowchart TD\n    A[\"Validator.run()\"] -->|\"Initialize\"| B[\"Block listener thread\"]\n    B -->|\"Monitor blocks\"| C[\"Update current_window\"]\n    \n    D[\"Highest stake validator\"] -->|\"Post start_window\"| E[\"Set global training start\"]\n    \n    F[\"Current window\"] -->|\"Drive\"| G[\"Validation loop\"]\n    G -->|\"Gather gradients\"| H[\"Evaluate quality\"]\n    H -->|\"Update scores\"| I[\"Set weights on chain\"]\n    \n    J[\"Peer management\"] -->|\"Select peers\"| K[\"post_peer_list\"]\n    K -->|\"For next window+margin\"| L[\"Update peers\"]\n```\n\nSources: [neurons/validator.py:516-579](), [neurons/validator.py:522-525]()\n\n## Weight Setting Process\n\nValidators evaluate miners and set weights on the blockchain:\n\n```mermaid\nflowchart TD\n    A[\"Evaluate gradients\"] -->|\"Calculate scores\"| B[\"update_openskill_ratings()\"]\n    B -->|\"Combine with other metrics\"| C[\"final_scores\"]\n    \n    C -->|\"Normalize\"| D[\"update_weights()\"]\n    D -->|\"Apply power normalization\"| E[\"weights tensor\"]\n    \n    F[\"Block processing\"] -->|\"Periodic weight setting\"| G[\"subtensor.set_weights()\"]\n    G -->|\"Submit to chain\"| H[\"Update metagraph\"]\n```\n\nSources: [neurons/validator.py:374-437](), [neurons/validator.py:446-487]()\n\n## Window-Based Synchronization\n\n### Start Window Coordination\n\nTo ensure all nodes start training from the same point, Templar coordinates a global start window:\n\n```mermaid\nsequenceDiagram\n    participant HV as \"Highest-Stake Validator\"\n    participant R2 as \"R2 Storage\"\n    participant OV as \"Other Validators\"\n    participant M as \"Miners\"\n    \n    HV->>R2: post_start_window(window)\n    OV->>R2: get_start_window()\n    R2-->>OV: start_window\n    M->>R2: get_start_window()\n    R2-->>M: start_window\n    \n    Note over HV,M: All nodes calculate global_step = current_window - start_window\n```\n\nSources: [neurons/validator.py:534-563](), [neurons/miner.py:250-259]()\n\n### Window-Driven Training Loop\n\nBoth miners and validators use window transitions to drive their main loops:\n\n```mermaid\nsequenceDiagram\n    participant BC as \"Bittensor Chain\"\n    participant M as \"Miner\"\n    participant V as \"Validator\"\n    \n    BC->>M: New block event\n    BC->>V: New block event\n    \n    M->>M: Update current_window\n    V->>V: Update current_window\n    \n    M->>M: Train for window\n    V->>V: Evaluate for window\n    \n    M->>M: Wait for next window\n    V->>V: Wait for next window\n    \n    Note over M,V: Both wait for: while current_window == step_window: await asyncio.sleep(0.1)\n```\n\nSources: [neurons/miner.py:751-754](), [neurons/validator.py:627-636]()\n\n## Configuration Parameters\n\nKey configuration parameters for chain integration:\n\n| Parameter | Description | Default | Source |\n|-----------|-------------|---------|--------|\n| `netuid` | Bittensor network UID | 268 | [neurons/miner.py:71]() |\n| `blocks_per_window` | Number of blocks per training window | 7 | [hparams.json:8]() |\n| `validator_offset` | Windows validators lag behind miners | 2 | [hparams.json:30]() |\n| `peer_replacement_frequency` | Windows between peer list updates | 5 | [hparams.json:36]() |\n| `peer_list_window_margin` | Windows before peer list takes effect | 2 | [hparams.json:37]() |\n| `reset_inactivity_windows` | Windows before inactive peer reset | 25 | [hparams.json:46]() |\n\nSources: [hparams.json:8-47](), [neurons/miner.py:71](), [neurons/validator.py:90]()\n\n## Using in Development\n\nFor local development, the [ecosystem.config.js]() file shows how to configure neurons to interact with a local Bittensor chain:\n\n```javascript\n// Example from ecosystem.config.js\n{\n    name: \"TM1\",\n    script: \"neurons/miner.py\",\n    interpreter: \"python3\",\n    args: `--wallet.name templar_test --wallet.hotkey M1 --device cuda:1 --subtensor.network local --netuid 2 --use_wandb --project \"${PROJECT_NAME}\"`\n}\n```\n\nThe `--subtensor.network local` flag directs the neurons to use a local Subtensor chain for development and testing.\n\nSources: [ecosystem.config.js:8-16]()",
    "resolved_links": [
      {
        "text": "ecosystem.config.js",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ecosystem.config.js",
        "original_deepwiki_href": "ecosystem.config.js",
        "context": "collapsible_aside_link"
      },
      {
        "text": "hparams.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams.json",
        "original_deepwiki_href": "hparams.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/miner.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/miner.py",
        "original_deepwiki_href": "neurons/miner.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "neurons/validator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/neurons/validator.py",
        "original_deepwiki_href": "neurons/validator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/__init__.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/__init__.py",
        "original_deepwiki_href": "src/tplr/__init__.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/chain.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/chain.py",
        "original_deepwiki_href": "src/tplr/chain.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/comms.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/comms.py",
        "original_deepwiki_href": "src/tplr/comms.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/compress.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/compress.py",
        "original_deepwiki_href": "src/tplr/compress.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/neurons.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/neurons.py",
        "original_deepwiki_href": "src/tplr/neurons.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_model_comparison.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_model_comparison.py",
        "original_deepwiki_href": "tests/test_model_comparison.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/chain.py:37-487",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/comms.py:64-102",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/chain.py:37-49",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/chain.py:174-233",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/chain.py:304-397",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/chain.py:143-172",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:757-777",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:522-525",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:229-325",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:516-567",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/chain.py:418-427",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/chain.py:448-487",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:674-686",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/neurons.py:127-197",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:107-143",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:134-174",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:246-247",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:235-240",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/chain.py:155-166",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:516-579",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:374-437",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:446-487",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:534-563",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:250-259",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:751-754",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:627-636",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams.json:8-47",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/miner.py:71",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "neurons/validator.py:90",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ecosystem.config.js:8-16",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Checkpoint Management",
        "href": "/communication-system/checkpoint-management#6.1",
        "original_deepwiki_href": "#6.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Bittensor Network\"\n        BT[\"Bittensor Chain\"]\n        MG[\"Metagraph\"]\n    end\n    \n    subgraph \"Chain Management\"\n        CM[\"ChainManager\"]\n        CB[\"Commitment Storage\"]\n        BP[\"Block Processing\"]\n        WM[\"Window Management\"]\n        PM[\"Peer Management\"]\n    end\n    \n    subgraph \"Neuron Integration\"\n        MI[\"Miner Integration\"]\n        VI[\"Validator Integration\"]\n        WS[\"Weight Setting\"]\n        PC[\"Peer Coordination\"]\n    end\n    \n    BT <--> CM\n    MG <--> CM\n    \n    CM --> CB\n    CM --> BP\n    CM --> WM\n    CM --> PM\n    \n    CB --> MI\n    CB --> VI\n    BP --> WM\n    WM --> MI\n    WM --> VI\n    PM --> PC\n    VI --> WS\n    WS --> BT",
      "classDiagram\n    class ChainManager {\n        +wallet: bt.wallet\n        +netuid: int\n        +metagraph: bt.metagraph\n        +hparams: dict\n        +current_block: int\n        +current_window: int\n        +commitments: dict\n        +peers: array\n        +eval_peers: dict\n        +block_event: asyncio.Event\n        +block_listener(loop)\n        +commit(wallet, bucket)\n        +try_commit(wallet, bucket)\n        +get_commitment(uid)\n        +get_commitments()\n        +update_peers_with_buckets()\n        +start_commitment_fetcher()\n    }\n    \n    ChainManager <|-- Comms\n    \n    class Comms {\n        +wallet: bt.wallet\n        +bucket: Bucket\n        +uid: int\n        +temp_dir: str\n        +get_own_bucket(bucket_type, access_type)\n        +put(state_dict, uid, window, key)\n        +gather(my_uid, uids, window, key)\n        +load_checkpoint(model, optimizer, scheduler)\n        +save_checkpoint(model, optimizer, scheduler)\n    }",
      "sequenceDiagram\n    participant Neuron\n    participant ChainManager\n    participant Subtensor\n    \n    Neuron->>ChainManager: try_commit(wallet, bucket)\n    ChainManager->>Subtensor: get_commitment(netuid, uid)\n    Subtensor-->>ChainManager: Return current commitment\n    \n    alt Commitment exists and matches\n        ChainManager->>Neuron: Use existing commitment\n    else Commitment missing or different\n        ChainManager->>Subtensor: commit(wallet, netuid, concatenated)\n        Subtensor-->>ChainManager: Confirm commitment\n        ChainManager->>Neuron: Log successful commitment\n    end\n    \n    Neuron->>ChainManager: start_commitment_fetcher()\n    loop Periodic updates\n        ChainManager->>Subtensor: query_map(\"Commitments\", \"CommitmentOf\")\n        Subtensor-->>ChainManager: Return all commitments\n        ChainManager->>ChainManager: Parse into Bucket objects\n        ChainManager->>ChainManager: Update commitments dict\n    end",
      "flowchart TD\n    A[\"block_listener(loop)\"] -->|\"Subscribe to\"| B[\"subtensor.substrate.subscribe_block_headers\"]\n    B -->|\"New block event\"| C[\"handler(event)\"]\n    C -->|\"Update\"| D[\"current_block = event.header.number\"]\n    D -->|\"Calculate\"| E[\"new_window = current_block / blocks_per_window\"]\n    \n    E -->|\"If changed\"| F[\"current_window = new_window\"]\n    F -->|\"Update\"| G[\"comms.current_window\"]\n    G -->|\"Drives\"| H[\"Training/Validation Loop\"]",
      "graph TD\n    A[\"Block Events\"] -->|\"Trigger window transitions\"| B[\"current_window\"]\n    \n    subgraph \"Miner\"\n        B -->|\"Train for window\"| C[\"Compute gradients\"]\n        C -->|\"Upload to R2\"| D[\"Wait for next window\"]\n        E[\"start_window\"] -->|\"Calculate\"| F[\"global_step = current_window - start_window\"]\n        F -->|\"Update\"| G[\"Optimizer state\"]\n    end\n    \n    subgraph \"Validator\"\n        B -->|\"Evaluate for window\"| H[\"Gather and assess gradients\"]\n        H -->|\"Set weights\"| I[\"Wait for next window\"]\n        E -->|\"Calculate\"| J[\"global_step\"]\n        J -->|\"Update\"| K[\"OpenSkill ratings\"]\n    end",
      "flowchart TD\n    A[\"fetch_commitments()\"] -->|\"Query chain\"| B[\"get_commitments()\"]\n    B -->|\"Parse raw data\"| C[\"commitments dict\"]\n    C -->|\"Process\"| D[\"update_peers_with_buckets()\"]\n    \n    D -->|\"Map UIDs to buckets\"| E[\"Evaluate peer eligibility\"]\n    E -->|\"Filter by activity\"| F[\"Active peers set\"]\n    F -->|\"Filter by stake\"| G[\"Eval peers dict\"]\n    \n    H[\"Inactive detection\"] -->|\"Track inactive peers\"| I[\"Apply penalties\"]",
      "sequenceDiagram\n    participant Validator\n    participant R2Storage\n    participant Miner\n    \n    Validator->>Validator: select_next_peers()\n    Validator->>R2Storage: post_peer_list(peers, window)\n    \n    Miner->>R2Storage: get_peer_list()\n    R2Storage-->>Miner: peers, update_window\n    \n    Note over Miner,Validator: Peer list effective after window margin\n    \n    Miner->>Miner: Update comms.peers when window reached",
      "flowchart TD\n    A[\"Miner.run()\"] -->|\"Initialize\"| B[\"Block listener thread\"]\n    B -->|\"Monitor blocks\"| C[\"Update current_window\"]\n    \n    D[\"Get start_window\"] -->|\"Coordinate with validators\"| E[\"Calculate global_step\"]\n    \n    F[\"Current window\"] -->|\"Drive\"| G[\"Training loop\"]\n    G -->|\"Process data\"| H[\"Upload gradients\"]\n    H -->|\"Wait for window transition\"| G\n    \n    I[\"Update peers\"] -->|\"From R2\"| J[\"Gather from peers\"]\n    J -->|\"Apply updates\"| K[\"Next window\"]",
      "flowchart TD\n    A[\"Validator.run()\"] -->|\"Initialize\"| B[\"Block listener thread\"]\n    B -->|\"Monitor blocks\"| C[\"Update current_window\"]\n    \n    D[\"Highest stake validator\"] -->|\"Post start_window\"| E[\"Set global training start\"]\n    \n    F[\"Current window\"] -->|\"Drive\"| G[\"Validation loop\"]\n    G -->|\"Gather gradients\"| H[\"Evaluate quality\"]\n    H -->|\"Update scores\"| I[\"Set weights on chain\"]\n    \n    J[\"Peer management\"] -->|\"Select peers\"| K[\"post_peer_list\"]\n    K -->|\"For next window+margin\"| L[\"Update peers\"]",
      "flowchart TD\n    A[\"Evaluate gradients\"] -->|\"Calculate scores\"| B[\"update_openskill_ratings()\"]\n    B -->|\"Combine with other metrics\"| C[\"final_scores\"]\n    \n    C -->|\"Normalize\"| D[\"update_weights()\"]\n    D -->|\"Apply power normalization\"| E[\"weights tensor\"]\n    \n    F[\"Block processing\"] -->|\"Periodic weight setting\"| G[\"subtensor.set_weights()\"]\n    G -->|\"Submit to chain\"| H[\"Update metagraph\"]",
      "sequenceDiagram\n    participant HV as \"Highest-Stake Validator\"\n    participant R2 as \"R2 Storage\"\n    participant OV as \"Other Validators\"\n    participant M as \"Miners\"\n    \n    HV->>R2: post_start_window(window)\n    OV->>R2: get_start_window()\n    R2-->>OV: start_window\n    M->>R2: get_start_window()\n    R2-->>M: start_window\n    \n    Note over HV,M: All nodes calculate global_step = current_window - start_window",
      "sequenceDiagram\n    participant BC as \"Bittensor Chain\"\n    participant M as \"Miner\"\n    participant V as \"Validator\"\n    \n    BC->>M: New block event\n    BC->>V: New block event\n    \n    M->>M: Update current_window\n    V->>V: Update current_window\n    \n    M->>M: Train for window\n    V->>V: Evaluate for window\n    \n    M->>M: Wait for next window\n    V->>V: Wait for next window\n    \n    Note over M,V: Both wait for: while current_window == step_window: await asyncio.sleep(0.1)"
    ],
    "potential_frontmatter": {
      "title": "Chain Integration"
    }
  },
  "/tplr-ai/templar/7-data-management": {
    "original_deepwiki_href": "/tplr-ai/templar/7-data-management",
    "title": "Data Management",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/7-data-management",
    "level": 0,
    "target_astro_path": "/data-management",
    "main_markdown_content": "# Data Management\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [scripts/benchmarks/benchmark_parquet_loader.py](scripts/benchmarks/benchmark_parquet_loader.py)\n- [scripts/benchmarks/benchmark_results/avg_batch_time_analysis.png](scripts/benchmarks/benchmark_results/avg_batch_time_analysis.png)\n- [scripts/benchmarks/benchmark_results/memory_used_mb_analysis.png](scripts/benchmarks/benchmark_results/memory_used_mb_analysis.png)\n- [scripts/benchmarks/benchmark_results/parquet_loader_results.csv](scripts/benchmarks/benchmark_results/parquet_loader_results.csv)\n- [scripts/benchmarks/benchmark_results/sequence_length_heatmap.png](scripts/benchmarks/benchmark_results/sequence_length_heatmap.png)\n- [scripts/benchmarks/benchmark_results/tokens_per_second_analysis.png](scripts/benchmarks/benchmark_results/tokens_per_second_analysis.png)\n- [scripts/benchmarks/benchmark_results/total_duration_analysis.png](scripts/benchmarks/benchmark_results/total_duration_analysis.png)\n- [src/tplr/config.py](src/tplr/config.py)\n- [src/tplr/r2_dataset.py](src/tplr/r2_dataset.py)\n- [tests/test_dataset_equivalence.py](tests/test_dataset_equivalence.py)\n- [tests/test_r2_loader.py](tests/test_r2_loader.py)\n\n</details>\n\n\n\nThis page documents the data management system within Templar, which provides efficient loading, processing, and distribution of datasets and model artifacts across the decentralized training framework. The system is designed to support distributed training over the internet with high-performance access to large datasets stored in cloud object storage.\n\nFor information about specific checkpoint management and saving/loading models, see [Checkpoint Management](#6.1).\n\n## Overview\n\nThe Templar data management system enables miners and validators to efficiently access training data and exchange model artifacts during the decentralized training process. It uses Cloudflare R2 storage as its primary storage backend, with specialized components for loading and processing dataset files in parallel.\n\n```mermaid\nflowchart TD\n    subgraph \"R2 Storage System\"\n        DB[\"Dataset Bucket\"]\n        GB[\"Gradients Bucket\"]\n        AB[\"Aggregator Bucket\"]\n        CB[\"Checkpoints Bucket\"]\n    end\n\n    subgraph \"Training Components\"\n        MN[\"Miners\"]\n        VL[\"Validators\"]\n        AG[\"Aggregation Server\"]\n    end\n\n    subgraph \"Data Processing\"\n        R2L[\"R2DatasetLoader\"]\n        PQ[\"Parquet Processing\"]\n        TK[\"Tokenization\"]\n        CR[\"Caching and Retries\"]\n    end\n\n    DB --> R2L\n    R2L --> PQ --> TK\n    CR --> R2L\n    \n    MN <--\"Get training data\"--> R2L\n    VL <--\"Get training data\"--> R2L\n    \n    MN --\"Store gradients\"--> GB\n    VL --\"Get gradients\"--> GB\n    AG --\"Store aggregated models\"--> AB\n    MN --\"Get aggregated weights\"--> AB\n    VL --\"Get aggregated weights\"--> AB\n    MN --\"Store checkpoints\"--> CB\n    VL --\"Store checkpoints\"--> CB\n```\n\nSources: [src/tplr/r2_dataset.py:33-46](), [src/tplr/config.py:28-144]()\n\n## Storage Architecture\n\nThe data management system uses Cloudflare R2 as its primary storage backend, with four key buckets for different data types:\n\n1. **Dataset Bucket**: Contains training datasets in Parquet format, organized by configuration\n2. **Gradients Bucket**: Used for exchanging gradients between miners and validators\n3. **Aggregator Bucket**: Stores aggregated model states\n4. **Checkpoints Bucket**: Stores model checkpoints\n\nAccess to these buckets is configured through environment variables, with separate read and write credentials for each bucket.\n\n```mermaid\nflowchart LR\n    subgraph \"Environment Configuration\"\n        ENV[\"Environment Variables\"]\n    end\n\n    subgraph \"BUCKET_SECRETS\"\n        GRD[\"gradients: {\n            account_id,\n            name,\n            credentials: {read, write}\n        }\"]\n        \n        AGG[\"aggregator: {\n            account_id,\n            name,\n            credentials: {read, write}\n        }\"]\n        \n        DST[\"dataset: {\n            account_id,\n            name,\n            credentials: {read, write}\n            OR \n            multiple: [configs]\n        }\"]\n    end\n\n    subgraph \"R2 Storage System\"\n        GRD_BUCKET[\"Gradients Bucket\"]\n        AGG_BUCKET[\"Aggregator Bucket\"]\n        DST_BUCKET[\"Dataset Bucket\"]\n    end\n\n    ENV --> BUCKET_SECRETS\n    GRD --> GRD_BUCKET\n    AGG --> AGG_BUCKET\n    DST --> DST_BUCKET\n```\n\nSources: [src/tplr/config.py:28-144]()\n\n### R2 Bucket Configuration\n\nThe system loads bucket configuration from environment variables using the `load_bucket_secrets()` function in the config module. This creates a `BUCKET_SECRETS` dictionary with the following structure for each bucket:\n\n- `account_id`: R2 account identifier\n- `bucket_name`: Name of the R2 bucket\n- `credentials`: Contains separate read and write credential sets:\n  - `read`: Read-only access credentials\n  - `write`: Write access credentials\n\nThe dataset bucket can be configured with multiple endpoints for load balancing, using a JSON array in the `R2_DATASET_BUCKET_LIST` environment variable.\n\nSources: [src/tplr/config.py:28-144]()\n\n## The R2DatasetLoader\n\nThe `R2DatasetLoader` class is responsible for efficiently loading training data from R2 storage. It handles dataset metadata caching, parallel data loading, tokenization, and batch creation.\n\n```mermaid\nclassDiagram\n    class R2DatasetLoader {\n        +DATASET_SUBFOLDER: str\n        +CF_REGION_NAME: str\n        -_fs_cache: dict\n        -_metadata_cache: dict\n        -_token_cache: dict\n        -_round_robin_index: int\n        +PREFETCH_SIZE: int\n        +MAX_CONCURRENT_REQUESTS: int\n        +__init__(batch_size, sequence_length, tokenizer, pack_samples)\n        +static next_pages(offset, n_pages, seed, num_rows_per_page): list\n        +static create(batch_size, sequence_length, pages_info, tokenizer, pack_samples): R2DatasetLoader\n        -static _load_r2_metadata(): tuple\n        -static _get_fs(): S3FileSystem\n        -_get_pad_size(input_ids): int\n        -_refill_padded_buffer(): void\n        -_process_page(page, sem): list\n        +__iter__(): R2DatasetLoader\n        +__next__(): np.array\n    }\n```\n\nSources: [src/tplr/r2_dataset.py:33-595]()\n\n### Dataset Loading Process\n\nThe dataset loading process involves several key steps:\n\n1. **Metadata Loading**: The loader first fetches and caches dataset metadata and shard sizes from R2 storage\n2. **Page Selection**: Random pages are selected based on a seed for reproducible training\n3. **Parallel Loading**: Selected pages are loaded in parallel using asyncio\n4. **Tokenization**: Text data is tokenized using the provided tokenizer\n5. **Batch Creation**: Tokenized data is organized into batches of the requested size\n\n```mermaid\nsequenceDiagram\n    participant Client\n    participant R2DatasetLoader\n    participant R2Storage\n    participant Tokenizer\n\n    Client->>R2DatasetLoader: next_pages(offset, n_pages, seed)\n    R2DatasetLoader->>R2Storage: load_r2_metadata()\n    R2Storage-->>R2DatasetLoader: metadata, shard_sizes\n    R2DatasetLoader-->>Client: pages_info\n\n    Client->>R2DatasetLoader: create(batch_size, sequence_length, pages_info, tokenizer)\n    loop For each page\n        R2DatasetLoader->>R2Storage: Open parquet file\n        R2Storage-->>R2DatasetLoader: parquet data\n        R2DatasetLoader->>Tokenizer: tokenize(text)\n        Tokenizer-->>R2DatasetLoader: tokens\n    end\n    R2DatasetLoader-->>Client: loader instance\n\n    Client->>R2DatasetLoader: iterate batches\n    loop Until exhausted\n        R2DatasetLoader->>R2DatasetLoader: _refill_padded_buffer()\n        R2DatasetLoader-->>Client: batch of tokens\n    end\n```\n\nSources: [src/tplr/r2_dataset.py:180-240](), [src/tplr/r2_dataset.py:241-303](), [src/tplr/r2_dataset.py:380-518]()\n\n### Load Balancing with Round-Robin\n\nThe system supports distributing dataset access across multiple R2 endpoints using a round-robin approach. This feature is enabled by configuring multiple dataset configurations in the `R2_DATASET_BUCKET_LIST` environment variable.\n\n```mermaid\nflowchart TD\n    subgraph \"Dataset Configuration\"\n        MULTI[\"multiple: [\n            {account_id: 'accountA', name: 'bucketA', credentials: {...}},\n            {account_id: 'accountB', name: 'bucketB', credentials: {...}}\n        ]\"]\n    end\n\n    subgraph \"R2DatasetLoader\"\n        RR[\"_round_robin_index\"]\n        FS[\"_fs_cache\"]\n        GET[\"_get_fs()\"]\n    end\n\n    subgraph \"R2 Endpoints\"\n        EP1[\"Endpoint A\"]\n        EP2[\"Endpoint B\"]\n    end\n\n    MULTI --> RR\n    RR --> GET\n    GET --> FS\n    FS --\"First request\"--> EP1\n    FS --\"Second request\"--> EP2\n    FS --\"Third request\"--> EP1\n```\n\nThe `_get_fs()` method implements the round-robin strategy by:\n1. Incrementing the `_round_robin_index` counter\n2. Selecting a configuration based on the index modulo the number of configurations\n3. Caching S3FileSystem instances to avoid repeated instantiation\n\nSources: [src/tplr/r2_dataset.py:333-378](), [tests/test_r2_loader.py:543-907]()\n\n### Error Handling and Retry Mechanisms\n\nThe `R2DatasetLoader` implements robust error handling and retry mechanisms to deal with transient failures when accessing R2 storage. This is essential for reliable operation in a distributed environment.\n\n```mermaid\nflowchart LR\n    subgraph \"Client Code\"\n        REQUEST[\"Data Request\"]\n        SUCCESS[\"Success\"]\n        FAILURE[\"Failure\"]\n    end\n\n    subgraph \"Error Handling\"\n        RETRY[\"retry_call()\"]\n        ATTEMPT1[\"Attempt 1\"]\n        ATTEMPT2[\"Attempt 2\"]\n        ATTEMPT3[\"Attempt 3\"]\n        BACKOFF[\"Exponential Backoff\"]\n    end\n\n    REQUEST --> RETRY\n    RETRY --> ATTEMPT1\n    ATTEMPT1 --\"Success\"--> SUCCESS\n    ATTEMPT1 --\"Failure\"--> BACKOFF\n    BACKOFF --> ATTEMPT2\n    ATTEMPT2 --\"Success\"--> SUCCESS\n    ATTEMPT2 --\"Failure\"--> BACKOFF\n    BACKOFF --> ATTEMPT3\n    ATTEMPT3 --\"Success\"--> SUCCESS\n    ATTEMPT3 --\"Failure\"--> FAILURE\n```\n\nKey error handling features include:\n- Exponential backoff between retry attempts\n- Separate retry configurations for different operations\n- Thread-safe filesystem and connection management\n- Caching of successful results to avoid redundant operations\n\nSources: [src/tplr/r2_dataset.py:435-469](), [tests/test_r2_loader.py:311-498]()\n\n## Dataset Structure and Format\n\nThe Templar framework uses Parquet files for dataset storage. These files are organized into shards, with metadata describing the contents and structure of each shard.\n\n### Parquet File Structure\n\nEach dataset configuration contains multiple shards, with each shard containing rows of text data. The system uses metadata files to track:\n\n- Total rows per configuration\n- Number of rows per shard\n- Shard file paths\n- Dataset splits (train/valid/test)\n\n```mermaid\nflowchart TD\n    subgraph \"R2 Dataset Bucket\"\n        META[\"_metadata.yaml\"]\n        SIZES[\"_shard_sizes.json\"]\n        \n        subgraph \"Config 1\"\n            C1S1[\"shard_0001.parquet\"]\n            C1S2[\"shard_0002.parquet\"]\n            C1S3[\"shard_0003.parquet\"]\n        end\n        \n        subgraph \"Config 2\"\n            C2S1[\"shard_0001.parquet\"]\n            C2S2[\"shard_0002.parquet\"]\n        end\n    end\n    \n    META --> C1S1\n    META --> C1S2\n    META --> C1S3\n    META --> C2S1\n    META --> C2S2\n    \n    SIZES --\"Contains row counts\"--> C1S1\n    SIZES --\"Contains row counts\"--> C1S2\n    SIZES --\"Contains row counts\"--> C1S3\n    SIZES --\"Contains row counts\"--> C2S1\n    SIZES --\"Contains row counts\"--> C2S2\n```\n\nThe dataset structure includes:\n- `_metadata.yaml`: Contains configuration information about the dataset\n- `_shard_sizes.json`: Maps configurations to shard files with row counts\n- Parquet files: Contain actual text data in columnar format\n\nSources: [src/tplr/r2_dataset.py:180-240](), [src/tplr/r2_dataset.py:270-331]()\n\n## Performance Optimizations\n\nThe `R2DatasetLoader` implements several performance optimizations to efficiently load and process large datasets:\n\n1. **Metadata Caching**: Dataset metadata is cached locally to avoid repeated network requests\n2. **Parallel Loading**: Multiple pages are loaded in parallel using asyncio and semaphores\n3. **Connection Pooling**: S3FileSystem instances are configured with connection pooling\n4. **Result Caching**: Tokenized results are cached to avoid redundant processing\n5. **Prefetching**: Data is prefetched in the background while processing current batches\n6. **Thread Safety**: Thread locks ensure safe concurrent access to shared resources\n\nSources: [src/tplr/r2_dataset.py:56-88](), [src/tplr/r2_dataset.py:333-378](), [scripts/benchmarks/benchmark_parquet_loader.py:54-242]()\n\n## Integration with Training Pipeline\n\nThe data management system integrates with the Templar training pipeline, providing data for miners and validators during the decentralized training process:\n\n```mermaid\nflowchart LR\n    subgraph \"Miner\"\n        MT[\"Model Training\"]\n        ML[\"Data Loading\"]\n        MR2[\"R2DatasetLoader\"]\n    end\n\n    subgraph \"Validator\"\n        VT[\"Evaluation\"]\n        VL[\"Data Loading\"]\n        VR2[\"R2DatasetLoader\"]\n    end\n\n    subgraph \"R2 Storage\"\n        DB[\"Dataset Bucket\"]\n        GB[\"Gradients Bucket\"]\n        AB[\"Aggregator Bucket\"]\n    end\n\n    DB --> MR2\n    MR2 --> ML\n    ML --> MT\n    MT --\"Gradients\"--> GB\n    \n    DB --> VR2\n    VR2 --> VL\n    VL --> VT\n    GB --\"Miner Gradients\"--> VT\n    VT --\"Evaluation Results\"--> AB\n```\n\nThe integration points include:\n- Miners use the `R2DatasetLoader` to fetch training data\n- Validators use the `R2DatasetLoader` to fetch evaluation data\n- Both components access other buckets for gradient exchange and aggregation\n\nSources: [src/tplr/r2_dataset.py:33-46]()\n\n## Benchmarking and Performance\n\nThe system includes benchmark tools to evaluate the performance of the data loading system under different configurations. Key metrics include:\n\n- Tokens per second processing rate\n- Memory usage\n- Total processing time\n- Batch processing time\n\nThese benchmarks help optimize configuration parameters like:\n- Number of concurrent requests\n- Batch size\n- Sequence length\n- Buffer sizes\n\nSources: [scripts/benchmarks/benchmark_parquet_loader.py:54-242](), [scripts/benchmarks/benchmark_results/parquet_loader_results.csv:1-23]()\n\n## Configuration Parameters\n\nThe `R2DatasetLoader` can be configured with several parameters to optimize performance:\n\n| Parameter | Description | Default Value |\n|-----------|-------------|---------------|\n| `MAX_CONCURRENT_REQUESTS` | Maximum parallel requests | 8 |\n| `PREFETCH_SIZE` | Number of pages to prefetch | 3 |\n| `READ_BUFFER_SIZE` | Buffer size for reading | 4MB |\n| `BATCH_SIZE` | Default batch size for tokenization | 128 |\n| `CF_REGION_NAME` | Cloudflare region name | \"enam\" |\n| `DATASET_SUBFOLDER` | Subfolder in bucket containing dataset | \"HuggingFaceFW_fineweb-edu-score-2\" |\n\nSources: [src/tplr/r2_dataset.py:75-88]()\n\n## Environment Configuration\n\nThe data management system requires specific environment variables to be set for proper operation:\n\n| Environment Variable | Description |\n|----------------------|-------------|\n| `R2_GRADIENTS_ACCOUNT_ID` | Account ID for gradients bucket |\n| `R2_GRADIENTS_BUCKET_NAME` | Bucket name for gradients |\n| `R2_GRADIENTS_READ_ACCESS_KEY_ID` | Read access key for gradients |\n| `R2_GRADIENTS_READ_SECRET_ACCESS_KEY` | Read secret key for gradients |\n| `R2_GRADIENTS_WRITE_ACCESS_KEY_ID` | Write access key for gradients |\n| `R2_GRADIENTS_WRITE_SECRET_ACCESS_KEY` | Write secret key for gradients |\n| `R2_AGGREGATOR_ACCOUNT_ID` | Account ID for aggregator bucket |\n| `R2_AGGREGATOR_BUCKET_NAME` | Bucket name for aggregator |\n| ... | (Similar variables for aggregator read/write) |\n| `R2_DATASET_ACCOUNT_ID` | Account ID for dataset bucket |\n| `R2_DATASET_BUCKET_NAME` | Bucket name for dataset |\n| ... | (Similar variables for dataset read/write) |\n| `R2_DATASET_BUCKET_LIST` | Optional JSON array of multiple dataset configs |\n\nSources: [src/tplr/config.py:28-144](), [tests/test_r2_loader.py:22-44]()",
    "resolved_links": [
      {
        "text": "scripts/benchmarks/benchmark_parquet_loader.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/benchmarks/benchmark_parquet_loader.py",
        "original_deepwiki_href": "scripts/benchmarks/benchmark_parquet_loader.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/benchmarks/benchmark_results/avg_batch_time_analysis.png",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/benchmarks/benchmark_results/avg_batch_time_analysis.png",
        "original_deepwiki_href": "scripts/benchmarks/benchmark_results/avg_batch_time_analysis.png",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/benchmarks/benchmark_results/memory_used_mb_analysis.png",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/benchmarks/benchmark_results/memory_used_mb_analysis.png",
        "original_deepwiki_href": "scripts/benchmarks/benchmark_results/memory_used_mb_analysis.png",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/benchmarks/benchmark_results/parquet_loader_results.csv",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/benchmarks/benchmark_results/parquet_loader_results.csv",
        "original_deepwiki_href": "scripts/benchmarks/benchmark_results/parquet_loader_results.csv",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/benchmarks/benchmark_results/sequence_length_heatmap.png",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/benchmarks/benchmark_results/sequence_length_heatmap.png",
        "original_deepwiki_href": "scripts/benchmarks/benchmark_results/sequence_length_heatmap.png",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/benchmarks/benchmark_results/tokens_per_second_analysis.png",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/benchmarks/benchmark_results/tokens_per_second_analysis.png",
        "original_deepwiki_href": "scripts/benchmarks/benchmark_results/tokens_per_second_analysis.png",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/benchmarks/benchmark_results/total_duration_analysis.png",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/benchmarks/benchmark_results/total_duration_analysis.png",
        "original_deepwiki_href": "scripts/benchmarks/benchmark_results/total_duration_analysis.png",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/config.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/config.py",
        "original_deepwiki_href": "src/tplr/config.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/r2_dataset.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/r2_dataset.py",
        "original_deepwiki_href": "src/tplr/r2_dataset.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_dataset_equivalence.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_dataset_equivalence.py",
        "original_deepwiki_href": "tests/test_dataset_equivalence.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_r2_loader.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_r2_loader.py",
        "original_deepwiki_href": "tests/test_r2_loader.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:33-46",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/config.py:28-144",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:33-595",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:180-240",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:241-303",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:380-518",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:333-378",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_r2_loader.py:543-907",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:435-469",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_r2_loader.py:311-498",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:270-331",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:56-88",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/benchmarks/benchmark_parquet_loader.py:54-242",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/benchmarks/benchmark_results/parquet_loader_results.csv:1-23",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:75-88",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_r2_loader.py:22-44",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Checkpoint Management",
        "href": "/communication-system/checkpoint-management#6.1",
        "original_deepwiki_href": "#6.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"R2 Storage System\"\n        DB[\"Dataset Bucket\"]\n        GB[\"Gradients Bucket\"]\n        AB[\"Aggregator Bucket\"]\n        CB[\"Checkpoints Bucket\"]\n    end\n\n    subgraph \"Training Components\"\n        MN[\"Miners\"]\n        VL[\"Validators\"]\n        AG[\"Aggregation Server\"]\n    end\n\n    subgraph \"Data Processing\"\n        R2L[\"R2DatasetLoader\"]\n        PQ[\"Parquet Processing\"]\n        TK[\"Tokenization\"]\n        CR[\"Caching and Retries\"]\n    end\n\n    DB --> R2L\n    R2L --> PQ --> TK\n    CR --> R2L\n    \n    MN <--\"Get training data\"--> R2L\n    VL <--\"Get training data\"--> R2L\n    \n    MN --\"Store gradients\"--> GB\n    VL --\"Get gradients\"--> GB\n    AG --\"Store aggregated models\"--> AB\n    MN --\"Get aggregated weights\"--> AB\n    VL --\"Get aggregated weights\"--> AB\n    MN --\"Store checkpoints\"--> CB\n    VL --\"Store checkpoints\"--> CB",
      "flowchart LR\n    subgraph \"Environment Configuration\"\n        ENV[\"Environment Variables\"]\n    end\n\n    subgraph \"BUCKET_SECRETS\"\n        GRD[\"gradients: {\n            account_id,\n            name,\n            credentials: {read, write}\n        }\"]\n        \n        AGG[\"aggregator: {\n            account_id,\n            name,\n            credentials: {read, write}\n        }\"]\n        \n        DST[\"dataset: {\n            account_id,\n            name,\n            credentials: {read, write}\n            OR \n            multiple: [configs]\n        }\"]\n    end\n\n    subgraph \"R2 Storage System\"\n        GRD_BUCKET[\"Gradients Bucket\"]\n        AGG_BUCKET[\"Aggregator Bucket\"]\n        DST_BUCKET[\"Dataset Bucket\"]\n    end\n\n    ENV --> BUCKET_SECRETS\n    GRD --> GRD_BUCKET\n    AGG --> AGG_BUCKET\n    DST --> DST_BUCKET",
      "classDiagram\n    class R2DatasetLoader {\n        +DATASET_SUBFOLDER: str\n        +CF_REGION_NAME: str\n        -_fs_cache: dict\n        -_metadata_cache: dict\n        -_token_cache: dict\n        -_round_robin_index: int\n        +PREFETCH_SIZE: int\n        +MAX_CONCURRENT_REQUESTS: int\n        +__init__(batch_size, sequence_length, tokenizer, pack_samples)\n        +static next_pages(offset, n_pages, seed, num_rows_per_page): list\n        +static create(batch_size, sequence_length, pages_info, tokenizer, pack_samples): R2DatasetLoader\n        -static _load_r2_metadata(): tuple\n        -static _get_fs(): S3FileSystem\n        -_get_pad_size(input_ids): int\n        -_refill_padded_buffer(): void\n        -_process_page(page, sem): list\n        +__iter__(): R2DatasetLoader\n        +__next__(): np.array\n    }",
      "sequenceDiagram\n    participant Client\n    participant R2DatasetLoader\n    participant R2Storage\n    participant Tokenizer\n\n    Client->>R2DatasetLoader: next_pages(offset, n_pages, seed)\n    R2DatasetLoader->>R2Storage: load_r2_metadata()\n    R2Storage-->>R2DatasetLoader: metadata, shard_sizes\n    R2DatasetLoader-->>Client: pages_info\n\n    Client->>R2DatasetLoader: create(batch_size, sequence_length, pages_info, tokenizer)\n    loop For each page\n        R2DatasetLoader->>R2Storage: Open parquet file\n        R2Storage-->>R2DatasetLoader: parquet data\n        R2DatasetLoader->>Tokenizer: tokenize(text)\n        Tokenizer-->>R2DatasetLoader: tokens\n    end\n    R2DatasetLoader-->>Client: loader instance\n\n    Client->>R2DatasetLoader: iterate batches\n    loop Until exhausted\n        R2DatasetLoader->>R2DatasetLoader: _refill_padded_buffer()\n        R2DatasetLoader-->>Client: batch of tokens\n    end",
      "flowchart TD\n    subgraph \"Dataset Configuration\"\n        MULTI[\"multiple: [\n            {account_id: 'accountA', name: 'bucketA', credentials: {...}},\n            {account_id: 'accountB', name: 'bucketB', credentials: {...}}\n        ]\"]\n    end\n\n    subgraph \"R2DatasetLoader\"\n        RR[\"_round_robin_index\"]\n        FS[\"_fs_cache\"]\n        GET[\"_get_fs()\"]\n    end\n\n    subgraph \"R2 Endpoints\"\n        EP1[\"Endpoint A\"]\n        EP2[\"Endpoint B\"]\n    end\n\n    MULTI --> RR\n    RR --> GET\n    GET --> FS\n    FS --\"First request\"--> EP1\n    FS --\"Second request\"--> EP2\n    FS --\"Third request\"--> EP1",
      "flowchart LR\n    subgraph \"Client Code\"\n        REQUEST[\"Data Request\"]\n        SUCCESS[\"Success\"]\n        FAILURE[\"Failure\"]\n    end\n\n    subgraph \"Error Handling\"\n        RETRY[\"retry_call()\"]\n        ATTEMPT1[\"Attempt 1\"]\n        ATTEMPT2[\"Attempt 2\"]\n        ATTEMPT3[\"Attempt 3\"]\n        BACKOFF[\"Exponential Backoff\"]\n    end\n\n    REQUEST --> RETRY\n    RETRY --> ATTEMPT1\n    ATTEMPT1 --\"Success\"--> SUCCESS\n    ATTEMPT1 --\"Failure\"--> BACKOFF\n    BACKOFF --> ATTEMPT2\n    ATTEMPT2 --\"Success\"--> SUCCESS\n    ATTEMPT2 --\"Failure\"--> BACKOFF\n    BACKOFF --> ATTEMPT3\n    ATTEMPT3 --\"Success\"--> SUCCESS\n    ATTEMPT3 --\"Failure\"--> FAILURE",
      "flowchart TD\n    subgraph \"R2 Dataset Bucket\"\n        META[\"_metadata.yaml\"]\n        SIZES[\"_shard_sizes.json\"]\n        \n        subgraph \"Config 1\"\n            C1S1[\"shard_0001.parquet\"]\n            C1S2[\"shard_0002.parquet\"]\n            C1S3[\"shard_0003.parquet\"]\n        end\n        \n        subgraph \"Config 2\"\n            C2S1[\"shard_0001.parquet\"]\n            C2S2[\"shard_0002.parquet\"]\n        end\n    end\n    \n    META --> C1S1\n    META --> C1S2\n    META --> C1S3\n    META --> C2S1\n    META --> C2S2\n    \n    SIZES --\"Contains row counts\"--> C1S1\n    SIZES --\"Contains row counts\"--> C1S2\n    SIZES --\"Contains row counts\"--> C1S3\n    SIZES --\"Contains row counts\"--> C2S1\n    SIZES --\"Contains row counts\"--> C2S2",
      "flowchart LR\n    subgraph \"Miner\"\n        MT[\"Model Training\"]\n        ML[\"Data Loading\"]\n        MR2[\"R2DatasetLoader\"]\n    end\n\n    subgraph \"Validator\"\n        VT[\"Evaluation\"]\n        VL[\"Data Loading\"]\n        VR2[\"R2DatasetLoader\"]\n    end\n\n    subgraph \"R2 Storage\"\n        DB[\"Dataset Bucket\"]\n        GB[\"Gradients Bucket\"]\n        AB[\"Aggregator Bucket\"]\n    end\n\n    DB --> MR2\n    MR2 --> ML\n    ML --> MT\n    MT --\"Gradients\"--> GB\n    \n    DB --> VR2\n    VR2 --> VL\n    VL --> VT\n    GB --\"Miner Gradients\"--> VT\n    VT --\"Evaluation Results\"--> AB"
    ],
    "potential_frontmatter": {
      "title": "Data Management"
    }
  },
  "/tplr-ai/templar/7.1-r2-storage": {
    "original_deepwiki_href": "/tplr-ai/templar/7.1-r2-storage",
    "title": "R2 Storage",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/7.1-r2-storage",
    "level": 1,
    "target_astro_path": "/data-management/r2-storage",
    "main_markdown_content": "# R2 Storage\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [LICENSE](LICENSE)\n- [_metadata.yaml](_metadata.yaml)\n- [_shard_sizes.json](_shard_sizes.json)\n- [docs/r2_bucket_management.md](docs/r2_bucket_management.md)\n- [scripts/analyser.py](scripts/analyser.py)\n- [scripts/clean_versions.py](scripts/clean_versions.py)\n- [scripts/cleanup_bucket.py](scripts/cleanup_bucket.py)\n- [scripts/delete_gather.py](scripts/delete_gather.py)\n- [scripts/get_gradients.py](scripts/get_gradients.py)\n- [scripts/s3_manager.py](scripts/s3_manager.py)\n- [scripts/validate_r2_access.py](scripts/validate_r2_access.py)\n- [src/tplr/config.py](src/tplr/config.py)\n- [src/tplr/r2_dataset.py](src/tplr/r2_dataset.py)\n- [tests/test_r2_loader.py](tests/test_r2_loader.py)\n\n</details>\n\n\n\nThis page documents the Cloudflare R2 storage system used in the Templar framework for distributed data exchange. R2 Storage provides reliable object storage that enables efficient sharing of gradients, datasets, checkpoints, and aggregated model data between distributed nodes in the network.\n\n## Overview of R2 Storage in Templar\n\nTemplar uses Cloudflare R2 as its primary storage backend for several critical components of the distributed training ecosystem. R2 Storage serves as the communication medium for exchanging large volumes of data that cannot be efficiently transmitted through the blockchain directly.\n\n```mermaid\nflowchart TD\n    subgraph \"R2 Storage System\"\n        direction TB\n        R2[\"Cloudflare R2\"]\n        \n        subgraph \"R2 Buckets\"\n            GradBucket[\"Gradients Bucket\"]\n            DataBucket[\"Dataset Bucket\"]\n            AggBucket[\"Aggregator Bucket\"]\n        end\n        \n        R2 --- GradBucket\n        R2 --- DataBucket\n        R2 --- AggBucket\n    end\n    \n    subgraph \"Network Nodes\"\n        Miners[\"Miners\"]\n        Validators[\"Validators\"]\n        Aggregator[\"Aggregation Server\"]\n    end\n    \n    Miners -- \"Upload gradients\" --> GradBucket\n    Miners -- \"Download datasets\" --> DataBucket\n    Validators -- \"Download gradients\" --> GradBucket\n    Validators -- \"Download aggregated state\" --> AggBucket\n    Aggregator -- \"Upload aggregated state\" --> AggBucket\n```\n\nSources: [src/tplr/config.py:27-135](), [src/tplr/r2_dataset.py:33-45]()\n\n## Bucket Structure\n\nTemplar uses three primary R2 buckets, each with distinct purposes:\n\n1. **Gradients Bucket**: Stores gradient updates computed by miners. These are compressed via DCT transform to minimize storage requirements and transmission overhead.\n\n2. **Dataset Bucket**: Contains training data in Parquet format, organized by collections and shards. Used by miners to load training data.\n\n3. **Aggregator Bucket**: Stores aggregated model states that are collected from multiple miners' contributions.\n\nEach bucket contains specific file organizations and naming patterns based on its purpose:\n\n```mermaid\nflowchart TD\n    subgraph \"Gradients Bucket Contents\"\n        direction TB\n        GradFiles[\"gradient-{window}-{step}-{version}.pt\\n(Compressed gradient data)\"]\n        CheckFiles[\"checkpoint-{version}-{step}.pt\\n(Model checkpoints)\"]\n        StartFiles[\"start_window-{uid}-{step}.json\\n(Window initializations)\"]\n    end\n    \n    subgraph \"Dataset Bucket Contents\"\n        direction TB\n        DataDir[\"HuggingFaceFW_fineweb-edu-score-2/\"]\n        MetadataFile[\"_metadata.yaml\\n(Dataset configuration)\"]\n        ShardSizes[\"_shard_sizes.json\\n(Row counts per shard)\"]\n        ParquetFiles[\"{config_name}/{split}/train-{shard}.parquet\\n(Actual training data)\"]\n        \n        DataDir --> MetadataFile\n        DataDir --> ShardSizes\n        DataDir --> ParquetFiles\n    end\n    \n    subgraph \"Aggregator Bucket Contents\"\n        direction TB\n        AggFiles[\"gathers/{version}/{step}-{hash}.npz\\n(Aggregated gradient data)\"]\n    end\n```\n\nSources: [_metadata.yaml:1-453](), [_shard_sizes.json:1-467](), [scripts/cleanup_bucket.py:75-81](), [scripts/delete_gather.py:66-87]()\n\n## Configuration and Authentication\n\nTemplar accesses R2 through environment variables that provide authentication credentials and bucket information. Each bucket has separate read and write credentials to enforce proper access control.\n\n### Environment Variable Structure\n\n```mermaid\nflowchart LR\n    subgraph \"R2 Configuration Environment Variables\"\n        direction TB\n        GradEnv[\"R2_GRADIENTS_*\"]\n        DataEnv[\"R2_DATASET_*\"]\n        AggEnv[\"R2_AGGREGATOR_*\"]\n        \n        subgraph \"Per-Bucket Variables\"\n            AccID[\"ACCOUNT_ID\\n(R2 account identifier)\"]\n            BucketName[\"BUCKET_NAME\\n(Bucket name)\"]\n            ReadKey[\"READ_ACCESS_KEY_ID\\n(Read-only credentials)\"]\n            ReadSecret[\"READ_SECRET_ACCESS_KEY\"]\n            WriteKey[\"WRITE_ACCESS_KEY_ID\\n(Write credentials)\"]\n            WriteSecret[\"WRITE_SECRET_ACCESS_KEY\"]\n        end\n        \n        GradEnv --> AccID & BucketName & ReadKey & ReadSecret & WriteKey & WriteSecret\n        DataEnv --> AccID & BucketName & ReadKey & ReadSecret & WriteKey & WriteSecret\n        AggEnv --> AccID & BucketName & ReadKey & ReadSecret & WriteKey & WriteSecret\n    end\n```\n\n### Authentication Flow\n\n```mermaid\nsequenceDiagram\n    participant Node as \"Templar Node\"\n    participant Config as \"BUCKET_SECRETS\"\n    participant S3Client as \"S3 Client\"\n    participant R2 as \"Cloudflare R2\"\n    \n    Node->>Config: Request credentials for bucket type\n    Config->>Node: Return credentials based on operation type (read/write)\n    \n    Node->>S3Client: Initialize client with appropriate credentials\n    S3Client->>R2: Authenticate and establish connection\n    \n    Note over Node,R2: For read operations (e.g., dataset loading)\n    Node->>S3Client: Request object\n    S3Client->>R2: GET object with read credentials\n    R2->>S3Client: Return object data\n    S3Client->>Node: Deliver object data\n    \n    Note over Node,R2: For write operations (e.g., gradient uploads)\n    Node->>S3Client: Upload object\n    S3Client->>R2: PUT object with write credentials\n    R2->>S3Client: Confirm upload\n    S3Client->>Node: Return success status\n```\n\nSources: [src/tplr/config.py:28-134](), [scripts/validate_r2_access.py:27-153]()\n\n## Multiple Dataset Endpoints Support\n\nThe R2 configuration system supports multiple dataset endpoints for load balancing and improved reliability. This feature enables Templar to distribute dataset access across multiple R2 locations.\n\n```mermaid\nflowchart TD\n    subgraph \"R2DatasetLoader Multiple Endpoint Handling\"\n        direction TB\n        Config[\"BUCKET_SECRETS['dataset']['multiple']\"]\n        RoundRobin[\"Round Robin Selection (_round_robin_index)\"]\n        FSCache[\"Filesystem Cache (_fs_cache)\"]\n        \n        Config --> RoundRobin\n        RoundRobin --> |\"Select endpoint\"| FSCache\n        FSCache --> |\"Cached connection\"| S3FileSystem\n    end\n    \n    subgraph \"Dataset Access\"\n        DataNode1[\"Dataset Bucket 1\"]\n        DataNode2[\"Dataset Bucket 2\"]\n        DataNode3[\"Dataset Bucket 3\"]\n    end\n    \n    S3FileSystem --> DataNode1\n    S3FileSystem --> DataNode2\n    S3FileSystem --> DataNode3\n```\n\nSources: [src/tplr/r2_dataset.py:339-369](), [src/tplr/config.py:89-109]()\n\n## R2DatasetLoader\n\nThe `R2DatasetLoader` class is a specialized component for loading training data from R2 storage. It's designed to efficiently load, cache, and process Parquet files containing training text data.\n\n### Dataset Loading Process\n\n```mermaid\nsequenceDiagram\n    participant App as \"Templar Node\"\n    participant Loader as \"R2DatasetLoader\"\n    participant Cache as \"Local Cache\"\n    participant R2 as \"R2 Dataset Bucket\"\n    \n    App->>Loader: Request pages with seed\n    Loader->>Loader: Generate random page selection\n    \n    Loader->>Cache: Check for cached metadata\n    alt Metadata not in cache\n        Loader->>R2: Fetch _metadata.yaml and _shard_sizes.json\n        R2->>Loader: Return metadata files\n        Loader->>Cache: Store metadata\n    end\n    \n    loop For each requested page\n        Loader->>Loader: Compute exact shard and offset\n        Loader->>Cache: Check for cached ParquetFile\n        \n        alt ParquetFile not in cache\n            Loader->>R2: Open Parquet file with retries\n            R2->>Loader: Return file handle\n            Loader->>Cache: Cache ParquetFile\n        end\n        \n        Loader->>R2: Read specific row group\n        R2->>Loader: Return row data\n        Loader->>Loader: Extract and tokenize text\n        Loader->>Cache: Cache tokenized result\n    end\n    \n    Loader->>App: Return processed text batches\n```\n\n### Performance Optimizations\n\nThe `R2DatasetLoader` implements numerous optimizations to efficiently handle distributed dataset access:\n\n1. **Multi-level caching**:\n   - Filesystem instance caching\n   - Parquet file caching\n   - Tokenized result caching\n   - Metadata caching\n\n2. **Distributed load balancing**:\n   - Round-robin selection of multiple dataset endpoints\n   - Thread-safe access patterns\n\n3. **Resilient operation**:\n   - Retries with exponential backoff\n   - Connection pooling\n   - Error handling for transient failures\n\n4. **Memory and bandwidth efficiency**:\n   - Read specific row groups instead of entire files\n   - Parallel tokenization and processing\n   - Optimized buffer sizes\n\nSources: [src/tplr/r2_dataset.py:33-594](), [tests/test_r2_loader.py:64-220]()\n\n## Storage Management and Maintenance\n\nTemplar includes utility scripts for maintaining R2 storage:\n\n### Bucket Maintenance Tools\n\n1. **cleanup_bucket.py**: Deletes temporary files like checkpoints, gradients, and start window markers.\n\n2. **delete_gather.py**: Removes aggregated gradient data from specific versions.\n\n3. **s3_manager.py**: General-purpose R2 bucket management tool with features for:\n   - Deleting objects older than X hours\n   - Deleting objects with specific prefixes or suffixes\n   - Wiping buckets (with confirmation prompts)\n   - Supporting different credential sets for different buckets\n\n```mermaid\nflowchart TD\n    subgraph \"R2 Storage Maintenance Tools\"\n        direction TB\n        CleanupBucket[\"cleanup_bucket.py\\n(Clean temporary files)\"]\n        DeleteGather[\"delete_gather.py\\n(Remove version-specific data)\"]\n        S3Manager[\"s3_manager.py\\n(General bucket management)\"]\n        \n        S3Manager -->|\"--delete-old\"| DeleteOld[\"Delete objects older than X hours\"]\n        S3Manager -->|\"--prefix\"| DeletePrefix[\"Delete objects with specific prefix\"]\n        S3Manager -->|\"--suffix\"| DeleteSuffix[\"Delete objects with specific suffix\"]\n        S3Manager -->|\"--wipe-bucket\"| Wipe[\"Delete ALL objects (dangerous)\"]\n    end\n    \n    subgraph \"Environment Configuration\"\n        EnvVars[\"Environment Variables\"]\n    end\n    \n    EnvVars --> CleanupBucket & DeleteGather & S3Manager\n```\n\nSources: [scripts/cleanup_bucket.py:32-114](), [scripts/s3_manager.py:15-441](), [scripts/delete_gather.py:31-116](), [scripts/clean_versions.py:29-120]()\n\n## Integration with Templar Components\n\nThe R2 storage system integrates closely with the core components of the Templar framework:\n\n```mermaid\nflowchart TD\n    subgraph \"R2 Storage Integration\"\n        direction TB\n        R2[\"Cloudflare R2\"]\n        GradBucket[\"Gradients Bucket\"]\n        DataBucket[\"Dataset Bucket\"] \n        AggBucket[\"Aggregator Bucket\"]\n    end\n    \n    subgraph \"Miner Operations\"\n        MinerTrain[\"Model Training\"]\n        GradComp[\"Gradient Computation\"]\n        GradCompress[\"Gradient Compression\"]\n        DataLoad[\"R2DatasetLoader\"]\n    end\n    \n    subgraph \"Validator Operations\"\n        GradDecomp[\"Gradient Decompression\"]\n        EvalGrad[\"Gradient Evaluation\"]\n        SetWeights[\"Set Weights on Chain\"]\n    end\n    \n    subgraph \"Aggregator Operations\"\n        Gather[\"Gather Gradients\"]\n        Aggregate[\"Aggregate Updates\"]\n        StoreAgg[\"Store Aggregated State\"]\n    end\n    \n    DataBucket -->|\"Load training data\"| DataLoad\n    DataLoad -->|\"Tokenized text\"| MinerTrain\n    MinerTrain -->|\"Model updates\"| GradComp\n    GradComp -->|\"Gradient tensors\"| GradCompress\n    GradCompress -->|\"Compressed gradients\"| GradBucket\n    \n    GradBucket -->|\"Download gradients\"| GradDecomp\n    GradDecomp -->|\"Reconstructed gradients\"| EvalGrad\n    EvalGrad -->|\"Quality score\"| SetWeights\n    \n    GradBucket -->|\"Download multiple gradients\"| Gather\n    Gather -->|\"Combined gradients\"| Aggregate\n    Aggregate -->|\"Aggregated state\"| StoreAgg\n    StoreAgg -->|\"Upload aggregated model\"| AggBucket\n```\n\nSources: [src/tplr/config.py:27-135](), [src/tplr/r2_dataset.py:33-45]()\n\n## Security Considerations\n\nThe R2 storage system implements several security measures:\n\n1. **Separate read and write credentials**:\n   - Read-only credentials for operations that only need to fetch data\n   - Write credentials carefully restricted to components that need to modify data\n\n2. **Access validation**:\n   - The `validate_r2_access.py` script verifies access permissions\n   - Tests for correct isolation between read and write permissions\n\n3. **Environment variable management**:\n   - Credentials stored in environment variables, not hard-coded\n   - Required variables checked at startup\n\nSources: [scripts/validate_r2_access.py:25-153](), [src/tplr/config.py:111-133]()\n\n## Troubleshooting and Maintenance\n\nCommon R2 storage issues and their solutions:\n\n| Issue | Possible Cause | Solution |\n|-------|----------------|----------|\n| Missing data files | Incorrect bucket configuration | Verify environment variables are correctly set |\n| Access denied errors | Invalid or expired credentials | Update R2 tokens and verify with validate_r2_access.py |\n| Slow data loading | Network congestion or high latency | Implement additional caching or add more dataset endpoints |\n| Out of storage space | Accumulated gradient or checkpoint files | Run cleanup scripts to remove old objects |\n| Timeout errors | Connection issues | Increase retry attempts and backoff in config |\n\nSources: [scripts/validate_r2_access.py:25-153](), [tests/test_r2_loader.py:311-438]()\n\n## Related Pages\n\nFor information about how dataset loading works beyond just the R2 storage aspect, see [Data Management](#7).\n\nFor details on how gradient sharing occurs within the network, see [Gradient Processing](#2.1).\n\nFor information on checkpoint management using R2 storage, see [Checkpoint Management](#6.1).",
    "resolved_links": [
      {
        "text": "LICENSE",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/LICENSE",
        "original_deepwiki_href": "LICENSE",
        "context": "collapsible_aside_link"
      },
      {
        "text": "_metadata.yaml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/_metadata.yaml",
        "original_deepwiki_href": "_metadata.yaml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "_shard_sizes.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/_shard_sizes.json",
        "original_deepwiki_href": "_shard_sizes.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docs/r2_bucket_management.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docs/r2_bucket_management.md",
        "original_deepwiki_href": "docs/r2_bucket_management.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/analyser.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/analyser.py",
        "original_deepwiki_href": "scripts/analyser.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/clean_versions.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/clean_versions.py",
        "original_deepwiki_href": "scripts/clean_versions.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/cleanup_bucket.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/cleanup_bucket.py",
        "original_deepwiki_href": "scripts/cleanup_bucket.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/delete_gather.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/delete_gather.py",
        "original_deepwiki_href": "scripts/delete_gather.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/get_gradients.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/get_gradients.py",
        "original_deepwiki_href": "scripts/get_gradients.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/s3_manager.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/s3_manager.py",
        "original_deepwiki_href": "scripts/s3_manager.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/validate_r2_access.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/validate_r2_access.py",
        "original_deepwiki_href": "scripts/validate_r2_access.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/config.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/config.py",
        "original_deepwiki_href": "src/tplr/config.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/r2_dataset.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/r2_dataset.py",
        "original_deepwiki_href": "src/tplr/r2_dataset.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_r2_loader.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_r2_loader.py",
        "original_deepwiki_href": "tests/test_r2_loader.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/config.py:27-135",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:33-45",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "_metadata.yaml:1-453",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "_shard_sizes.json:1-467",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/cleanup_bucket.py:75-81",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/delete_gather.py:66-87",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/config.py:28-134",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/validate_r2_access.py:27-153",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:339-369",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/config.py:89-109",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/r2_dataset.py:33-594",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_r2_loader.py:64-220",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/cleanup_bucket.py:32-114",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/s3_manager.py:15-441",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/delete_gather.py:31-116",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/clean_versions.py:29-120",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/validate_r2_access.py:25-153",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/config.py:111-133",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_r2_loader.py:311-438",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Data Management",
        "href": "/data-management#7",
        "original_deepwiki_href": "#7",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Gradient Processing",
        "href": "/miners/gradient-processing#2.1",
        "original_deepwiki_href": "#2.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Checkpoint Management",
        "href": "/communication-system/checkpoint-management#6.1",
        "original_deepwiki_href": "#6.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"R2 Storage System\"\n        direction TB\n        R2[\"Cloudflare R2\"]\n        \n        subgraph \"R2 Buckets\"\n            GradBucket[\"Gradients Bucket\"]\n            DataBucket[\"Dataset Bucket\"]\n            AggBucket[\"Aggregator Bucket\"]\n        end\n        \n        R2 --- GradBucket\n        R2 --- DataBucket\n        R2 --- AggBucket\n    end\n    \n    subgraph \"Network Nodes\"\n        Miners[\"Miners\"]\n        Validators[\"Validators\"]\n        Aggregator[\"Aggregation Server\"]\n    end\n    \n    Miners -- \"Upload gradients\" --> GradBucket\n    Miners -- \"Download datasets\" --> DataBucket\n    Validators -- \"Download gradients\" --> GradBucket\n    Validators -- \"Download aggregated state\" --> AggBucket\n    Aggregator -- \"Upload aggregated state\" --> AggBucket",
      "flowchart TD\n    subgraph \"Gradients Bucket Contents\"\n        direction TB\n        GradFiles[\"gradient-{window}-{step}-{version}.pt\\n(Compressed gradient data)\"]\n        CheckFiles[\"checkpoint-{version}-{step}.pt\\n(Model checkpoints)\"]\n        StartFiles[\"start_window-{uid}-{step}.json\\n(Window initializations)\"]\n    end\n    \n    subgraph \"Dataset Bucket Contents\"\n        direction TB\n        DataDir[\"HuggingFaceFW_fineweb-edu-score-2/\"]\n        MetadataFile[\"_metadata.yaml\\n(Dataset configuration)\"]\n        ShardSizes[\"_shard_sizes.json\\n(Row counts per shard)\"]\n        ParquetFiles[\"{config_name}/{split}/train-{shard}.parquet\\n(Actual training data)\"]\n        \n        DataDir --> MetadataFile\n        DataDir --> ShardSizes\n        DataDir --> ParquetFiles\n    end\n    \n    subgraph \"Aggregator Bucket Contents\"\n        direction TB\n        AggFiles[\"gathers/{version}/{step}-{hash}.npz\\n(Aggregated gradient data)\"]\n    end",
      "flowchart LR\n    subgraph \"R2 Configuration Environment Variables\"\n        direction TB\n        GradEnv[\"R2_GRADIENTS_*\"]\n        DataEnv[\"R2_DATASET_*\"]\n        AggEnv[\"R2_AGGREGATOR_*\"]\n        \n        subgraph \"Per-Bucket Variables\"\n            AccID[\"ACCOUNT_ID\\n(R2 account identifier)\"]\n            BucketName[\"BUCKET_NAME\\n(Bucket name)\"]\n            ReadKey[\"READ_ACCESS_KEY_ID\\n(Read-only credentials)\"]\n            ReadSecret[\"READ_SECRET_ACCESS_KEY\"]\n            WriteKey[\"WRITE_ACCESS_KEY_ID\\n(Write credentials)\"]\n            WriteSecret[\"WRITE_SECRET_ACCESS_KEY\"]\n        end\n        \n        GradEnv --> AccID & BucketName & ReadKey & ReadSecret & WriteKey & WriteSecret\n        DataEnv --> AccID & BucketName & ReadKey & ReadSecret & WriteKey & WriteSecret\n        AggEnv --> AccID & BucketName & ReadKey & ReadSecret & WriteKey & WriteSecret\n    end",
      "sequenceDiagram\n    participant Node as \"Templar Node\"\n    participant Config as \"BUCKET_SECRETS\"\n    participant S3Client as \"S3 Client\"\n    participant R2 as \"Cloudflare R2\"\n    \n    Node->>Config: Request credentials for bucket type\n    Config->>Node: Return credentials based on operation type (read/write)\n    \n    Node->>S3Client: Initialize client with appropriate credentials\n    S3Client->>R2: Authenticate and establish connection\n    \n    Note over Node,R2: For read operations (e.g., dataset loading)\n    Node->>S3Client: Request object\n    S3Client->>R2: GET object with read credentials\n    R2->>S3Client: Return object data\n    S3Client->>Node: Deliver object data\n    \n    Note over Node,R2: For write operations (e.g., gradient uploads)\n    Node->>S3Client: Upload object\n    S3Client->>R2: PUT object with write credentials\n    R2->>S3Client: Confirm upload\n    S3Client->>Node: Return success status",
      "flowchart TD\n    subgraph \"R2DatasetLoader Multiple Endpoint Handling\"\n        direction TB\n        Config[\"BUCKET_SECRETS['dataset']['multiple']\"]\n        RoundRobin[\"Round Robin Selection (_round_robin_index)\"]\n        FSCache[\"Filesystem Cache (_fs_cache)\"]\n        \n        Config --> RoundRobin\n        RoundRobin --> |\"Select endpoint\"| FSCache\n        FSCache --> |\"Cached connection\"| S3FileSystem\n    end\n    \n    subgraph \"Dataset Access\"\n        DataNode1[\"Dataset Bucket 1\"]\n        DataNode2[\"Dataset Bucket 2\"]\n        DataNode3[\"Dataset Bucket 3\"]\n    end\n    \n    S3FileSystem --> DataNode1\n    S3FileSystem --> DataNode2\n    S3FileSystem --> DataNode3",
      "sequenceDiagram\n    participant App as \"Templar Node\"\n    participant Loader as \"R2DatasetLoader\"\n    participant Cache as \"Local Cache\"\n    participant R2 as \"R2 Dataset Bucket\"\n    \n    App->>Loader: Request pages with seed\n    Loader->>Loader: Generate random page selection\n    \n    Loader->>Cache: Check for cached metadata\n    alt Metadata not in cache\n        Loader->>R2: Fetch _metadata.yaml and _shard_sizes.json\n        R2->>Loader: Return metadata files\n        Loader->>Cache: Store metadata\n    end\n    \n    loop For each requested page\n        Loader->>Loader: Compute exact shard and offset\n        Loader->>Cache: Check for cached ParquetFile\n        \n        alt ParquetFile not in cache\n            Loader->>R2: Open Parquet file with retries\n            R2->>Loader: Return file handle\n            Loader->>Cache: Cache ParquetFile\n        end\n        \n        Loader->>R2: Read specific row group\n        R2->>Loader: Return row data\n        Loader->>Loader: Extract and tokenize text\n        Loader->>Cache: Cache tokenized result\n    end\n    \n    Loader->>App: Return processed text batches",
      "flowchart TD\n    subgraph \"R2 Storage Maintenance Tools\"\n        direction TB\n        CleanupBucket[\"cleanup_bucket.py\\n(Clean temporary files)\"]\n        DeleteGather[\"delete_gather.py\\n(Remove version-specific data)\"]\n        S3Manager[\"s3_manager.py\\n(General bucket management)\"]\n        \n        S3Manager -->|\"--delete-old\"| DeleteOld[\"Delete objects older than X hours\"]\n        S3Manager -->|\"--prefix\"| DeletePrefix[\"Delete objects with specific prefix\"]\n        S3Manager -->|\"--suffix\"| DeleteSuffix[\"Delete objects with specific suffix\"]\n        S3Manager -->|\"--wipe-bucket\"| Wipe[\"Delete ALL objects (dangerous)\"]\n    end\n    \n    subgraph \"Environment Configuration\"\n        EnvVars[\"Environment Variables\"]\n    end\n    \n    EnvVars --> CleanupBucket & DeleteGather & S3Manager",
      "flowchart TD\n    subgraph \"R2 Storage Integration\"\n        direction TB\n        R2[\"Cloudflare R2\"]\n        GradBucket[\"Gradients Bucket\"]\n        DataBucket[\"Dataset Bucket\"] \n        AggBucket[\"Aggregator Bucket\"]\n    end\n    \n    subgraph \"Miner Operations\"\n        MinerTrain[\"Model Training\"]\n        GradComp[\"Gradient Computation\"]\n        GradCompress[\"Gradient Compression\"]\n        DataLoad[\"R2DatasetLoader\"]\n    end\n    \n    subgraph \"Validator Operations\"\n        GradDecomp[\"Gradient Decompression\"]\n        EvalGrad[\"Gradient Evaluation\"]\n        SetWeights[\"Set Weights on Chain\"]\n    end\n    \n    subgraph \"Aggregator Operations\"\n        Gather[\"Gather Gradients\"]\n        Aggregate[\"Aggregate Updates\"]\n        StoreAgg[\"Store Aggregated State\"]\n    end\n    \n    DataBucket -->|\"Load training data\"| DataLoad\n    DataLoad -->|\"Tokenized text\"| MinerTrain\n    MinerTrain -->|\"Model updates\"| GradComp\n    GradComp -->|\"Gradient tensors\"| GradCompress\n    GradCompress -->|\"Compressed gradients\"| GradBucket\n    \n    GradBucket -->|\"Download gradients\"| GradDecomp\n    GradDecomp -->|\"Reconstructed gradients\"| EvalGrad\n    EvalGrad -->|\"Quality score\"| SetWeights\n    \n    GradBucket -->|\"Download multiple gradients\"| Gather\n    Gather -->|\"Combined gradients\"| Aggregate\n    Aggregate -->|\"Aggregated state\"| StoreAgg\n    StoreAgg -->|\"Upload aggregated model\"| AggBucket"
    ],
    "potential_frontmatter": {
      "title": "R2 Storage"
    }
  },
  "/tplr-ai/templar/8-deployment": {
    "original_deepwiki_href": "/tplr-ai/templar/8-deployment",
    "title": "Deployment",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/8-deployment",
    "level": 0,
    "target_astro_path": "/deployment",
    "main_markdown_content": "# Deployment\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [.github/workflows/docker.yml](.github/workflows/docker.yml)\n- [ansible/README.md](ansible/README.md)\n- [ansible/group_vars/all/vault.yml.example](ansible/group_vars/all/vault.yml.example)\n- [ansible/playbook.yml](ansible/playbook.yml)\n- [ansible/roles/templar/defaults/main.yml](ansible/roles/templar/defaults/main.yml)\n- [ansible/roles/templar/templates/miner.service.j2](ansible/roles/templar/templates/miner.service.j2)\n- [docker/Dockerfile](docker/Dockerfile)\n- [docker/compose.yml](docker/compose.yml)\n- [docker/docker-compose-test.yml](docker/docker-compose-test.yml)\n- [scripts/entrypoint.sh](scripts/entrypoint.sh)\n\n</details>\n\n\n\nThis page provides an overview of deployment options and considerations for the Templar decentralized training framework. It covers Docker-based and Ansible-based deployment approaches, environment configuration, and resource requirements for running miner and validator nodes.\n\nFor Docker-specific deployment details, see [Docker Deployment](#8.1). For Ansible-specific deployment instructions, see [Ansible Deployment](#8.2).\n\n## Deployment Options Overview\n\nThe Templar framework offers two primary deployment methods:\n\n1. **Docker-based deployment** - Containerized approach with Docker and Docker Compose\n2. **Ansible-based deployment** - Infrastructure-as-code approach for configuring hosts\n\nThe choice between these depends on your operational requirements, infrastructure management approach, and team preferences.\n\n```mermaid\nflowchart TD\n    subgraph \"Deployment Options\"\n        D[\"Docker Deployment\"] --> DC[\"Docker Compose\"]\n        D --> DT[\"Docker Test Environment\"]\n        A[\"Ansible Deployment\"] --> AP[\"Ansible Playbooks\"]\n        A --> AR[\"Ansible Roles\"]\n    end\n    \n    subgraph \"Operational Components\"\n        N[\"Node Types\"]\n        N --> M[\"Miner\"]\n        N --> V[\"Validator\"]\n        RM[\"Resource Management\"]\n        RM --> GPU[\"GPU Assignment\"]\n        RM --> MEM[\"Memory Allocation\"]\n        EV[\"Environment Variables\"]\n        WT[\"Watchtower Updates\"]\n    end\n    \n    D --> N\n    D --> RM\n    D --> EV\n    D --> WT\n    A --> N\n    A --> RM\n    A --> EV\n```\n\nSources: [docker/compose.yml](), [docker/Dockerfile](), [ansible/playbook.yml](), [ansible/README.md]()\n\n## Docker Deployment Architecture\n\nDocker is the most streamlined deployment method for Templar, using NVIDIA GPU-enabled containers.\n\n```mermaid\nflowchart TD\n    subgraph \"Docker Host\"\n        subgraph \"Templar Node Container\"\n            E[\"Entrypoint.sh\"] --> N[\"Node Process\"]\n            N --> M[\"Miner.py\"] \n            N --> V[\"Validator.py\"]\n            ENV[\"Environment Variables\"]\n            VOL[\"Volumes\"]\n            VOL --> W[\"Wallets\"]\n            VOL --> L[\"Logs\"]\n        end\n        \n        subgraph \"Watchtower Container\"\n            WT[\"Watchtower Service\"]\n            WT --> IM[\"Image Updates\"]\n            WT --> CR[\"Container Restart\"]\n        end\n        \n        GPUs[\"NVIDIA GPUs\"]\n        GPUs --> N\n    end\n    \n    GH[\"GitHub Container Registry\"] --> WT\n```\n\nSources: [docker/compose.yml](), [docker/Dockerfile](), [scripts/entrypoint.sh]()\n\n### Docker Image\n\nThe Templar Docker image is based on NVIDIA's CUDA runtime image, with Python and essential dependencies installed:\n\n- Base image: `nvidia/cuda:12.6.0-runtime-ubuntu22.04`\n- Python with dependencies installed via `uv`\n- Entrypoint script for node startup\n\nThe official image is published to GitHub Container Registry as `ghcr.io/tplr-ai/templar`.\n\nSources: [docker/Dockerfile](), [.github/workflows/docker.yml]()\n\n### Docker Compose Configuration\n\nThe `docker-compose.yml` file defines the services required for running Templar nodes:\n\n1. **node service** - Configures the Templar node (miner or validator)\n2. **watchtower service** - Provides automatic updates of container images\n\nKey configuration aspects include:\n\n- Volume mounts for wallet and log persistence\n- Environment variable configuration\n- GPU device assignment\n- Automatic updates via Watchtower\n\nFor testing environments, a `docker-compose-test.yml` is provided that configures a multi-node setup with miners and validators.\n\nSources: [docker/compose.yml](), [docker/docker-compose-test.yml]()\n\n### Environment Variables for Docker Deployment\n\nDocker deployments require a number of environment variables to configure node behavior, access storage resources, and connect to the Bittensor network.\n\n| Category | Variable Name | Description | Required |\n|----------|--------------|-------------|----------|\n| **Node Configuration** | NODE_TYPE | Either \"miner\" or \"validator\" | Yes |\n| | WALLET_NAME | Bittensor wallet name | Yes |\n| | WALLET_HOTKEY | Bittensor wallet hotkey | Yes |\n| | CUDA_DEVICE | CUDA device to use (e.g., \"cuda:0\") | Yes |\n| | NETWORK | Bittensor network (e.g., \"finney\", \"test\") | Yes |\n| | NETUID | Bittensor subnet UID | Yes |\n| | DEBUG | Enable debug mode (true/false) | No |\n| **API Keys** | WANDB_API_KEY | Weights & Biases API key | Yes |\n| **R2 Storage** | R2_GRADIENTS_ACCOUNT_ID | Cloudflare R2 account ID | Yes |\n| | R2_GRADIENTS_BUCKET_NAME | Bucket name for gradients | Yes |\n| | R2_GRADIENTS_READ_ACCESS_KEY_ID | Read access key ID | Yes |\n| | R2_GRADIENTS_READ_SECRET_ACCESS_KEY | Read secret access key | Yes |\n| | R2_GRADIENTS_WRITE_ACCESS_KEY_ID | Write access key ID | Yes |\n| | R2_GRADIENTS_WRITE_SECRET_ACCESS_KEY | Write secret access key | Yes |\n| | R2_DATASET_* | Similar set of variables for dataset bucket | Yes |\n| | R2_AGGREGATOR_* | Similar set of variables for aggregator bucket | Yes |\n| **GitHub Integration** | GITHUB_USER | GitHub username for Watchtower | No |\n| | GITHUB_TOKEN | GitHub token for Watchtower | No |\n\nSources: [docker/compose.yml](), [scripts/entrypoint.sh]()\n\n## Ansible Deployment Approach\n\nAnsible provides a more infrastructure-focused approach to deployment, suitable for managing multiple machines or complex deployments.\n\n```mermaid\nflowchart TD\n    subgraph \"Control Machine\"\n        A[\"Ansible Playbook\"]\n        IT[\"Inventory\"]\n        VT[\"Vault\"]\n    end\n    \n    subgraph \"Target Host\"\n        subgraph \"Per GPU\"\n            TR[\"Templar Repository\"]\n            EV[\"Environment Configuration\"]\n            VE[\"Python venv\"]\n            SD[\"Systemd Service\"]\n            G[\"GPU Assignment\"]\n        end\n        APT[\"System Packages\"]\n        PIP[\"Global Pip Packages\"]\n    end\n    \n    A --> IT\n    A --> VT\n    A --> APT\n    A --> PIP\n    A --> TR\n    A --> EV\n    A --> VE\n    A --> SD\n    EV --> G\n```\n\nSources: [ansible/playbook.yml](), [ansible/roles/templar/defaults/main.yml](), [ansible/README.md]()\n\n### Ansible Configuration\n\nThe Ansible deployment requires:\n\n1. **Inventory file** - Defines target hosts and their GPU configurations\n2. **Vault file** - Securely stores environment variables and secrets\n3. **Playbook** - Orchestrates the deployment process\n\nThe Ansible setup supports multi-GPU deployments, creating separate instances for each GPU with dedicated directories and services.\n\nKey files:\n- `ansible/playbook.yml` - Main playbook\n- `ansible/roles/templar/*` - Role definitions\n- `group_vars/all/vault.yml` - Encrypted variables\n\nSources: [ansible/playbook.yml](), [ansible/roles/templar/defaults/main.yml](), [ansible/README.md](), [ansible/group_vars/all/vault.yml.example]()\n\n### Systemd Service Configuration\n\nFor persistent operation, the Ansible deployment can configure systemd services to manage Templar processes:\n\n```\n[Unit]\nDescription=Templar Miner Service\nAfter=network.target\n\n[Service]\nWorkingDirectory=/path/to/templar\nEnvironmentFile=/path/to/templar/.env\nExecStart=/path/to/templar/.venv/bin/python neurons/miner.py [options]\nRestart=always\nRestartSec=5s\n```\n\nThis ensures automatic restart on failure and proper startup sequence.\n\nSources: [ansible/roles/templar/templates/miner.service.j2]()\n\n## Resource Requirements\n\nTemplar requires:\n\n- CUDA-capable NVIDIA GPU(s)\n- Sufficient RAM for model operations\n- Storage for checkpoints and logs\n- Network connectivity for Bittensor communication and R2 storage access\n\nThe docker-compose configuration allows assigning specific GPUs to containers using the device_ids property:\n\n```yaml\ndeploy:\n  resources:\n    reservations:\n      devices:\n        - driver: nvidia\n          device_ids: [ '0', '1', '2' ]\n          capabilities: [ gpu ]\n```\n\nSources: [docker/compose.yml](), [docker/docker-compose-test.yml]()\n\n## CI/CD Pipeline\n\nTemplar includes a GitHub Actions workflow for building and publishing Docker images:\n\n```mermaid\nflowchart TD\n    subgraph \"GitHub Actions Workflow\"\n        T[\"Trigger\"] --> C[\"Checkout Code\"]\n        C --> S[\"Setup Docker Buildx\"]\n        S --> L[\"Login to Registry\"]\n        L --> M[\"Extract Metadata\"]\n        M --> B[\"Build Docker Image\"]\n        B --> P[\"Push to Registry\"]\n    end\n    \n    subgraph \"Triggers\"\n        REL[\"Release Published\"]\n        WD[\"Workflow Dispatch\"]\n    end\n    \n    subgraph \"Tags Generated\"\n        SV[\"Semantic Version Tags\"]\n        LT[\"Latest Tag\"]\n        SHA[\"SHA Tags\"]\n    end\n    \n    REL --> T\n    WD --> T\n    M --> SV\n    M --> LT\n    M --> SHA\n```\n\nThe workflow automatically builds images when releases are published and tags them appropriately based on semantic versioning.\n\nSources: [.github/workflows/docker.yml]()\n\n## Startup Process\n\nWhen a Templar container starts, the entrypoint script (`scripts/entrypoint.sh`) performs several initialization steps:\n\n1. Validates required environment variables\n2. Activates Python virtual environment\n3. Checks CUDA availability\n4. Logs in to Weights & Biases\n5. Starts the appropriate node type (miner or validator)\n\nThe script constructs the correct command-line arguments based on environment variables.\n\nSources: [scripts/entrypoint.sh]()\n\n## Troubleshooting\n\nCommon deployment issues include:\n\n1. **CUDA availability** - Ensure NVIDIA drivers are installed and compatible with the container's CUDA version\n2. **Environment variables** - Check that all required variables are set correctly\n3. **GPU assignment** - Verify that GPUs are correctly assigned to containers\n4. **Network connectivity** - Ensure access to Bittensor network and R2 storage\n\nFor Docker deployments, you can check logs with:\n```\ndocker logs templar-{NODE_TYPE}-{WALLET_HOTKEY}\n```\n\nFor Ansible deployments with systemd, check:\n```\nsystemctl status templar-miner\njournalctl -u templar-miner\n```\n\nSources: [scripts/entrypoint.sh](), [docker/compose.yml](), [ansible/roles/templar/templates/miner.service.j2]()",
    "resolved_links": [
      {
        "text": ".github/workflows/docker.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/.github/workflows/docker.yml",
        "original_deepwiki_href": ".github/workflows/docker.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/README.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/README.md",
        "original_deepwiki_href": "ansible/README.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/group_vars/all/vault.yml.example",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/group_vars/all/vault.yml.example",
        "original_deepwiki_href": "ansible/group_vars/all/vault.yml.example",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/playbook.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/playbook.yml",
        "original_deepwiki_href": "ansible/playbook.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/roles/templar/defaults/main.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/roles/templar/defaults/main.yml",
        "original_deepwiki_href": "ansible/roles/templar/defaults/main.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/roles/templar/templates/miner.service.j2",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/roles/templar/templates/miner.service.j2",
        "original_deepwiki_href": "ansible/roles/templar/templates/miner.service.j2",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docker/Dockerfile",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docker/Dockerfile",
        "original_deepwiki_href": "docker/Dockerfile",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docker/compose.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docker/compose.yml",
        "original_deepwiki_href": "docker/compose.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docker/docker-compose-test.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docker/docker-compose-test.yml",
        "original_deepwiki_href": "docker/docker-compose-test.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/entrypoint.sh",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/entrypoint.sh",
        "original_deepwiki_href": "scripts/entrypoint.sh",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docker/compose.yml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "docker/Dockerfile",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/playbook.yml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/entrypoint.sh",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/docker.yml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "docker/docker-compose-test.yml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/roles/templar/defaults/main.yml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/group_vars/all/vault.yml.example",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/roles/templar/templates/miner.service.j2",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Docker Deployment",
        "href": "/deployment/docker-deployment#8.1",
        "original_deepwiki_href": "#8.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Ansible Deployment",
        "href": "/deployment/ansible-deployment#8.2",
        "original_deepwiki_href": "#8.2",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Deployment Options\"\n        D[\"Docker Deployment\"] --> DC[\"Docker Compose\"]\n        D --> DT[\"Docker Test Environment\"]\n        A[\"Ansible Deployment\"] --> AP[\"Ansible Playbooks\"]\n        A --> AR[\"Ansible Roles\"]\n    end\n    \n    subgraph \"Operational Components\"\n        N[\"Node Types\"]\n        N --> M[\"Miner\"]\n        N --> V[\"Validator\"]\n        RM[\"Resource Management\"]\n        RM --> GPU[\"GPU Assignment\"]\n        RM --> MEM[\"Memory Allocation\"]\n        EV[\"Environment Variables\"]\n        WT[\"Watchtower Updates\"]\n    end\n    \n    D --> N\n    D --> RM\n    D --> EV\n    D --> WT\n    A --> N\n    A --> RM\n    A --> EV",
      "flowchart TD\n    subgraph \"Docker Host\"\n        subgraph \"Templar Node Container\"\n            E[\"Entrypoint.sh\"] --> N[\"Node Process\"]\n            N --> M[\"Miner.py\"] \n            N --> V[\"Validator.py\"]\n            ENV[\"Environment Variables\"]\n            VOL[\"Volumes\"]\n            VOL --> W[\"Wallets\"]\n            VOL --> L[\"Logs\"]\n        end\n        \n        subgraph \"Watchtower Container\"\n            WT[\"Watchtower Service\"]\n            WT --> IM[\"Image Updates\"]\n            WT --> CR[\"Container Restart\"]\n        end\n        \n        GPUs[\"NVIDIA GPUs\"]\n        GPUs --> N\n    end\n    \n    GH[\"GitHub Container Registry\"] --> WT",
      "flowchart TD\n    subgraph \"Control Machine\"\n        A[\"Ansible Playbook\"]\n        IT[\"Inventory\"]\n        VT[\"Vault\"]\n    end\n    \n    subgraph \"Target Host\"\n        subgraph \"Per GPU\"\n            TR[\"Templar Repository\"]\n            EV[\"Environment Configuration\"]\n            VE[\"Python venv\"]\n            SD[\"Systemd Service\"]\n            G[\"GPU Assignment\"]\n        end\n        APT[\"System Packages\"]\n        PIP[\"Global Pip Packages\"]\n    end\n    \n    A --> IT\n    A --> VT\n    A --> APT\n    A --> PIP\n    A --> TR\n    A --> EV\n    A --> VE\n    A --> SD\n    EV --> G",
      "flowchart TD\n    subgraph \"GitHub Actions Workflow\"\n        T[\"Trigger\"] --> C[\"Checkout Code\"]\n        C --> S[\"Setup Docker Buildx\"]\n        S --> L[\"Login to Registry\"]\n        L --> M[\"Extract Metadata\"]\n        M --> B[\"Build Docker Image\"]\n        B --> P[\"Push to Registry\"]\n    end\n    \n    subgraph \"Triggers\"\n        REL[\"Release Published\"]\n        WD[\"Workflow Dispatch\"]\n    end\n    \n    subgraph \"Tags Generated\"\n        SV[\"Semantic Version Tags\"]\n        LT[\"Latest Tag\"]\n        SHA[\"SHA Tags\"]\n    end\n    \n    REL --> T\n    WD --> T\n    M --> SV\n    M --> LT\n    M --> SHA"
    ],
    "potential_frontmatter": {
      "title": "Deployment"
    }
  },
  "/tplr-ai/templar/8.1-docker-deployment": {
    "original_deepwiki_href": "/tplr-ai/templar/8.1-docker-deployment",
    "title": "Docker Deployment",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/8.1-docker-deployment",
    "level": 1,
    "target_astro_path": "/deployment/docker-deployment",
    "main_markdown_content": "# Docker Deployment\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [.github/workflows/docker.yml](.github/workflows/docker.yml)\n- [docker/Dockerfile](docker/Dockerfile)\n- [docker/compose.yml](docker/compose.yml)\n- [docker/docker-compose-test.yml](docker/docker-compose-test.yml)\n- [scripts/entrypoint.sh](scripts/entrypoint.sh)\n\n</details>\n\n\n\nThis document details how to deploy Templar nodes (miners and validators) using Docker containers. Docker provides a consistent, isolated runtime environment for Templar, simplifying deployment across different machines while ensuring all dependencies are properly configured.\n\nFor information about deploying with Ansible, see [Ansible Deployment](#8.2). For setting up a local Subtensor chain for development, see [Local Chain Setup](#8.3).\n\n## Prerequisites\n\nBefore deploying Templar using Docker, ensure you have:\n\n1. Docker and Docker Compose installed on your system\n2. NVIDIA drivers installed (for GPU support)\n3. NVIDIA Container Toolkit installed and configured\n4. A Bittensor wallet created and funded\n5. Cloudflare R2 storage credentials configured\n6. Weights & Biases API key (for logging and monitoring)\n\n## Docker Architecture Overview\n\nTemplar's Docker deployment architecture consists of several components working together:\n\n```mermaid\nflowchart TD\n    subgraph \"Host Machine\"\n        GPU[\"NVIDIA GPU\"]\n        FS[\"File System\"]\n        DockD[\"Docker Daemon\"]\n    end\n    \n    subgraph \"Docker Container\"\n        TE[\"Templar Entrypoint\"]\n        NNT[\"Node Type\\n(Miner/Validator)\"]\n        PT[\"PyTorch + CUDA\"]\n        BT[\"Bittensor Client\"]\n    end\n    \n    subgraph \"External Services\"\n        R2[\"Cloudflare R2 Storage\"]\n        BNET[\"Bittensor Network\"]\n        WB[\"Weights & Biases\"]\n    end\n    \n    GPU <--> DockD\n    FS <--> DockD\n    DockD <--> TE\n    \n    TE --> NNT\n    NNT <--> PT\n    NNT <--> BT\n    \n    BT <--> BNET\n    NNT <--> R2\n    NNT --> WB\n```\n\nSources: [docker/Dockerfile](docker/Dockerfile), [scripts/entrypoint.sh](scripts/entrypoint.sh)\n\n## Docker Image\n\nTemplar uses a custom Docker image based on NVIDIA's CUDA runtime environment:\n\n```mermaid\nflowchart TD\n    subgraph \"Templar Docker Image\"\n        BASE[\"nvidia/cuda:12.6.0-runtime-ubuntu22.04\"]\n        PY[\"Python 3 + Dependencies\"]\n        UV[\"uv Package Manager\"]\n        TCODE[\"Templar Codebase\"]\n        ENTRYPT[\"Entrypoint Script\"]\n    end\n    \n    BASE --> PY\n    PY --> UV\n    UV --> TCODE\n    TCODE --> ENTRYPT\n    \n    VOL1[\"Volume: /root/.bittensor/wallets\"]\n    VOL2[\"Volume: /app/logs\"]\n```\n\nThe Docker image is automatically built and published to GitHub Container Registry via GitHub Actions when releases are made or manually triggered.\n\nSources: [docker/Dockerfile](docker/Dockerfile), [.github/workflows/docker.yml](.github/workflows/docker.yml)\n\n## Deployment Options\n\n### Standard Deployment with Docker Compose\n\nThe standard deployment uses `compose.yml` to run a single Templar node (miner or validator) with the following components:\n\n1. The Templar node container\n2. Watchtower for automatic updates\n\n```bash\n# Clone the repository and navigate to the docker directory\ngit clone https://github.com/tplr-ai/templar.git\ncd templar/docker\n\n# Create an .env file with your configuration\n# Start the container\ndocker-compose up -d\n```\n\n### Test Environment Deployment\n\nFor testing or development, the `docker-compose-test.yml` file provides a multi-node setup with:\n\n- Two miners (on different GPUs)\n- One validator (on a separate GPU)\n- A shared Docker network\n\n```bash\n# Navigate to the docker directory\ncd templar/docker\n\n# Start the test environment\ndocker-compose -f docker-compose-test.yml up -d\n```\n\nSources: [docker/compose.yml](docker/compose.yml), [docker/docker-compose-test.yml](docker/docker-compose-test.yml)\n\n## Configuration\n\n### Environment Variables\n\nThe Templar Docker containers are configured via environment variables, which can be set in a `.env` file or passed directly to Docker Compose.\n\n| Variable | Description | Default Value | Required |\n|----------|-------------|---------------|----------|\n| `NODE_TYPE` | Node type (miner or validator) | miner | Yes |\n| `WALLET_NAME` | Bittensor wallet name | | Yes |\n| `WALLET_HOTKEY` | Bittensor wallet hotkey | | Yes |\n| `CUDA_DEVICE` | CUDA device to use | cuda:0 | Yes |\n| `NETWORK` | Bittensor network | finney | Yes |\n| `DEBUG` | Enable debug mode | false | No |\n| `NETUID` | Network UID | 268 | Yes |\n| `WANDB_API_KEY` | Weights & Biases API key | | Yes |\n| `R2_*` | Cloudflare R2 configuration variables | | Yes |\n| `GITHUB_USER` | GitHub username for Watchtower | | For auto-updates |\n| `GITHUB_TOKEN` | GitHub token for Watchtower | | For auto-updates |\n\n### GPU Configuration\n\nNVIDIA GPU access is configured in the Docker Compose file:\n\n```yaml\ndeploy:\n  resources:\n    reservations:\n      devices:\n        - driver: nvidia\n          device_ids: [ '0', '1', '2' ]\n          capabilities: [ gpu ]\n```\n\nThis configuration allows the container to access GPUs 0, 1, and 2. Modify the `device_ids` array to select specific GPUs.\n\nSources: [docker/compose.yml:36-42](docker/compose.yml:36-42), [docker/docker-compose-test.yml:31-37](docker/docker-compose-test.yml:31-37)\n\n## Container Lifecycle\n\n### Container Startup Process\n\nThe container startup process is managed by the entrypoint script:\n\n```mermaid\nflowchart TD\n    START[\"Container Start\"] --> CHECK[\"Check Required Environment Variables\"]\n    CHECK --> CUDA[\"Check CUDA Availability\"]\n    CUDA --> WANDB[\"Login to Weights & Biases\"]\n    WANDB --> TYPE{\"NODE_TYPE?\"}\n    \n    TYPE -- \"miner\" --> MINER[\"Start Miner Process\"]\n    TYPE -- \"validator\" --> VAL[\"Start Validator Process\"]\n    TYPE -- \"invalid\" --> ERR[\"Error: Invalid NODE_TYPE\"]\n    \n    ERR --> EXIT[\"Container Exit\"]\n```\n\nThe entrypoint script validates the environment, checks dependencies, and starts the appropriate node type.\n\nSources: [scripts/entrypoint.sh](scripts/entrypoint.sh)\n\n### Persistence and Volumes\n\nTwo Docker volumes are used for persistence:\n\n1. `/root/.bittensor/wallets` - Stores Bittensor wallet information\n2. `/app/logs` - Stores application logs\n\nThese volumes persist data even when the container is restarted or updated.\n\n### Automatic Updates with Watchtower\n\nThe standard Docker Compose configuration includes a Watchtower container that automatically checks for updated Templar Docker images and deploys them:\n\n```mermaid\nflowchart LR\n    subgraph \"Docker Environment\"\n        W[\"Watchtower Container\"]\n        T[\"Templar Container\"]\n    end\n    \n    subgraph \"GitHub Container Registry\"\n        I[\"Templar Docker Images\"]\n    end\n    \n    W -- \"1. Check for updates\" --> I\n    W -- \"2. Pull new image\" --> I\n    W -- \"3. Stop container\" --> T\n    W -- \"4. Start new container\" --> T\n```\n\nWatchtower checks for updates every 30 minutes and automatically updates containers with the `com.centurylinklabs.watchtower.enable=true` label.\n\nSources: [docker/compose.yml:46-57](docker/compose.yml:46-57)\n\n## Troubleshooting\n\n### Common Issues\n\n1. **CUDA not available** - Ensure NVIDIA drivers and NVIDIA Container Toolkit are properly installed.\n2. **Missing environment variables** - Check your `.env` file or Docker Compose environment configuration.\n3. **Wallet access issues** - Verify your wallet volume is correctly mounted and permissions are set.\n4. **R2 connectivity problems** - Verify your R2 credentials and check the container logs for connection errors.\n\n### Viewing Logs\n\n```bash\n# View logs for Templar node\ndocker logs templar-miner-YOUR_HOTKEY\n\n# Follow logs in real-time\ndocker logs -f templar-miner-YOUR_HOTKEY\n```\n\n## Multi-Node Setup\n\nFor running multiple nodes on the same machine:\n\n1. Create a copy of the `compose.yml` file for each node\n2. Give each container a unique name\n3. Assign different GPUs to each container\n4. Use different wallet hotkeys for each node\n\n```mermaid\nflowchart TD\n    subgraph \"Host Machine\"\n        GPU0[\"GPU 0\"]\n        GPU1[\"GPU 1\"]\n        GPU2[\"GPU 2\"]\n    end\n    \n    subgraph \"Docker Containers\"\n        M1[\"Miner 1\\nWallet: key1\\nGPU: 0\"]\n        M2[\"Miner 2\\nWallet: key2\\nGPU: 1\"]\n        V1[\"Validator\\nWallet: key3\\nGPU: 2\"]\n    end\n    \n    GPU0 --- M1\n    GPU1 --- M2\n    GPU2 --- V1\n    \n    subgraph \"Shared Resources\"\n        R2[\"R2 Storage\"]\n        BT[\"Bittensor Network\"]\n    end\n    \n    M1 --- R2\n    M2 --- R2\n    V1 --- R2\n    \n    M1 --- BT\n    M2 --- BT\n    V1 --- BT\n```\n\nThe test Docker Compose file demonstrates this configuration pattern.\n\nSources: [docker/docker-compose-test.yml](docker/docker-compose-test.yml)",
    "resolved_links": [
      {
        "text": ".github/workflows/docker.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/.github/workflows/docker.yml",
        "original_deepwiki_href": ".github/workflows/docker.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docker/Dockerfile",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docker/Dockerfile",
        "original_deepwiki_href": "docker/Dockerfile",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docker/compose.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docker/compose.yml",
        "original_deepwiki_href": "docker/compose.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docker/docker-compose-test.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/docker/docker-compose-test.yml",
        "original_deepwiki_href": "docker/docker-compose-test.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/entrypoint.sh",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/entrypoint.sh",
        "original_deepwiki_href": "scripts/entrypoint.sh",
        "context": "collapsible_aside_link"
      },
      {
        "text": "docker/Dockerfile",
        "href": "",
        "original_deepwiki_href": "docker/Dockerfile",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/entrypoint.sh",
        "href": "",
        "original_deepwiki_href": "scripts/entrypoint.sh",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/docker.yml",
        "href": "",
        "original_deepwiki_href": ".github/workflows/docker.yml",
        "context": "inline_source_link"
      },
      {
        "text": "docker/compose.yml",
        "href": "",
        "original_deepwiki_href": "docker/compose.yml",
        "context": "inline_source_link"
      },
      {
        "text": "docker/docker-compose-test.yml",
        "href": "",
        "original_deepwiki_href": "docker/docker-compose-test.yml",
        "context": "inline_source_link"
      },
      {
        "text": "docker/compose.yml:36-42",
        "href": "",
        "original_deepwiki_href": "docker/compose.yml:36-42",
        "context": "inline_source_link"
      },
      {
        "text": "docker/docker-compose-test.yml:31-37",
        "href": "",
        "original_deepwiki_href": "docker/docker-compose-test.yml:31-37",
        "context": "inline_source_link"
      },
      {
        "text": "docker/compose.yml:46-57",
        "href": "",
        "original_deepwiki_href": "docker/compose.yml:46-57",
        "context": "inline_source_link"
      },
      {
        "text": "Ansible Deployment",
        "href": "/deployment/ansible-deployment#8.2",
        "original_deepwiki_href": "#8.2",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Local Chain Setup",
        "href": "/deployment/local-chain-setup#8.3",
        "original_deepwiki_href": "#8.3",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Host Machine\"\n        GPU[\"NVIDIA GPU\"]\n        FS[\"File System\"]\n        DockD[\"Docker Daemon\"]\n    end\n    \n    subgraph \"Docker Container\"\n        TE[\"Templar Entrypoint\"]\n        NNT[\"Node Type\\n(Miner/Validator)\"]\n        PT[\"PyTorch + CUDA\"]\n        BT[\"Bittensor Client\"]\n    end\n    \n    subgraph \"External Services\"\n        R2[\"Cloudflare R2 Storage\"]\n        BNET[\"Bittensor Network\"]\n        WB[\"Weights & Biases\"]\n    end\n    \n    GPU <--> DockD\n    FS <--> DockD\n    DockD <--> TE\n    \n    TE --> NNT\n    NNT <--> PT\n    NNT <--> BT\n    \n    BT <--> BNET\n    NNT <--> R2\n    NNT --> WB",
      "flowchart TD\n    subgraph \"Templar Docker Image\"\n        BASE[\"nvidia/cuda:12.6.0-runtime-ubuntu22.04\"]\n        PY[\"Python 3 + Dependencies\"]\n        UV[\"uv Package Manager\"]\n        TCODE[\"Templar Codebase\"]\n        ENTRYPT[\"Entrypoint Script\"]\n    end\n    \n    BASE --> PY\n    PY --> UV\n    UV --> TCODE\n    TCODE --> ENTRYPT\n    \n    VOL1[\"Volume: /root/.bittensor/wallets\"]\n    VOL2[\"Volume: /app/logs\"]",
      "flowchart TD\n    START[\"Container Start\"] --> CHECK[\"Check Required Environment Variables\"]\n    CHECK --> CUDA[\"Check CUDA Availability\"]\n    CUDA --> WANDB[\"Login to Weights & Biases\"]\n    WANDB --> TYPE{\"NODE_TYPE?\"}\n    \n    TYPE -- \"miner\" --> MINER[\"Start Miner Process\"]\n    TYPE -- \"validator\" --> VAL[\"Start Validator Process\"]\n    TYPE -- \"invalid\" --> ERR[\"Error: Invalid NODE_TYPE\"]\n    \n    ERR --> EXIT[\"Container Exit\"]",
      "flowchart LR\n    subgraph \"Docker Environment\"\n        W[\"Watchtower Container\"]\n        T[\"Templar Container\"]\n    end\n    \n    subgraph \"GitHub Container Registry\"\n        I[\"Templar Docker Images\"]\n    end\n    \n    W -- \"1. Check for updates\" --> I\n    W -- \"2. Pull new image\" --> I\n    W -- \"3. Stop container\" --> T\n    W -- \"4. Start new container\" --> T",
      "flowchart TD\n    subgraph \"Host Machine\"\n        GPU0[\"GPU 0\"]\n        GPU1[\"GPU 1\"]\n        GPU2[\"GPU 2\"]\n    end\n    \n    subgraph \"Docker Containers\"\n        M1[\"Miner 1\\nWallet: key1\\nGPU: 0\"]\n        M2[\"Miner 2\\nWallet: key2\\nGPU: 1\"]\n        V1[\"Validator\\nWallet: key3\\nGPU: 2\"]\n    end\n    \n    GPU0 --- M1\n    GPU1 --- M2\n    GPU2 --- V1\n    \n    subgraph \"Shared Resources\"\n        R2[\"R2 Storage\"]\n        BT[\"Bittensor Network\"]\n    end\n    \n    M1 --- R2\n    M2 --- R2\n    V1 --- R2\n    \n    M1 --- BT\n    M2 --- BT\n    V1 --- BT"
    ],
    "potential_frontmatter": {
      "title": "Docker Deployment"
    }
  },
  "/tplr-ai/templar/8.2-ansible-deployment": {
    "original_deepwiki_href": "/tplr-ai/templar/8.2-ansible-deployment",
    "title": "Ansible Deployment",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/8.2-ansible-deployment",
    "level": 1,
    "target_astro_path": "/deployment/ansible-deployment",
    "main_markdown_content": "# Ansible Deployment\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [ansible/README.md](ansible/README.md)\n- [ansible/group_vars/all/vault.yml.example](ansible/group_vars/all/vault.yml.example)\n- [ansible/playbook.yml](ansible/playbook.yml)\n- [ansible/roles/templar/defaults/main.yml](ansible/roles/templar/defaults/main.yml)\n- [ansible/roles/templar/templates/miner.service.j2](ansible/roles/templar/templates/miner.service.j2)\n\n</details>\n\n\n\nThis document describes how to deploy Templar using Ansible, focusing on automated provisioning of miner nodes across single or multiple GPUs. For Docker-based deployment, see [Docker Deployment](#8.1).\n\n## Overview\n\nThe Templar Ansible playbook automates the deployment of miner nodes by:\n- Cloning the repository\n- Setting up Python virtual environments with CUDA support\n- Installing required system packages\n- Configuring environment variables\n- Deploying miners as continuously running services (optionally with systemd)\n- Supporting multi-GPU configurations with separate instances per GPU\n\n### Deployment Architecture\n\n```mermaid\nflowchart TD\n    subgraph \"Control Machine\"\n        AP[\"ansible-playbook\"]\n        IV[\"inventory file\"]\n        VF[\"vault.yml (secrets)\"]\n        PB[\"playbook.yml\"]\n    end\n    \n    subgraph \"Target Machine\"\n        subgraph \"GPU Node\"\n            P0[\"Python Virtual Env\"]\n            M0[\"Miner Instance 0\"]\n            S0[\"Systemd Service 0\"]\n        end\n        \n        subgraph \"Multi-GPU Node\"\n            P1[\"Python Virtual Env 1\"]\n            M1[\"Miner Instance 1\"]\n            S1[\"Systemd Service 1\"]\n            \n            P2[\"Python Virtual Env 2\"]\n            M2[\"Miner Instance 2\"]\n            S2[\"Systemd Service 2\"]\n        end\n    end\n    \n    AP --> |\"SSH\"| GPU\n    AP --> |\"SSH\"| \"Multi-GPU Node\"\n    IV --> AP\n    VF --> AP\n    PB --> AP\n    \n    P0 --> M0\n    M0 --> S0\n    \n    P1 --> M1\n    M1 --> S1\n    \n    P2 --> M2\n    M2 --> S2\n```\n\nSources: [ansible/playbook.yml](), [ansible/README.md]()\n\n## Prerequisites\n\nBefore using the Ansible deployment, ensure you have:\n\n1. **On the control machine (where you run Ansible)**:\n   - Ansible installed\n   - A Unix-like environment (Linux/macOS) with SSH access to target hosts\n   - Python 3 and pip\n\n2. **On target hosts (where miners will run)**:\n   - Ubuntu (recommended: 22.04)\n   - CUDA support already installed\n   - SSH server configured and accessible\n   - Python installed (the playbook will install it if missing)\n   - At least one CUDA-enabled GPU\n\nSources: [ansible/README.md:19-29]()\n\n## Configuration\n\n### Inventory File\n\nThe inventory file defines your target hosts and their GPU configurations:\n\n```ini\n[bittensor_subnet]\n# Single GPU example\n192.168.123.213 ansible_user=root ansible_port=12345 wallet_hotkeys='[\"miner\"]' cuda_devices='[\"cuda\"]'\n\n# Multi-GPU example\n192.168.222.111 ansible_user=root ansible_port=23456 wallet_hotkeys='[\"miner_1\", \"miner_2\", \"miner_3\", \"miner_4\"]' cuda_devices='[\"cuda:0\", \"cuda:1\", \"cuda:2\", \"cuda:3\"]'\n```\n\n**Note**: The `wallet_hotkeys` and `cuda_devices` arrays must have matching lengths to ensure proper pairing.\n\nSources: [ansible/README.md:32-52]()\n\n### Environment Variables and Secrets\n\nSensitive configuration settings are managed via Ansible Vault. These include R2 storage credentials, wallet configuration, and API keys.\n\n#### Creating a Vault File\n\n1. Create directory structure:\n   ```bash\n   mkdir -p group_vars/all/\n   ```\n\n2. Create an encrypted vault file:\n   ```bash\n   ansible-vault create group_vars/all/vault.yml\n   ```\n\n3. Add your configuration in YAML format:\n\n```yaml\nenv_vars:\n  WANDB_API_KEY: \"your_wandb_key\"\n  INFLUXDB_TOKEN: \"your_influxdb_token\"\n  R2_ACCOUNT_ID: \"your_r2_account_id\"\n  R2_GRADIENTS_ACCOUNT_ID: \"your_r2_gradients_account_id\"\n  # Other R2 credentials...\n  WALLET_NAME: \"default\"\n  NETWORK: \"finney\"\n  NETUID: \"3\"\n\n# Miner configuration\ncuda_devices: [\"cuda:0\"]\nwallet_hotkeys: [\"miner_0\"]\n```\n\nSources: [ansible/group_vars/all/vault.yml.example](), [ansible/README.md:53-87]()\n\n### Configuration Diagram\n\n```mermaid\nflowchart TD\n    subgraph \"Ansible Configuration\"\n        IV[\"inventory\"]\n        VF[\"vault.yml\"]\n        DF[\"defaults/main.yml\"]\n    end\n    \n    subgraph \"Environment Variables\"\n        R2[\"R2 Credentials\"]\n        WB[\"WandB API Key\"]\n        IF[\"InfluxDB Token\"]\n        WC[\"Wallet Configuration\"]\n    end\n    \n    subgraph \"Package Installation\"\n        AP[\"APT Packages\"]\n        PP[\"Pip Packages\"]\n        UP[\"UV Pip Packages\"]\n    end\n    \n    subgraph \"Miner Configuration\"\n        BS[\"actual_batch_size\"]\n        NU[\"netuid\"]\n        SN[\"subtensor_network\"]\n        WN[\"wallet_name\"]\n        WH[\"wallet_hotkeys\"]\n        CD[\"cuda_devices\"]\n    end\n    \n    VF --> R2\n    VF --> WB\n    VF --> IF\n    VF --> WC\n    VF --> WH\n    VF --> CD\n    \n    DF --> AP\n    DF --> PP\n    DF --> UP\n    DF --> BS\n    DF --> NU\n    DF --> SN\n    DF --> WN\n    \n    IV --> WH\n    IV --> CD\n```\n\nSources: [ansible/roles/templar/defaults/main.yml](), [ansible/group_vars/all/vault.yml.example]()\n\n## Running the Deployment\n\n### Basic Usage\n\nFrom the `ansible` directory, run:\n\n```bash\nansible-playbook -i inventory playbook.yml --ask-vault-pass\n```\n\n- The `-i inventory` option specifies your inventory file\n- The `--ask-vault-pass` flag prompts for your vault password (if using encrypted vault)\n\nSources: [ansible/README.md:92-99]()\n\n### Overriding Default Variables\n\nYou can override default variables in several ways:\n\n1. **Via Command Line**:\n   ```bash\n   ansible-playbook -i inventory playbook.yml -e \"actual_batch_size=5 wallet_name=default\" --ask-vault-pass\n   ```\n\n2. **In Group/Host Variables Files**:\n   Create files in `host_vars/your_host.yml` with your custom variables.\n\n3. **In Inventory**:\n   Set variables directly in your inventory file.\n\nSources: [ansible/README.md:101-117]()\n\n## Multi-GPU Setup\n\nThe playbook automatically provisions separate instances for each GPU specified in your inventory:\n\n### Multi-GPU Deployment Process\n\n```mermaid\nflowchart TD\n    subgraph \"playbook.yml\"\n        PreCheck[\"Verify arrays match in length\"]\n        Loop[\"Loop through GPUs\"]\n        Role[\"Include templar role\"]\n    end\n    \n    subgraph \"Per-GPU Instance 0\"\n        DIR0[\"Create directory\\ntemplar-0\"]\n        ENV0[\"Configure .env\"]\n        SVC0[\"Create systemd service\"]\n    end\n    \n    subgraph \"Per-GPU Instance 1\"\n        DIR1[\"Create directory\\ntemplar-1\"]\n        ENV1[\"Configure .env\"]\n        SVC1[\"Create systemd service\"]\n    end\n    \n    PreCheck --> Loop\n    Loop --> Role\n    Role --> DIR0\n    Role --> DIR1\n    DIR0 --> ENV0\n    DIR1 --> ENV1\n    ENV0 --> SVC0\n    ENV1 --> SVC1\n```\n\nFor each GPU:\n- A separate clone of the repository is created in a unique directory (`templar-0`, `templar-1`, etc.)\n- Environment variables are configured with GPU-specific settings\n- A dedicated systemd service is created (when systemd is enabled)\n\nThe instance directory naming follows the pattern: `templar-<GPU index>` where the index is extracted from the `cuda:X` device name.\n\nSources: [ansible/playbook.yml](), [ansible/README.md:133-153]()\n\n## Systemd Service Configuration\n\nWhen `use_systemd` is set to `true`, the playbook will create systemd services for each miner instance. The service:\n\n- Runs the miner with the specified GPU and wallet\n- Automatically restarts on failure\n- Starts on system boot\n\nThe systemd service template parameters:\n\n| Parameter | Description |\n|-----------|-------------|\n| `templar_dir` | Working directory for the instance |\n| `wallet_name` | Name of the wallet to use |\n| `wallet_hotkey` | Hotkey identifier for the wallet |\n| `device` | CUDA device to use (e.g., `cuda:0`) |\n| `netuid` | Network UID for the subnet |\n| `subtensor_network` | Subtensor network (e.g., `finney`) |\n| `actual_batch_size` | Batch size for training |\n\nSources: [ansible/roles/templar/templates/miner.service.j2](), [ansible/roles/templar/defaults/main.yml:35-36]()\n\n## Customization\n\n### Package Installation\n\nYou can customize package installation by modifying:\n\n- `apt_packages`: System packages to install via APT\n- `additional_apt_packages`: Additional system packages\n- `essential_pip_packages`: Global pip packages\n- `additional_pip_packages`: Additional global pip packages\n- `additional_uv_pip_packages`: Additional packages to install in the virtual environment with `uv pip`\n\nSources: [ansible/roles/templar/defaults/main.yml:49-69](), [ansible/README.md:120-124]()\n\n### Miner Parameters\n\nDefault miner parameters can be customized:\n\n- `actual_batch_size`: Batch size for training\n- `netuid`: Network UID for the subnet\n- `subtensor_network`: Subtensor network name\n- `wallet_name`: Name of the wallet to use\n- `wallet_hotkeys`: Array of wallet hotkeys to use\n- `cuda_devices`: Array of CUDA devices to use\n\nSources: [ansible/roles/templar/defaults/main.yml:38-47](), [ansible/README.md:126-127]()\n\n## Troubleshooting\n\n- Use the `-vvv` flag with `ansible-playbook` for verbose output when troubleshooting:\n  ```bash\n  ansible-playbook -i inventory playbook.yml --ask-vault-pass -vvv\n  ```\n\n- Ensure SSH keys and network connectivity are correctly configured\n- Check that the `cuda_devices` and `wallet_hotkeys` arrays have the same length\n- Verify that your vault file contains all required environment variables\n\nSources: [ansible/README.md:168-171]()",
    "resolved_links": [
      {
        "text": "ansible/README.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/README.md",
        "original_deepwiki_href": "ansible/README.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/group_vars/all/vault.yml.example",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/group_vars/all/vault.yml.example",
        "original_deepwiki_href": "ansible/group_vars/all/vault.yml.example",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/playbook.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/playbook.yml",
        "original_deepwiki_href": "ansible/playbook.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/roles/templar/defaults/main.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/roles/templar/defaults/main.yml",
        "original_deepwiki_href": "ansible/roles/templar/defaults/main.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/roles/templar/templates/miner.service.j2",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/ansible/roles/templar/templates/miner.service.j2",
        "original_deepwiki_href": "ansible/roles/templar/templates/miner.service.j2",
        "context": "collapsible_aside_link"
      },
      {
        "text": "ansible/playbook.yml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:19-29",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:32-52",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/group_vars/all/vault.yml.example",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:53-87",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/roles/templar/defaults/main.yml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:92-99",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:101-117",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:133-153",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/roles/templar/templates/miner.service.j2",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/roles/templar/defaults/main.yml:35-36",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/roles/templar/defaults/main.yml:49-69",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:120-124",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/roles/templar/defaults/main.yml:38-47",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:126-127",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "ansible/README.md:168-171",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Docker Deployment",
        "href": "/deployment/docker-deployment#8.1",
        "original_deepwiki_href": "#8.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Control Machine\"\n        AP[\"ansible-playbook\"]\n        IV[\"inventory file\"]\n        VF[\"vault.yml (secrets)\"]\n        PB[\"playbook.yml\"]\n    end\n    \n    subgraph \"Target Machine\"\n        subgraph \"GPU Node\"\n            P0[\"Python Virtual Env\"]\n            M0[\"Miner Instance 0\"]\n            S0[\"Systemd Service 0\"]\n        end\n        \n        subgraph \"Multi-GPU Node\"\n            P1[\"Python Virtual Env 1\"]\n            M1[\"Miner Instance 1\"]\n            S1[\"Systemd Service 1\"]\n            \n            P2[\"Python Virtual Env 2\"]\n            M2[\"Miner Instance 2\"]\n            S2[\"Systemd Service 2\"]\n        end\n    end\n    \n    AP --> |\"SSH\"| GPU\n    AP --> |\"SSH\"| \"Multi-GPU Node\"\n    IV --> AP\n    VF --> AP\n    PB --> AP\n    \n    P0 --> M0\n    M0 --> S0\n    \n    P1 --> M1\n    M1 --> S1\n    \n    P2 --> M2\n    M2 --> S2",
      "flowchart TD\n    subgraph \"Ansible Configuration\"\n        IV[\"inventory\"]\n        VF[\"vault.yml\"]\n        DF[\"defaults/main.yml\"]\n    end\n    \n    subgraph \"Environment Variables\"\n        R2[\"R2 Credentials\"]\n        WB[\"WandB API Key\"]\n        IF[\"InfluxDB Token\"]\n        WC[\"Wallet Configuration\"]\n    end\n    \n    subgraph \"Package Installation\"\n        AP[\"APT Packages\"]\n        PP[\"Pip Packages\"]\n        UP[\"UV Pip Packages\"]\n    end\n    \n    subgraph \"Miner Configuration\"\n        BS[\"actual_batch_size\"]\n        NU[\"netuid\"]\n        SN[\"subtensor_network\"]\n        WN[\"wallet_name\"]\n        WH[\"wallet_hotkeys\"]\n        CD[\"cuda_devices\"]\n    end\n    \n    VF --> R2\n    VF --> WB\n    VF --> IF\n    VF --> WC\n    VF --> WH\n    VF --> CD\n    \n    DF --> AP\n    DF --> PP\n    DF --> UP\n    DF --> BS\n    DF --> NU\n    DF --> SN\n    DF --> WN\n    \n    IV --> WH\n    IV --> CD",
      "flowchart TD\n    subgraph \"playbook.yml\"\n        PreCheck[\"Verify arrays match in length\"]\n        Loop[\"Loop through GPUs\"]\n        Role[\"Include templar role\"]\n    end\n    \n    subgraph \"Per-GPU Instance 0\"\n        DIR0[\"Create directory\\ntemplar-0\"]\n        ENV0[\"Configure .env\"]\n        SVC0[\"Create systemd service\"]\n    end\n    \n    subgraph \"Per-GPU Instance 1\"\n        DIR1[\"Create directory\\ntemplar-1\"]\n        ENV1[\"Configure .env\"]\n        SVC1[\"Create systemd service\"]\n    end\n    \n    PreCheck --> Loop\n    Loop --> Role\n    Role --> DIR0\n    Role --> DIR1\n    DIR0 --> ENV0\n    DIR1 --> ENV1\n    ENV0 --> SVC0\n    ENV1 --> SVC1"
    ],
    "potential_frontmatter": {
      "title": "Ansible Deployment"
    }
  },
  "/tplr-ai/templar/8.3-local-chain-setup": {
    "original_deepwiki_href": "/tplr-ai/templar/8.3-local-chain-setup",
    "title": "Local Chain Setup",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/8.3-local-chain-setup",
    "level": 1,
    "target_astro_path": "/deployment/local-chain-setup",
    "main_markdown_content": "# Local Chain Setup\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [scripts/local_chain/README.md](scripts/local_chain/README.md)\n- [scripts/local_chain/docker-compose.yaml](scripts/local_chain/docker-compose.yaml)\n- [scripts/local_chain/setup.sh](scripts/local_chain/setup.sh)\n- [scripts/local_chain/setup_subnet.py](scripts/local_chain/setup_subnet.py)\n\n</details>\n\n\n\n## Purpose and Scope\n\nThis document provides comprehensive instructions for setting up a local Subtensor blockchain for development and testing purposes in the Templar framework. A local chain allows you to develop and test miners, validators, and other components without connecting to the public Bittensor network or spending real TAO tokens.\n\nFor deploying with Docker in production environments, see [Docker Deployment](#8.1). For Ansible-based deployment, see [Ansible Deployment](#8.2).\n\n## Prerequisites\n\nBefore setting up a local Subtensor chain, ensure you have:\n\n- Docker and Docker Compose installed\n- Python 3.8 or later\n- Bittensor CLI tools installed\n\n## Local Chain Architecture\n\nThe local chain setup creates a minimal Subtensor blockchain network running in Docker containers. The setup includes two validator nodes (Alice and Bob) that maintain the network consensus.\n\n```mermaid\ngraph LR\n    subgraph \"Local Subtensor Network\"\n        subgraph \"Alice Node\"\n            AN[\"Alice Validator\"]\n            AD[\"Chain Data\"]\n        end\n        \n        subgraph \"Bob Node\"\n            BN[\"Bob Validator\"]\n            BD[\"Chain Data\"]\n        end\n        \n        CS[\"Chain Specification\"]\n    end\n    \n    subgraph \"Development Environment\"\n        TM[\"Templar Components\"]\n        WA[\"Bittensor Wallet\"]\n        API[\"RPC API\"]\n    end\n    \n    AN <--> BN\n    AN --> AD\n    BN --> BD\n    CS --> AN\n    CS --> BN\n    \n    API <--> AN\n    API <--> BN\n    TM <--> API\n    WA <--> API\n```\n\nSources: [scripts/local_chain/docker-compose.yaml](), [scripts/local_chain/setup.sh]()\n\n## Setup Process\n\nThe setup process follows these steps:\n\n1. Create directories for chain data\n2. Generate a local chain specification\n3. Generate node keys for validators\n4. Start the validator nodes\n5. Create a subnet and fund wallets\n\n```mermaid\nflowchart TD\n    A[\"Start Setup\"] --> B[\"Create Directories\"]\n    B --> C[\"Purge Previous State\\n(if needed)\"]\n    C --> D[\"Generate Chain Specification\"]\n    D --> E[\"Generate Node Keys\"]\n    E --> F[\"Start Validator Nodes\"]\n    F --> G[\"Wait for Network Startup\"]\n    G --> H[\"Create Subnet\"]\n    H --> I[\"Fund Development Wallet\"]\n    I --> J[\"Register Validator Hotkey\"]\n    J --> K[\"Setup Complete\"]\n```\n\nSources: [scripts/local_chain/setup.sh](), [scripts/local_chain/setup_subnet.py]()\n\n## Setting Up the Local Chain\n\n### Step 1: Initialize and Start the Local Chain\n\nTo set up the local chain, run the setup script:\n\n```bash\ncd scripts/local_chain\n./setup.sh\n```\n\nThis script:\n- Creates directories for chain data\n- Generates a local chain specification\n- Starts two validator nodes (Alice and Bob) using Docker Compose\n- Exposes RPC endpoints at `ws://localhost:9944` and `ws://localhost:9945`\n\nIf you want to keep existing chain data, use the `--no-purge` flag:\n\n```bash\n./setup.sh --no-purge\n```\n\nSources: [scripts/local_chain/setup.sh:4-47]()\n\n### Step 2: Create a Subnet and Fund Wallets\n\nAfter the local chain is running, you need to create a subnet and fund your development wallets:\n\n```bash\npython scripts/local_chain/setup_subnet.py \\\n  --wallet.name YourWallet \\\n  --validator.hotkey validator \\\n  --miner.hotkeys miner1 miner2\n```\n\nThe `setup_subnet.py` script performs these operations:\n\n1. Connects to your local chain at `ws://localhost:9944`\n2. Accesses the pre-funded development account (//Alice)\n3. Funds your specified wallet from the development account\n4. Creates a new subnet (which becomes netuid 2)\n5. Registers and stakes your validator hotkey on the subnet\n\nSources: [scripts/local_chain/setup_subnet.py:11-138]()\n\n### Configuration Options\n\nThe subnet setup script accepts several parameters:\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `--wallet.name` | Name of your Bittensor wallet | Required |\n| `--validator.hotkey` | Hotkey to register as a validator | Required |\n| `--miner.hotkeys` | Space-separated list of miner hotkeys | [] |\n| `--stake.amount` | Amount to stake for the validator (TAO) | 10.0 |\n| `--fund.amount` | Amount to fund your wallet (TAO) | 100.0 |\n\nSources: [scripts/local_chain/setup_subnet.py:13-40](), [scripts/local_chain/README.md:69-77]()\n\n## Running Components with the Local Chain\n\n### Running a Validator\n\nTo run a validator against your local chain:\n\n```bash\npython neurons/validator.py \\\n  --wallet.name YourWallet \\\n  --wallet.hotkey validator \\\n  --subtensor.network ws://localhost:9944 \\\n  --netuid 2\n```\n\n### Running a Miner\n\nTo run a miner against your local chain:\n\n```bash\npython neurons/miner.py \\\n  --wallet.name YourWallet \\\n  --wallet.hotkey miner1 \\\n  --subtensor.network ws://localhost:9944 \\\n  --netuid 2\n```\n\nSources: [scripts/local_chain/README.md:27-39]()\n\n## Technical Implementation Details\n\n### Docker Compose Configuration\n\nThe local chain uses Docker Compose to run two validator nodes:\n\n1. **Alice Node**: Primary validator node with RPC endpoint at `ws://localhost:9946`\n2. **Bob Node**: Secondary validator node with RPC endpoint at `ws://localhost:9944`\n\nBoth nodes use the `ghcr.io/opentensor/subtensor:v2.0.4` Docker image and run with specific flags to enable validator mode and expose RPC endpoints.\n\n```mermaid\ngraph TD\n    subgraph \"Docker Compose Setup\"\n        DC[\"docker-compose.yaml\"]\n        \n        subgraph \"Alice Container\"\n            AC[\"subtensor-alice\"]\n            AA[\"Base Path: /data\"]\n            AP1[\"Port: 30334\"]\n            AP2[\"RPC Port: 9933  9946\"]\n        end\n        \n        subgraph \"Bob Container\"\n            BC[\"subtensor-bob\"]\n            BA[\"Base Path: /data\"]\n            BP1[\"Port: 30335\"]\n            BP2[\"RPC Port: 9933  9944\"]\n        end\n        \n        V1[\"Volume: ./data/alice:/data\"]\n        V2[\"Volume: ./chain-specs:/chain-specs\"]\n        V3[\"Volume: ./data/bob:/data\"]\n        \n        NET[\"Network: subtensor-net\"]\n    end\n    \n    DC --> AC\n    DC --> BC\n    AC --> V1\n    AC --> V2\n    BC --> V3\n    BC --> V2\n    AC --> NET\n    BC --> NET\n```\n\nSources: [scripts/local_chain/docker-compose.yaml:1-52]()\n\n### Subnet Creation and Wallet Funding\n\nThe `setup_subnet.py` script automates the process of:\n\n1. Connecting to the local chain\n2. Accessing the pre-funded development account (//Alice)\n3. Transferring funds to your wallet's coldkey\n4. Creating a new subnet (which becomes netuid 2)\n5. Staking TAO for the validator\n6. Registering the validator hotkey on the subnet\n\n```mermaid\nsequenceDiagram\n    participant Script as \"setup_subnet.py\"\n    participant Alice as \"//Alice Account\"\n    participant Chain as \"Local Subtensor\"\n    participant Wallet as \"Developer Wallet\"\n    participant Subnet as \"New Subnet\"\n    \n    Script->>Chain: Connect to ws://localhost:9944\n    Script->>Alice: Access dev account\n    Script->>Alice: Check balance\n    Alice->>Wallet: Transfer funds (config.fund.amount TAO)\n    Script->>Chain: Create subnet using Alice keypair\n    Chain->>Subnet: Register subnet (netuid 2)\n    Script->>Wallet: Get validator hotkey\n    Wallet->>Chain: Stake TAO for validator\n    Script->>Chain: Get metagraph for netuid 2\n    Chain->>Script: Return registered neurons\n    Script->>Script: Verify validator registration\n```\n\nSources: [scripts/local_chain/setup_subnet.py:45-127]()\n\n## Troubleshooting\n\n### Common Issues and Solutions\n\n| Issue | Possible Cause | Solution |\n|-------|---------------|----------|\n| Chain doesn't start properly | Docker configuration issue | Check Docker logs with `docker compose logs` |\n| Connection issues | Port mapping problem | Ensure ports 9944 and 9945 are exposed with `docker ps` |\n| Funding or subnet creation fails | Chain not running or wallet issues | Verify containers are running and wallet exists |\n| Need to reset the chain | Corrupt state | Run `docker compose down && rm -rf data chain-specs && ./setup.sh` |\n\n### Verifying the Setup\n\nTo verify the local chain is running correctly:\n\n1. Check Docker containers are running:\n   ```bash\n   docker ps | grep subtensor\n   ```\n\n2. Verify you can connect to the RPC endpoint:\n   ```bash\n   btcli subnet list --subtensor.network ws://localhost:9944\n   ```\n\n3. Check that subnet 2 exists:\n   ```bash\n   btcli subnet info 2 --subtensor.network ws://localhost:9944\n   ```\n\nSources: [scripts/local_chain/README.md:96-134]()\n\n## File Structure\n\nThe local chain setup uses the following directory structure:\n\n```\nscripts/local_chain/\n README.md            # Documentation\n setup.sh             # Main setup script\n setup_subnet.py      # Script to create subnet and fund wallets\n docker-compose.yaml  # Docker configuration\n data/                # Created during setup\n    alice/           # Alice node data\n    bob/             # Bob node data\n chain-specs/         # Created during setup\n     local.json       # Local chain specification\n```\n\nSources: [scripts/local_chain/README.md:88-95](), [scripts/local_chain/setup.sh:8-9]()",
    "resolved_links": [
      {
        "text": "scripts/local_chain/README.md",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/local_chain/README.md",
        "original_deepwiki_href": "scripts/local_chain/README.md",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/local_chain/docker-compose.yaml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/local_chain/docker-compose.yaml",
        "original_deepwiki_href": "scripts/local_chain/docker-compose.yaml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/local_chain/setup.sh",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/local_chain/setup.sh",
        "original_deepwiki_href": "scripts/local_chain/setup.sh",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/local_chain/setup_subnet.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/local_chain/setup_subnet.py",
        "original_deepwiki_href": "scripts/local_chain/setup_subnet.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/local_chain/docker-compose.yaml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/setup.sh",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/setup_subnet.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/setup.sh:4-47",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/setup_subnet.py:11-138",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/setup_subnet.py:13-40",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/README.md:69-77",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/README.md:27-39",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/docker-compose.yaml:1-52",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/setup_subnet.py:45-127",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/README.md:96-134",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/README.md:88-95",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/local_chain/setup.sh:8-9",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Docker Deployment",
        "href": "/deployment/docker-deployment#8.1",
        "original_deepwiki_href": "#8.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Ansible Deployment",
        "href": "/deployment/ansible-deployment#8.2",
        "original_deepwiki_href": "#8.2",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph LR\n    subgraph \"Local Subtensor Network\"\n        subgraph \"Alice Node\"\n            AN[\"Alice Validator\"]\n            AD[\"Chain Data\"]\n        end\n        \n        subgraph \"Bob Node\"\n            BN[\"Bob Validator\"]\n            BD[\"Chain Data\"]\n        end\n        \n        CS[\"Chain Specification\"]\n    end\n    \n    subgraph \"Development Environment\"\n        TM[\"Templar Components\"]\n        WA[\"Bittensor Wallet\"]\n        API[\"RPC API\"]\n    end\n    \n    AN <--> BN\n    AN --> AD\n    BN --> BD\n    CS --> AN\n    CS --> BN\n    \n    API <--> AN\n    API <--> BN\n    TM <--> API\n    WA <--> API",
      "flowchart TD\n    A[\"Start Setup\"] --> B[\"Create Directories\"]\n    B --> C[\"Purge Previous State\\n(if needed)\"]\n    C --> D[\"Generate Chain Specification\"]\n    D --> E[\"Generate Node Keys\"]\n    E --> F[\"Start Validator Nodes\"]\n    F --> G[\"Wait for Network Startup\"]\n    G --> H[\"Create Subnet\"]\n    H --> I[\"Fund Development Wallet\"]\n    I --> J[\"Register Validator Hotkey\"]\n    J --> K[\"Setup Complete\"]",
      "graph TD\n    subgraph \"Docker Compose Setup\"\n        DC[\"docker-compose.yaml\"]\n        \n        subgraph \"Alice Container\"\n            AC[\"subtensor-alice\"]\n            AA[\"Base Path: /data\"]\n            AP1[\"Port: 30334\"]\n            AP2[\"RPC Port: 9933  9946\"]\n        end\n        \n        subgraph \"Bob Container\"\n            BC[\"subtensor-bob\"]\n            BA[\"Base Path: /data\"]\n            BP1[\"Port: 30335\"]\n            BP2[\"RPC Port: 9933  9944\"]\n        end\n        \n        V1[\"Volume: ./data/alice:/data\"]\n        V2[\"Volume: ./chain-specs:/chain-specs\"]\n        V3[\"Volume: ./data/bob:/data\"]\n        \n        NET[\"Network: subtensor-net\"]\n    end\n    \n    DC --> AC\n    DC --> BC\n    AC --> V1\n    AC --> V2\n    BC --> V3\n    BC --> V2\n    AC --> NET\n    BC --> NET",
      "sequenceDiagram\n    participant Script as \"setup_subnet.py\"\n    participant Alice as \"//Alice Account\"\n    participant Chain as \"Local Subtensor\"\n    participant Wallet as \"Developer Wallet\"\n    participant Subnet as \"New Subnet\"\n    \n    Script->>Chain: Connect to ws://localhost:9944\n    Script->>Alice: Access dev account\n    Script->>Alice: Check balance\n    Alice->>Wallet: Transfer funds (config.fund.amount TAO)\n    Script->>Chain: Create subnet using Alice keypair\n    Chain->>Subnet: Register subnet (netuid 2)\n    Script->>Wallet: Get validator hotkey\n    Wallet->>Chain: Stake TAO for validator\n    Script->>Chain: Get metagraph for netuid 2\n    Chain->>Script: Return registered neurons\n    Script->>Script: Verify validator registration"
    ],
    "potential_frontmatter": {
      "title": "Local Chain Setup"
    }
  },
  "/tplr-ai/templar/9-monitoring-and-telemetry": {
    "original_deepwiki_href": "/tplr-ai/templar/9-monitoring-and-telemetry",
    "title": "Monitoring and Telemetry",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/9-monitoring-and-telemetry",
    "level": 0,
    "target_astro_path": "/monitoring-and-telemetry",
    "main_markdown_content": "# Monitoring and Telemetry\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [hparams-local-run.json](hparams-local-run.json)\n- [src/tplr/dataset.py](src/tplr/dataset.py)\n- [src/tplr/hparams.py](src/tplr/hparams.py)\n- [src/tplr/logging.py](src/tplr/logging.py)\n- [src/tplr/metrics.py](src/tplr/metrics.py)\n- [src/tplr/schemas.py](src/tplr/schemas.py)\n- [src/tplr/wandb.py](src/tplr/wandb.py)\n- [telemetry/ansible/host_vars/grafana_prod.yml](telemetry/ansible/host_vars/grafana_prod.yml)\n- [telemetry/simulator/testing_metrics.py](telemetry/simulator/testing_metrics.py)\n- [tests/conftest.py](tests/conftest.py)\n- [tests/test_metrics_logger.py](tests/test_metrics_logger.py)\n\n</details>\n\n\n\nThis document describes the monitoring and telemetry system implemented in the Templar framework. It covers the metrics collection, logging infrastructure, and visualization tools that provide observability into the distributed training process. For information about deploying the monitoring services, see [Deployment](#8).\n\n## Overview\n\nTemplar's monitoring and telemetry system provides comprehensive visibility into the distributed training process through three main components:\n\n1. **Metrics Logging** - Collection and storage of time-series metrics in InfluxDB\n2. **Experiment Tracking** - Tracking of training runs with Weights & Biases (WandB)\n3. **Structured Logging** - Centralized logging with Loki for operational visibility\n\nThese components work together to provide a complete view of the training process, from model performance metrics to system resource utilization.\n\n```mermaid\nflowchart TD\n    subgraph \"Templar Nodes\"\n        M[\"Miners\"]\n        V[\"Validators\"]\n        A[\"Aggregator\"]\n        E[\"Evaluator\"]\n    end\n\n    subgraph \"Telemetry Infrastructure\"\n        I[\"InfluxDB\"]\n        W[\"Weights & Biases\"]\n        L[\"Loki\"]\n        G[\"Grafana\"]\n    end\n\n    M -->|\"Performance & System Metrics\"| I\n    V -->|\"Performance & System Metrics\"| I\n    A -->|\"Performance & System Metrics\"| I\n    E -->|\"Performance & System Metrics\"| I\n\n    M -->|\"Experiment Tracking\"| W\n    V -->|\"Experiment Tracking\"| W\n    A -->|\"Experiment Tracking\"| W\n    E -->|\"Experiment Tracking\"| W\n\n    M -->|\"Structured Logs\"| L\n    V -->|\"Structured Logs\"| L\n    A -->|\"Structured Logs\"| L\n    E -->|\"Structured Logs\"| L\n\n    I -->|\"Data Source\"| G\n    L -->|\"Data Source\"| G\n```\n\nSources: [src/tplr/metrics.py](), [src/tplr/wandb.py](), [src/tplr/logging.py]()\n\n## Metrics Logging with InfluxDB\n\nTemplar uses a custom `MetricsLogger` class to collect and store metrics in InfluxDB. This system provides insights into training performance, system resource utilization, and gradient processing efficiency.\n\n### Architecture\n\nThe metrics logging system is designed to be asynchronous and non-blocking to minimize impact on the training process. It uses a queue-based architecture to buffer metrics before sending them to InfluxDB.\n\n```mermaid\nsequenceDiagram\n    participant Node as \"Templar Node\"\n    participant Logger as \"MetricsLogger\"\n    participant Queue as \"Async Queue\"\n    participant Thread as \"Background Thread\"\n    participant InfluxDB as \"InfluxDB\"\n\n    Node->>Logger: log(measurement, tags, fields)\n    Logger->>Logger: Process fields & add metadata\n    Logger->>Queue: Enqueue Point\n    Note over Queue,Thread: Non-blocking operation\n    Thread->>Queue: Dequeue Point\n    Thread->>InfluxDB: Write point (retry if needed)\n```\n\nSources: [src/tplr/metrics.py:182-226]()\n\n### MetricsLogger Class\n\nThe `MetricsLogger` class provides a simple interface for logging metrics while handling the complexity of asynchronous communication with InfluxDB.\n\nKey features:\n- Automatic collection of system and GPU metrics\n- Statistical processing of list values (mean, min, max, median)\n- Tagging with runtime information (version, node role, etc.)\n- Configurable batching and retry logic\n\n```mermaid\nclassDiagram\n    class MetricsLogger {\n        +client: InfluxDBClient\n        +write_api: WriteApi\n        +prefix: str\n        +uid: str\n        +role: str\n        +version: str\n        +runtime_id: str\n        +log(measurement, tags, fields)\n        +process_value(value)\n        -_add_system_metrics(fields)\n        -_add_gpu_metrics(tags, fields)\n        -_add_standard_tags(point)\n        -_add_config_tags(point)\n        -_write_point(point)\n    }\n```\n\nSources: [src/tplr/metrics.py:82-321]()\n\n### Configuration\n\nThe `MetricsLogger` can be configured through environment variables and constructor parameters:\n\n| Parameter | Environment Variable | Default | Description |\n|-----------|---------------------|---------|-------------|\n| host | INFLUXDB_HOST | AWS InfluxDB endpoint | InfluxDB server hostname |\n| port | INFLUXDB_PORT | 8086 | InfluxDB server port |\n| database | INFLUXDB_DATABASE | \"tplr\" | InfluxDB bucket/database name |\n| token | INFLUXDB_TOKEN | Fallback token | Authentication token |\n| org | INFLUXDB_ORG | \"tplr\" | InfluxDB organization |\n| prefix | - | \"\" | Prefix for all metrics |\n| role | - | \"\" | Node role (miner, validator, etc.) |\n\nSources: [src/tplr/metrics.py:45-59](), [src/tplr/metrics.py:88-105]()\n\n### System and GPU Metrics\n\nThe metrics logging system automatically collects system and GPU metrics when requested:\n\n**System Metrics:**\n- CPU usage percentage\n- Memory usage (used and total)\n\n**GPU Metrics:**\n- GPU memory allocated\n- GPU memory cached/reserved\n- GPU memory segments\n- Total GPU memory used\n\n```python\n# Example usage\nmetrics_logger.log(\n    measurement=\"training_step\",\n    tags={\"uid\": 42},\n    fields={\"loss\": 0.75, \"learning_rate\": 0.001},\n    with_system_metrics=True,\n    with_gpu_metrics=True\n)\n```\n\nSources: [src/tplr/metrics.py:324-359]()\n\n## Experiment Tracking with Weights & Biases\n\nTemplar integrates with Weights & Biases (WandB) for experiment tracking and visualization. This integration provides a way to track training progress, compare different runs, and visualize model performance.\n\n### Integration Architecture\n\nThe WandB integration is designed to handle versioning and run resumption, ensuring that training runs are properly tracked even if they span multiple sessions or software versions.\n\n```mermaid\nflowchart TD\n    subgraph \"Templar Node\"\n        Init[\"initialize_wandb()\"]\n        Log[\"run.log()\"]\n    end\n\n    subgraph \"WandB\"\n        API[\"WandB API\"]\n        RunObj[\"Run Object\"]\n        Storage[\"Cloud Storage\"]\n    end\n\n    Init -->|\"Create/Resume Run\"| API\n    API -->|\"Return Run Object\"| RunObj\n    Log -->|\"Log metrics with version prefix\"| RunObj\n    RunObj -->|\"Store metrics & artifacts\"| Storage\n```\n\nSources: [src/tplr/wandb.py:20-125]()\n\n### Version Tracking\n\nA unique feature of Templar's WandB integration is version tracking. Metrics are automatically prefixed with the current software version, allowing for easier comparison of performance across different software versions.\n\n```\nv0.1.0/loss\nv0.1.0/step\nlatest/loss\nlatest/step\n```\n\nThe system also maintains a version history in the run configuration, enabling tracking of when a run was executed with different versions of the software.\n\nSources: [src/tplr/wandb.py:62-68](), [src/tplr/wandb.py:104-116]()\n\n### Run Resumption\n\nThe integration supports run resumption by maintaining a record of run IDs and checking for existing runs when initializing WandB. This allows for seamless continuation of training across multiple sessions.\n\n```python\n# Run ID is stored in a file\nrun_id_file = os.path.join(wandb_dir, f\"wandb_run_id_{run_prefix}{uid}.txt\")\n```\n\nSources: [src/tplr/wandb.py:28-43](), [src/tplr/wandb.py:121-123]()\n\n## Structured Logging with Loki\n\nTemplar uses a structured logging system with Loki integration for centralized log collection and analysis. This system provides operational visibility into the distributed training process.\n\n### Architecture\n\nThe logging system is built on Python's standard logging module with enhancements for structured logging and Loki integration. It uses a queue-based architecture for asynchronous log transmission.\n\n```mermaid\nflowchart TD\n    subgraph \"Templar Node\"\n        Log[\"logger.info()\"]\n        QH[\"QueueHandler\"]\n        Rich[\"RichHandler\"]\n    end\n\n    subgraph \"Background Processing\"\n        QL[\"QueueListener\"]\n        LH[\"LokiHandler\"]\n    end\n\n    subgraph \"Infrastructure\"\n        Loki[\"Loki Server\"]\n        Console[\"Console Output\"]\n    end\n\n    Log -->|\"Log Record\"| QH\n    Log -->|\"Log Record\"| Rich\n    QH -->|\"Enqueue\"| QL\n    QL -->|\"Dequeue\"| LH\n    Rich -->|\"Format & Display\"| Console\n    LH -->|\"HTTP POST\"| Loki\n```\n\nSources: [src/tplr/logging.py:149-287]()\n\n### Context-based Logging\n\nThe logging system supports context-based logging, allowing additional metadata to be attached to log messages. This metadata can include information like trace IDs, batch identifiers, or custom metrics.\n\n```python\n# Example context-based logging\nlog_with_context(\n    'info', \n    'Processing batch', \n    batch_size=32, \n    batch_id='abc123'\n)\n```\n\nSources: [src/tplr/logging.py:290-309]()\n\n### Log Filtering\n\nThe logging system includes custom filters to reduce noise and focus on relevant information. For example, it filters out common subtensor warnings that are not actionable.\n\n```python\nclass NoSubtensorWarning(logging.Filter):\n    def filter(self, record: logging.LogRecord) -> bool:\n        # Return False if the record contains the undesired subtensor warning\n        return (\n            \"Verify your local subtensor is running on port\" not in record.getMessage()\n        )\n```\n\nSources: [src/tplr/logging.py:91-96]()\n\n## Dashboards and Visualization\n\nTemplar uses Grafana for dashboard visualization of metrics stored in InfluxDB and logs stored in Loki. This provides a unified view of system performance and health.\n\n### Grafana Configuration\n\nGrafana is configured to connect to InfluxDB and Loki as data sources. The configuration is managed through Ansible for automated deployment.\n\n```mermaid\nflowchart TD\n    subgraph \"Data Sources\"\n        I[\"InfluxDB\"]\n        L[\"Loki\"]\n    end\n\n    subgraph \"Grafana\"\n        G[\"Grafana Server\"]\n        D1[\"Training Metrics Dashboard\"]\n        D2[\"System Metrics Dashboard\"]\n        D3[\"Log Analytics Dashboard\"]\n    end\n\n    I -->|\"Time Series Data\"| G\n    L -->|\"Log Data\"| G\n    G --- D1\n    G --- D2\n    G --- D3\n```\n\nSources: [telemetry/ansible/host_vars/grafana_prod.yml]()\n\n### Available Metrics\n\nThe monitoring system collects a wide range of metrics that can be visualized in Grafana:\n\n| Category | Metrics |\n|----------|---------|\n| Training | Loss, learning rate, gradient norms |\n| System | CPU usage, memory usage |\n| GPU | Memory allocated, memory cached |\n| Network | Active peers, sync status |\n| Performance | Gradient compression ratio, training throughput |\n\nSources: [src/tplr/metrics.py:182-226](), [tests/test_metrics_logger.py:315-331]()\n\n## Integration in the Templar Ecosystem\n\nThe monitoring and telemetry system is integrated throughout the Templar ecosystem, providing visibility into all components of the distributed training process.\n\n```mermaid\nflowchart TD\n    subgraph \"Templar Framework\"\n        M[\"Miner\"]\n        V[\"Validator\"]\n        A[\"Aggregator\"]\n        C[\"Comms\"]\n        E[\"Evaluator\"]\n    end\n\n    subgraph \"Metrics Collection\"\n        ML[\"MetricsLogger\"]\n        W[\"WandB Integration\"]\n        Log[\"Structured Logger\"]\n    end\n\n    subgraph \"Infrastructure\"\n        I[\"InfluxDB\"]\n        WB[\"Weights & Biases\"]\n        L[\"Loki\"]\n        G[\"Grafana\"]\n    end\n\n    M -->|\"Training Metrics\"| ML\n    V -->|\"Validation Metrics\"| ML\n    A -->|\"Aggregation Metrics\"| ML\n    C -->|\"Communication Metrics\"| ML\n    E -->|\"Evaluation Metrics\"| ML\n\n    M -->|\"Experiment Data\"| W\n    V -->|\"Experiment Data\"| W\n    A -->|\"Experiment Data\"| W\n    E -->|\"Experiment Data\"| W\n\n    M -->|\"Operational Logs\"| Log\n    V -->|\"Operational Logs\"| Log\n    A -->|\"Operational Logs\"| Log\n    C -->|\"Operational Logs\"| Log\n    E -->|\"Operational Logs\"| Log\n\n    ML -->|\"Time Series Data\"| I\n    W -->|\"Run Data\"| WB\n    Log -->|\"Structured Logs\"| L\n\n    I -->|\"Data Source\"| G\n    L -->|\"Data Source\"| G\n```\n\nSources: [src/tplr/metrics.py](), [src/tplr/wandb.py](), [src/tplr/logging.py]()\n\n## Usage Examples\n\n### Logging Training Metrics\n\n```python\n# Initialize MetricsLogger\nmetrics_logger = MetricsLogger(\n    prefix=\"miner\",\n    uid=\"123\",\n    role=\"miner\",\n    group=\"finney\",\n    job_type=\"training\"\n)\n\n# Log training metrics\nmetrics_logger.log(\n    measurement=\"training_step\",\n    tags={\"batch_id\": batch_id},\n    fields={\n        \"loss\": loss.item(),\n        \"learning_rate\": current_lr,\n        \"gradient_norm\": gradient_norm\n    },\n    with_system_metrics=True,\n    with_gpu_metrics=True\n)\n```\n\nSources: [src/tplr/metrics.py:88-105](), [src/tplr/metrics.py:182-226]()\n\n### Initializing W&B for Experiment Tracking\n\n```python\n# Initialize W&B\nrun = initialize_wandb(\n    run_prefix=\"miner_\",\n    uid=\"123\",\n    config=config,\n    group=\"finney\",\n    job_type=\"training\"\n)\n\n# Log metrics to W&B\nrun.log({\n    \"loss\": loss.item(),\n    \"learning_rate\": current_lr,\n    \"gradient_norm\": gradient_norm\n})\n```\n\nSources: [src/tplr/wandb.py:20-125]()\n\n### Setting Up Structured Logging\n\n```python\n# Setup Loki logger\nlogger = setup_loki_logger(\n    service=\"miner\",\n    uid=\"123\",\n    version=\"0.1.0\",\n    environment=\"finney\"\n)\n\n# Log with context\nlogger.log_with_context(\n    \"info\",\n    \"Completed training step\",\n    step=current_step,\n    loss=loss.item(),\n    duration=step_duration\n)\n```\n\nSources: [src/tplr/logging.py:149-287](), [src/tplr/logging.py:290-309]()\n\n## Troubleshooting\n\nIf metrics are not appearing in Grafana dashboards:\n\n1. Check that the `INFLUXDB_TOKEN` environment variable is set correctly\n2. Verify that the InfluxDB host is reachable from the Templar nodes\n3. Check the console logs for any errors related to metrics logging\n4. Verify that Grafana is properly configured to connect to InfluxDB and Loki\n\nIf W&B integration is not working:\n\n1. Check for the existence of a `wandb_run_id_*.txt` file in the `wandb` directory\n2. Verify that the W&B API can be reached from the Templar nodes\n3. Check that the project name is correctly configured\n\nSources: [src/tplr/metrics.py:254](), [src/tplr/wandb.py:36-43]()",
    "resolved_links": [
      {
        "text": "hparams-local-run.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams-local-run.json",
        "original_deepwiki_href": "hparams-local-run.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/dataset.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/dataset.py",
        "original_deepwiki_href": "src/tplr/dataset.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/hparams.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/hparams.py",
        "original_deepwiki_href": "src/tplr/hparams.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/logging.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/logging.py",
        "original_deepwiki_href": "src/tplr/logging.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/metrics.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/metrics.py",
        "original_deepwiki_href": "src/tplr/metrics.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/schemas.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/schemas.py",
        "original_deepwiki_href": "src/tplr/schemas.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/wandb.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/wandb.py",
        "original_deepwiki_href": "src/tplr/wandb.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/host_vars/grafana_prod.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/host_vars/grafana_prod.yml",
        "original_deepwiki_href": "telemetry/ansible/host_vars/grafana_prod.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/simulator/testing_metrics.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/simulator/testing_metrics.py",
        "original_deepwiki_href": "telemetry/simulator/testing_metrics.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/conftest.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/conftest.py",
        "original_deepwiki_href": "tests/conftest.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_metrics_logger.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_metrics_logger.py",
        "original_deepwiki_href": "tests/test_metrics_logger.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/metrics.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/logging.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:182-226",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:82-321",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:45-59",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:88-105",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:324-359",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:20-125",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:62-68",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:104-116",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:28-43",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:121-123",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/logging.py:149-287",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/logging.py:290-309",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/logging.py:91-96",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/host_vars/grafana_prod.yml",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_metrics_logger.py:315-331",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:254",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:36-43",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Deployment",
        "href": "/deployment#8",
        "original_deepwiki_href": "#8",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Templar Nodes\"\n        M[\"Miners\"]\n        V[\"Validators\"]\n        A[\"Aggregator\"]\n        E[\"Evaluator\"]\n    end\n\n    subgraph \"Telemetry Infrastructure\"\n        I[\"InfluxDB\"]\n        W[\"Weights & Biases\"]\n        L[\"Loki\"]\n        G[\"Grafana\"]\n    end\n\n    M -->|\"Performance & System Metrics\"| I\n    V -->|\"Performance & System Metrics\"| I\n    A -->|\"Performance & System Metrics\"| I\n    E -->|\"Performance & System Metrics\"| I\n\n    M -->|\"Experiment Tracking\"| W\n    V -->|\"Experiment Tracking\"| W\n    A -->|\"Experiment Tracking\"| W\n    E -->|\"Experiment Tracking\"| W\n\n    M -->|\"Structured Logs\"| L\n    V -->|\"Structured Logs\"| L\n    A -->|\"Structured Logs\"| L\n    E -->|\"Structured Logs\"| L\n\n    I -->|\"Data Source\"| G\n    L -->|\"Data Source\"| G",
      "sequenceDiagram\n    participant Node as \"Templar Node\"\n    participant Logger as \"MetricsLogger\"\n    participant Queue as \"Async Queue\"\n    participant Thread as \"Background Thread\"\n    participant InfluxDB as \"InfluxDB\"\n\n    Node->>Logger: log(measurement, tags, fields)\n    Logger->>Logger: Process fields & add metadata\n    Logger->>Queue: Enqueue Point\n    Note over Queue,Thread: Non-blocking operation\n    Thread->>Queue: Dequeue Point\n    Thread->>InfluxDB: Write point (retry if needed)",
      "classDiagram\n    class MetricsLogger {\n        +client: InfluxDBClient\n        +write_api: WriteApi\n        +prefix: str\n        +uid: str\n        +role: str\n        +version: str\n        +runtime_id: str\n        +log(measurement, tags, fields)\n        +process_value(value)\n        -_add_system_metrics(fields)\n        -_add_gpu_metrics(tags, fields)\n        -_add_standard_tags(point)\n        -_add_config_tags(point)\n        -_write_point(point)\n    }",
      "flowchart TD\n    subgraph \"Templar Node\"\n        Init[\"initialize_wandb()\"]\n        Log[\"run.log()\"]\n    end\n\n    subgraph \"WandB\"\n        API[\"WandB API\"]\n        RunObj[\"Run Object\"]\n        Storage[\"Cloud Storage\"]\n    end\n\n    Init -->|\"Create/Resume Run\"| API\n    API -->|\"Return Run Object\"| RunObj\n    Log -->|\"Log metrics with version prefix\"| RunObj\n    RunObj -->|\"Store metrics & artifacts\"| Storage",
      "flowchart TD\n    subgraph \"Templar Node\"\n        Log[\"logger.info()\"]\n        QH[\"QueueHandler\"]\n        Rich[\"RichHandler\"]\n    end\n\n    subgraph \"Background Processing\"\n        QL[\"QueueListener\"]\n        LH[\"LokiHandler\"]\n    end\n\n    subgraph \"Infrastructure\"\n        Loki[\"Loki Server\"]\n        Console[\"Console Output\"]\n    end\n\n    Log -->|\"Log Record\"| QH\n    Log -->|\"Log Record\"| Rich\n    QH -->|\"Enqueue\"| QL\n    QL -->|\"Dequeue\"| LH\n    Rich -->|\"Format & Display\"| Console\n    LH -->|\"HTTP POST\"| Loki",
      "flowchart TD\n    subgraph \"Data Sources\"\n        I[\"InfluxDB\"]\n        L[\"Loki\"]\n    end\n\n    subgraph \"Grafana\"\n        G[\"Grafana Server\"]\n        D1[\"Training Metrics Dashboard\"]\n        D2[\"System Metrics Dashboard\"]\n        D3[\"Log Analytics Dashboard\"]\n    end\n\n    I -->|\"Time Series Data\"| G\n    L -->|\"Log Data\"| G\n    G --- D1\n    G --- D2\n    G --- D3",
      "flowchart TD\n    subgraph \"Templar Framework\"\n        M[\"Miner\"]\n        V[\"Validator\"]\n        A[\"Aggregator\"]\n        C[\"Comms\"]\n        E[\"Evaluator\"]\n    end\n\n    subgraph \"Metrics Collection\"\n        ML[\"MetricsLogger\"]\n        W[\"WandB Integration\"]\n        Log[\"Structured Logger\"]\n    end\n\n    subgraph \"Infrastructure\"\n        I[\"InfluxDB\"]\n        WB[\"Weights & Biases\"]\n        L[\"Loki\"]\n        G[\"Grafana\"]\n    end\n\n    M -->|\"Training Metrics\"| ML\n    V -->|\"Validation Metrics\"| ML\n    A -->|\"Aggregation Metrics\"| ML\n    C -->|\"Communication Metrics\"| ML\n    E -->|\"Evaluation Metrics\"| ML\n\n    M -->|\"Experiment Data\"| W\n    V -->|\"Experiment Data\"| W\n    A -->|\"Experiment Data\"| W\n    E -->|\"Experiment Data\"| W\n\n    M -->|\"Operational Logs\"| Log\n    V -->|\"Operational Logs\"| Log\n    A -->|\"Operational Logs\"| Log\n    C -->|\"Operational Logs\"| Log\n    E -->|\"Operational Logs\"| Log\n\n    ML -->|\"Time Series Data\"| I\n    W -->|\"Run Data\"| WB\n    Log -->|\"Structured Logs\"| L\n\n    I -->|\"Data Source\"| G\n    L -->|\"Data Source\"| G"
    ],
    "potential_frontmatter": {
      "title": "Monitoring and Telemetry"
    }
  },
  "/tplr-ai/templar/9.1-metrics-logging": {
    "original_deepwiki_href": "/tplr-ai/templar/9.1-metrics-logging",
    "title": "Metrics Logging",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/9.1-metrics-logging",
    "level": 1,
    "target_astro_path": "/monitoring-and-telemetry/metrics-logging",
    "main_markdown_content": "# Metrics Logging\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [src/tplr/metrics.py](src/tplr/metrics.py)\n- [telemetry/ansible/host_vars/grafana_prod.yml](telemetry/ansible/host_vars/grafana_prod.yml)\n- [telemetry/simulator/testing_metrics.py](telemetry/simulator/testing_metrics.py)\n- [tests/conftest.py](tests/conftest.py)\n- [tests/test_metrics_logger.py](tests/test_metrics_logger.py)\n\n</details>\n\n\n\n## Purpose and Scope\n\nThe Metrics Logging system in Templar provides comprehensive monitoring capabilities for tracking training progress, system performance, and resource utilization across the distributed training framework. It enables real-time collection of metrics from miners, validators, and other components, with data stored in InfluxDB for subsequent analysis and visualization. For information about visualizing this data through dashboards, see [Dashboards](#9.3). For experiment tracking with Weights & Biases, see [Experiment Tracking](#9.2).\n\n## Architecture Overview\n\nThe Metrics Logging system is built around the `MetricsLogger` class, which collects metrics data and asynchronously sends it to an InfluxDB instance.\n\n### Data Flow Diagram\n\n```mermaid\nflowchart TD\n    subgraph \"Templar Components\"\n        M[\"Miner\"]\n        V[\"Validator\"]\n        E[\"Evaluator\"]\n        A[\"Aggregator\"]\n    end\n    \n    subgraph \"MetricsLogger\"\n        MLC[\"log() Method\"]\n        PT[\"Process & Transform\"]\n        PP[\"Point Preparation\"]\n        AQ[\"Async Queue\"]\n        BW[\"Background Writer\"]\n    end\n    \n    subgraph \"Storage & Visualization\"\n        IDB[\"InfluxDB\"]\n        GF[\"Grafana Dashboards\"]\n    end\n    \n    M --> MLC\n    V --> MLC\n    E --> MLC\n    A --> MLC\n    \n    MLC --> PT\n    PT --> PP\n    PP --> AQ\n    AQ --> BW\n    BW --> IDB\n    IDB --> GF\n```\n\nSources: [src/tplr/metrics.py:82-360]()\n\n### MetricsLogger Internal Architecture\n\n```mermaid\nflowchart TD\n    subgraph \"Public Interface\"\n        LOG[\"log(measurement, tags, fields)\"]\n        PV[\"process_value(v)\"]\n    end\n    \n    subgraph \"Internal Components\"\n        PF[\"_process_fields()\"]\n        ASM[\"_add_system_metrics()\"]\n        AGM[\"_add_gpu_metrics()\"]\n        AT[\"_add_tags()\"]\n        AST[\"_add_standard_tags()\"]\n        ACT[\"_add_config_tags()\"]\n        Q[\"Queue\"]\n        CON[\"_consumer()\"]\n        H[\"_handle()\"]\n        WP[\"_write_point()\"]\n    end\n    \n    subgraph \"External Dependencies\"\n        IDB[\"InfluxDBClient\"]\n        WA[\"write_api\"]\n        P[\"Point\"]\n    end\n    \n    LOG --> PF\n    PF --> PV\n    PF --> ASM\n    PF --> AGM\n    LOG --> AT\n    AT --> AST\n    AT --> ACT\n    LOG --> Q\n    Q --> CON\n    CON --> H\n    H --> WP\n    WP --> WA\n    WA --> IDB\n    \n    ASM --> GSM[\"get_system_metrics()\"]\n    AGM --> GGM[\"get_gpu_metrics()\"]\n```\n\nSources: [src/tplr/metrics.py:182-255]()\n\n## Core Components\n\n### MetricsLogger Class\n\nThe `MetricsLogger` class is the central component of the metrics logging system. It handles initialization of the InfluxDB connection, processes data types appropriately, and manages asynchronous writes to avoid blocking the main training loop.\n\n```mermaid\nclassDiagram\n    class MetricsLogger {\n        +__init__(host, port, database, token, org, prefix, uid, role, config, group, job_type)\n        +process_value(v)\n        +log(measurement, tags, fields, timestamp, with_system_metrics, with_gpu_metrics)\n        -_run()\n        -_consumer()\n        -_handle(point)\n        -_write_point(point)\n        -_process_fields(fields)\n        -_add_system_metrics(fields)\n        -_add_gpu_metrics(tags, fields)\n        -_add_tags(point, tags)\n        -_add_standard_tags(point)\n        -_add_config_tags(point)\n    }\n```\n\nSources: [src/tplr/metrics.py:82-321]()\n\n### Configuration Options\n\nThe metrics logger can be configured with the following parameters:\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `host` | InfluxDB host | From `INFLUXDB_HOST` env var or AWS TimeStream instance |\n| `port` | InfluxDB port | From `INFLUXDB_PORT` env var or `8086` |\n| `database` | InfluxDB bucket | From `INFLUXDB_DATABASE` env var or `\"tplr\"` |\n| `token` | Authentication token | From `INFLUXDB_TOKEN` env var or fallback |\n| `org` | InfluxDB organization | From `INFLUXDB_ORG` env var or `\"tplr\"` |\n| `prefix` | Metric name prefix | `\"\"` |\n| `uid` | Unique identifier | `None` |\n| `role` | Node role | `\"\"` (e.g., \"miner\", \"validator\") |\n| `config` | Bittensor config | `None` |\n| `group` | Group identifier | `\"\"` |\n| `job_type` | Job type | `\"\"` |\n| `max_queue_size` | Max queue size | `600_000` |\n| `max_workers` | Thread pool size | `1` |\n\nSources: [src/tplr/metrics.py:88-105](), [src/tplr/metrics.py:44-53]()\n\n### Data Processing\n\nThe `process_value` method handles different types of data with type-specific processing:\n\n| Data Type | Processing Behavior |\n|-----------|---------------------|\n| Integer | Preserved as integer |\n| Float | Preserved as float |\n| List of integers | Converted to string (for peer IDs) |\n| List of numbers | Converted to statistics object (mean, min, max, median) |\n| String | Preserved as string |\n| None | Converted to `0.0` |\n| Other types | Converted to string |\n\nSources: [src/tplr/metrics.py:154-180]()\n\n### System and GPU Metrics Collection\n\nThe metrics logger can automatically collect and include system and GPU metrics when requested:\n\n```python\n# System metrics collected (when with_system_metrics=True)\n{\n    \"sys_cpu_usage\": <percent>,             # CPU utilization percentage\n    \"sys_mem_used\": <megabytes>,            # RAM used in MB\n    \"sys_mem_total\": <megabytes>            # Total RAM in MB\n}\n\n# GPU metrics collected (when with_gpu_metrics=True)\n{\n    \"gpu_mem_segments\": <count>,            # GPU memory segments\n    \"gpu_mem_allocated_mb\": <megabytes>,    # Allocated GPU memory\n    \"gpu_mem_cached_mb\": <megabytes>,       # Cached GPU memory\n    \"gpu_mem_total_mb\": <megabytes>,        # Total GPU memory\n    \"gpu_name\": <device_name>,              # GPU device name (as tag)\n    \"gpu_id\": <device_id>                   # GPU device ID (as tag)\n}\n```\n\nSources: [src/tplr/metrics.py:324-359]()\n\n## Asynchronous Processing\n\nThe `MetricsLogger` uses asynchronous processing to avoid blocking the main thread during metric collection:\n\n1. Each log call adds a point to an async queue\n2. A background thread continuously processes items from the queue\n3. Write operations are performed in a thread pool executor\n4. Failed writes are logged but do not crash the application\n\nSources: [src/tplr/metrics.py:227-255]()\n\n## Usage Examples\n\n### Basic Initialization\n\n```python\nfrom tplr.metrics import MetricsLogger\n\n# Basic initialization with role\nlogger = MetricsLogger(\n    prefix=\"miner\",\n    uid=\"123\",\n    role=\"miner\",\n    group=\"training_group\"\n)\n\n# With custom InfluxDB settings\nlogger = MetricsLogger(\n    host=\"custom.influxdb.host\",\n    port=8086,\n    token=\"your-token\",\n    org=\"your-org\",\n    database=\"your-bucket\",\n    prefix=\"validator\",\n    uid=\"456\",\n    role=\"validator\"\n)\n```\n\n### Logging Metrics\n\n```python\n# Basic metrics logging\nlogger.log(\n    measurement=\"training_step\",\n    tags={\"step\": 42},\n    fields={\"loss\": 0.75}\n)\n\n# With system and GPU metrics\nlogger.log(\n    measurement=\"training_step\",\n    tags={\"batch\": 100, \"epoch\": 5},\n    fields={\"loss\": 0.345, \"accuracy\": 0.92},\n    with_system_metrics=True,\n    with_gpu_metrics=True\n)\n\n# Logging metrics with lists that will be processed automatically\nlogger.log(\n    measurement=\"training_step\",\n    tags={\"step\": 42},\n    fields={\n        \"peer_ids\": [1, 2, 3, 4],           # Will be stored as string\n        \"losses\": [0.1, 0.2, 0.3, 0.4]      # Will be stored as statistics\n    }\n)\n```\n\nSources: [src/tplr/metrics.py:182-201]()\n\n## Integration with InfluxDB\n\nThe `MetricsLogger` integrates with InfluxDB via the official InfluxDB client library. It uses:\n\n1. A custom write options class (`MertricsLoggerWriteOptions`) for configuration\n2. The `Point` class for structuring metrics data\n3. Batched writes with configurable batch sizes (defaults: 10,000 for validators, 1,000 for other roles)\n4. The InfluxDB 2.0 API with organization and bucket concepts\n\nSources: [src/tplr/metrics.py:62-79](), [src/tplr/metrics.py:130-136]()\n\n## Best Practices\n\n1. **Use consistent measurement names**: Keep measurement names consistent across related metrics for easier querying\n   \n2. **Add contextual tags**: Include tags like `step`, `epoch`, `batch` to segment and filter data\n\n3. **Include system metrics for performance-related data**: Always enable `with_system_metrics=True` when logging performance data\n\n4. **Group related metrics in single calls**: Combine related metrics in a single `log()` call rather than multiple calls\n\n5. **Handle exceptions**: The logger is designed to handle exceptions internally, but be aware of potential connection issues\n\n6. **Use appropriate value types**: The `process_value()` method handles type conversion, but using appropriate types initially improves clarity\n\nSources: [tests/test_metrics_logger.py:316-331]()\n\n## Testing and Debugging\n\nThe metrics logger includes comprehensive test coverage. For troubleshooting:\n\n1. Enable debug logging to see detailed information about metric writes\n2. Use the `testing_metrics.py` script to verify connectivity to InfluxDB\n3. Check the Grafana dashboards to confirm metrics are being received\n\nSources: [tests/test_metrics_logger.py:1-342](), [telemetry/simulator/testing_metrics.py:1-52]()",
    "resolved_links": [
      {
        "text": "src/tplr/metrics.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/metrics.py",
        "original_deepwiki_href": "src/tplr/metrics.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/host_vars/grafana_prod.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/host_vars/grafana_prod.yml",
        "original_deepwiki_href": "telemetry/ansible/host_vars/grafana_prod.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/simulator/testing_metrics.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/simulator/testing_metrics.py",
        "original_deepwiki_href": "telemetry/simulator/testing_metrics.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/conftest.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/conftest.py",
        "original_deepwiki_href": "tests/conftest.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_metrics_logger.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_metrics_logger.py",
        "original_deepwiki_href": "tests/test_metrics_logger.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/metrics.py:82-360",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:182-255",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:82-321",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:88-105",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:44-53",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:154-180",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:324-359",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:227-255",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:182-201",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:62-79",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/metrics.py:130-136",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_metrics_logger.py:316-331",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_metrics_logger.py:1-342",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/simulator/testing_metrics.py:1-52",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Dashboards",
        "href": "/monitoring-and-telemetry/dashboards#9.3",
        "original_deepwiki_href": "#9.3",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Experiment Tracking",
        "href": "/monitoring-and-telemetry/experiment-tracking#9.2",
        "original_deepwiki_href": "#9.2",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Templar Components\"\n        M[\"Miner\"]\n        V[\"Validator\"]\n        E[\"Evaluator\"]\n        A[\"Aggregator\"]\n    end\n    \n    subgraph \"MetricsLogger\"\n        MLC[\"log() Method\"]\n        PT[\"Process & Transform\"]\n        PP[\"Point Preparation\"]\n        AQ[\"Async Queue\"]\n        BW[\"Background Writer\"]\n    end\n    \n    subgraph \"Storage & Visualization\"\n        IDB[\"InfluxDB\"]\n        GF[\"Grafana Dashboards\"]\n    end\n    \n    M --> MLC\n    V --> MLC\n    E --> MLC\n    A --> MLC\n    \n    MLC --> PT\n    PT --> PP\n    PP --> AQ\n    AQ --> BW\n    BW --> IDB\n    IDB --> GF",
      "flowchart TD\n    subgraph \"Public Interface\"\n        LOG[\"log(measurement, tags, fields)\"]\n        PV[\"process_value(v)\"]\n    end\n    \n    subgraph \"Internal Components\"\n        PF[\"_process_fields()\"]\n        ASM[\"_add_system_metrics()\"]\n        AGM[\"_add_gpu_metrics()\"]\n        AT[\"_add_tags()\"]\n        AST[\"_add_standard_tags()\"]\n        ACT[\"_add_config_tags()\"]\n        Q[\"Queue\"]\n        CON[\"_consumer()\"]\n        H[\"_handle()\"]\n        WP[\"_write_point()\"]\n    end\n    \n    subgraph \"External Dependencies\"\n        IDB[\"InfluxDBClient\"]\n        WA[\"write_api\"]\n        P[\"Point\"]\n    end\n    \n    LOG --> PF\n    PF --> PV\n    PF --> ASM\n    PF --> AGM\n    LOG --> AT\n    AT --> AST\n    AT --> ACT\n    LOG --> Q\n    Q --> CON\n    CON --> H\n    H --> WP\n    WP --> WA\n    WA --> IDB\n    \n    ASM --> GSM[\"get_system_metrics()\"]\n    AGM --> GGM[\"get_gpu_metrics()\"]",
      "classDiagram\n    class MetricsLogger {\n        +__init__(host, port, database, token, org, prefix, uid, role, config, group, job_type)\n        +process_value(v)\n        +log(measurement, tags, fields, timestamp, with_system_metrics, with_gpu_metrics)\n        -_run()\n        -_consumer()\n        -_handle(point)\n        -_write_point(point)\n        -_process_fields(fields)\n        -_add_system_metrics(fields)\n        -_add_gpu_metrics(tags, fields)\n        -_add_tags(point, tags)\n        -_add_standard_tags(point)\n        -_add_config_tags(point)\n    }"
    ],
    "potential_frontmatter": {
      "title": "Metrics Logging"
    }
  },
  "/tplr-ai/templar/9.2-experiment-tracking": {
    "original_deepwiki_href": "/tplr-ai/templar/9.2-experiment-tracking",
    "title": "Experiment Tracking",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/9.2-experiment-tracking",
    "level": 1,
    "target_astro_path": "/monitoring-and-telemetry/experiment-tracking",
    "main_markdown_content": "# Experiment Tracking\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [hparams-local-run.json](hparams-local-run.json)\n- [src/tplr/dataset.py](src/tplr/dataset.py)\n- [src/tplr/hparams.py](src/tplr/hparams.py)\n- [src/tplr/logging.py](src/tplr/logging.py)\n- [src/tplr/schemas.py](src/tplr/schemas.py)\n- [src/tplr/wandb.py](src/tplr/wandb.py)\n\n</details>\n\n\n\nThis document describes how the Templar framework handles experiment tracking and monitoring using Weights & Biases (WandB) integration. It covers run initialization, version tracking, metrics logging, and hyperparameter management. For information about metrics logging to InfluxDB, see [Metrics Logging](#9.1), and for visualization with dashboards, see [Dashboards](#9.3).\n\n## Overview of Experiment Tracking\n\nTemplar integrates deeply with Weights & Biases to provide comprehensive experiment tracking capabilities. This integration allows miners and validators to log model training metrics, hyperparameters, and version information in a structured manner, enabling detailed analysis of training progress across distributed nodes.\n\n### Key Features\n\n- **Run Management**: Automatic creation and resumption of experiment runs\n- **Version Tracking**: Tracking metrics across different code versions\n- **Hyperparameter Logging**: Comprehensive tracking of model configurations\n- **Metrics Namespacing**: Versioned metrics organization for easy comparison\n\nSources: [src/tplr/wandb.py:20-125]()\n\n## WandB Integration Architecture\n\nThe experiment tracking system integrates with other Templar components as shown below:\n\n```mermaid\nflowchart TD\n    subgraph \"Experiment Tracking\"\n        WB[\"WandB Run\"]\n        VI[\"Version Information\"]\n        HT[\"Hyperparameter Tracking\"]\n        ML[\"Metrics Logging\"]\n    end\n\n    subgraph \"Templar Core\"\n        MN[\"Miner Node\"]\n        VL[\"Validator Node\"]\n        HP[\"Hyperparameters\"]\n        LG[\"Logging System\"]\n    end\n\n    MN --> |\"initialize_wandb()\"| WB\n    VL --> |\"initialize_wandb()\"| WB\n    HP --> |\"create_namespace()\"| HT\n    WB --> |\"run.log()\"| ML\n    VI <--> |\"version_history\"| WB\n    LG --> |\"logger.info()\"| MN\n    LG --> |\"logger.info()\"| VL\n```\n\nSources: [src/tplr/wandb.py:20-125](), [src/tplr/hparams.py:62-104]()\n\n## Run Management\n\nThe `initialize_wandb` function handles WandB run creation and resumption. It automatically detects existing runs based on a persistent run ID stored in the file system.\n\n### Run Initialization Process\n\n```mermaid\nsequenceDiagram\n    participant Node as \"Miner/Validator\"\n    participant WandB as \"initialize_wandb()\"\n    participant FSIO as \"File System\"\n    participant WAPI as \"WandB API\"\n    \n    Node->>WandB: \"Call with run_prefix, uid, config\"\n    WandB->>FSIO: \"Check for run_id file\"\n    \n    alt Run ID exists\n        FSIO->>WandB: \"Return stored run_id\"\n        WandB->>WAPI: \"Verify run exists\"\n        \n        alt Run found in WandB\n            WAPI->>WandB: \"Confirm run\"\n            WandB->>Node: \"Resume existing run\"\n        else Run not found\n            WAPI->>WandB: \"Run not found\"\n            WandB->>FSIO: \"Delete invalid run_id file\"\n            WandB->>WAPI: \"Create new run\"\n            WandB->>FSIO: \"Store new run_id\"\n        end\n    else No run ID\n        WandB->>WAPI: \"Create new run\"\n        WandB->>FSIO: \"Store new run_id\"\n    end\n    \n    WandB->>Node: \"Return configured run\"\n```\n\nSources: [src/tplr/wandb.py:20-45](), [src/tplr/wandb.py:120-124]()\n\n## Version Tracking System\n\nTemplar meticulously tracks software versions used for each experiment run. This allows for comparing metrics across different code versions and understanding the impact of code changes.\n\n### Key Features:\n\n1. **Version History**: Each run maintains a history of all versions that contributed to it\n2. **Current Version**: The active code version is always tracked\n3. **Versioned Metrics**: All metrics are automatically prefixed with the version that logged them\n\n```mermaid\nflowchart LR\n    subgraph \"Version Management\"\n        VH[\"version_history\\nArray\"]\n        CV[\"current_version\\nProperty\"]\n    end\n    \n    subgraph \"Metrics Prefixing\"\n        OM[\"Original Metrics\\n{loss: 0.1, acc: 0.9}\"]\n        MM[\"Modified Metrics\\n{v0.1.1/loss: 0.1,\\nv0.1.1/acc: 0.9,\\nlatest/loss: 0.1,\\nlatest/acc: 0.9}\"]\n        VM[\"Versioned Metrics\\nCollection\"]\n    end\n    \n    I[\"initialize_wandb()\"] --> |\"Track versions\"| VH\n    I --> |\"Set current\"| CV\n    OM --> |\"log_with_version()\"| MM\n    MM --> |\"Store in WandB\"| VM\n    VH --> |\"Reference for\\nmetrics analysis\"| VM\n```\n\nSources: [src/tplr/wandb.py:64-68](), [src/tplr/wandb.py:92-117]()\n\n## Metrics Logging\n\nThe WandB integration includes a custom logging wrapper that automatically adds version information to all metrics. This provides clear separation between metrics logged by different code versions.\n\n### Metrics Transformation Process\n\n1. Original metrics are captured during training\n2. `log_with_version` transforms metrics by adding version prefixes\n3. Both version-specific (`v{__version__}/metric`) and latest (`latest/metric`) paths are maintained\n4. Step counting is handled automatically or can be explicitly provided\n\nSources: [src/tplr/wandb.py:92-117]()\n\n## Hyperparameter Management\n\nTemplar uses a structured approach to hyperparameter management, with defaults that can be overridden by configuration files.\n\n### Hyperparameter Loading Flow\n\n```mermaid\nflowchart TD\n    subgraph \"Configuration Sources\"\n        DF[\"DEFAULT_HPARAMS\\nBuilt-in defaults\"]\n        HF[\"hparams.json\\nProject config\"]\n        LH[\"hparams-local-run.json\\nLocal overrides\"]\n    end\n    \n    subgraph \"Hyperparameter Processing\"\n        LHP[\"load_hparams()\\nFunction\"]\n        CNP[\"create_namespace()\\nFunction\"]\n        NS[\"SimpleNamespace\\nObject\"]\n    end\n    \n    subgraph \"Model Configuration\"\n        TK[\"Tokenizer\\nConfiguration\"]\n        MC[\"LlamaConfig\\nModel structure\"]\n    end\n    \n    HF --> |\"Load JSON\"| LHP\n    LH --> |\"Optional local\\noverrides\"| LHP\n    DF --> |\"Default values\"| CNP\n    LHP --> |\"Merged params\"| CNP\n    CNP --> |\"Initialize\"| NS\n    NS --> |\"Configure\"| TK\n    NS --> |\"Configure\"| MC\n    NS --> |\"Log to WandB\"| WB[\"WandB Config\"]\n```\n\nThe system supports special local configurations through `hparams-local-run.json`, which is useful for development and testing.\n\nSources: [src/tplr/hparams.py:26-59](), [src/tplr/hparams.py:107-145](), [hparams-local-run.json:1-9]()\n\n## WandB Run Configuration Options\n\nThe following table shows the key configuration options used when initializing WandB runs:\n\n| Parameter | Description | Default Value |\n|-----------|-------------|---------------|\n| `project` | Project name | From config.project |\n| `entity` | Team or user account | \"tplr\" (or None for private) |\n| `id` | Run ID (for resuming) | From stored run ID file |\n| `resume` | Resume policy | \"must\" if run ID exists, \"never\" otherwise |\n| `name` | Run name | \"{run_prefix}{uid}\" |\n| `group` | Grouping for related runs | From parameter |\n| `job_type` | Type of job (miner/validator) | From parameter |\n| `tags` | Version tags | [\"v{__version__}\"] |\n\nSources: [src/tplr/wandb.py:46-61]()\n\n## Typical Usage Workflow\n\nWhen running a miner or validator node, the experiment tracking system is initialized with appropriate parameters that identify the node type and purpose. The system will automatically handle run resumption if the node restarts.\n\n```mermaid\nsequenceDiagram\n    participant MV as \"Miner/Validator\"\n    participant HP as \"Hyperparameters\"\n    participant WI as \"WandB Integration\"\n    participant WB as \"WandB Server\"\n    \n    MV->>HP: \"load_hparams()\"\n    HP->>MV: \"Return config namespace\"\n    MV->>WI: \"initialize_wandb('miner_', uid, config, 'miners', 'miner')\"\n    WI->>WB: \"Create/resume run\"\n    WB->>WI: \"Return run object\"\n    WI->>MV: \"Return configured run with custom log method\"\n    \n    loop Training Loop\n        MV->>MV: \"Train for one step\"\n        MV->>WI: \"run.log({'loss': loss, 'perplexity': ppl})\"\n        WI->>WI: \"Add version prefixes\"\n        WI->>WB: \"Log versioned metrics\"\n    end\n```\n\nSources: [src/tplr/wandb.py:20-125]()\n\n## Integration with Logging System\n\nThe experiment tracking system integrates with Templar's logging system, allowing error messages and information to be properly captured both in the console and in remote logging systems.\n\nSources: [src/tplr/logging.py:80-85](), [src/tplr/wandb.py:17]()",
    "resolved_links": [
      {
        "text": "hparams-local-run.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/hparams-local-run.json",
        "original_deepwiki_href": "hparams-local-run.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/dataset.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/dataset.py",
        "original_deepwiki_href": "src/tplr/dataset.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/hparams.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/hparams.py",
        "original_deepwiki_href": "src/tplr/hparams.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/logging.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/logging.py",
        "original_deepwiki_href": "src/tplr/logging.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/schemas.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/schemas.py",
        "original_deepwiki_href": "src/tplr/schemas.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/wandb.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/src/tplr/wandb.py",
        "original_deepwiki_href": "src/tplr/wandb.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "src/tplr/wandb.py:20-125",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/hparams.py:62-104",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:20-45",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:120-124",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:64-68",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:92-117",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/hparams.py:26-59",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/hparams.py:107-145",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "hparams-local-run.json:1-9",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:46-61",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/logging.py:80-85",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "src/tplr/wandb.py:17",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Metrics Logging",
        "href": "/monitoring-and-telemetry/metrics-logging#9.1",
        "original_deepwiki_href": "#9.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Dashboards",
        "href": "/monitoring-and-telemetry/dashboards#9.3",
        "original_deepwiki_href": "#9.3",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Experiment Tracking\"\n        WB[\"WandB Run\"]\n        VI[\"Version Information\"]\n        HT[\"Hyperparameter Tracking\"]\n        ML[\"Metrics Logging\"]\n    end\n\n    subgraph \"Templar Core\"\n        MN[\"Miner Node\"]\n        VL[\"Validator Node\"]\n        HP[\"Hyperparameters\"]\n        LG[\"Logging System\"]\n    end\n\n    MN --> |\"initialize_wandb()\"| WB\n    VL --> |\"initialize_wandb()\"| WB\n    HP --> |\"create_namespace()\"| HT\n    WB --> |\"run.log()\"| ML\n    VI <--> |\"version_history\"| WB\n    LG --> |\"logger.info()\"| MN\n    LG --> |\"logger.info()\"| VL",
      "sequenceDiagram\n    participant Node as \"Miner/Validator\"\n    participant WandB as \"initialize_wandb()\"\n    participant FSIO as \"File System\"\n    participant WAPI as \"WandB API\"\n    \n    Node->>WandB: \"Call with run_prefix, uid, config\"\n    WandB->>FSIO: \"Check for run_id file\"\n    \n    alt Run ID exists\n        FSIO->>WandB: \"Return stored run_id\"\n        WandB->>WAPI: \"Verify run exists\"\n        \n        alt Run found in WandB\n            WAPI->>WandB: \"Confirm run\"\n            WandB->>Node: \"Resume existing run\"\n        else Run not found\n            WAPI->>WandB: \"Run not found\"\n            WandB->>FSIO: \"Delete invalid run_id file\"\n            WandB->>WAPI: \"Create new run\"\n            WandB->>FSIO: \"Store new run_id\"\n        end\n    else No run ID\n        WandB->>WAPI: \"Create new run\"\n        WandB->>FSIO: \"Store new run_id\"\n    end\n    \n    WandB->>Node: \"Return configured run\"",
      "flowchart LR\n    subgraph \"Version Management\"\n        VH[\"version_history\\nArray\"]\n        CV[\"current_version\\nProperty\"]\n    end\n    \n    subgraph \"Metrics Prefixing\"\n        OM[\"Original Metrics\\n{loss: 0.1, acc: 0.9}\"]\n        MM[\"Modified Metrics\\n{v0.1.1/loss: 0.1,\\nv0.1.1/acc: 0.9,\\nlatest/loss: 0.1,\\nlatest/acc: 0.9}\"]\n        VM[\"Versioned Metrics\\nCollection\"]\n    end\n    \n    I[\"initialize_wandb()\"] --> |\"Track versions\"| VH\n    I --> |\"Set current\"| CV\n    OM --> |\"log_with_version()\"| MM\n    MM --> |\"Store in WandB\"| VM\n    VH --> |\"Reference for\\nmetrics analysis\"| VM",
      "flowchart TD\n    subgraph \"Configuration Sources\"\n        DF[\"DEFAULT_HPARAMS\\nBuilt-in defaults\"]\n        HF[\"hparams.json\\nProject config\"]\n        LH[\"hparams-local-run.json\\nLocal overrides\"]\n    end\n    \n    subgraph \"Hyperparameter Processing\"\n        LHP[\"load_hparams()\\nFunction\"]\n        CNP[\"create_namespace()\\nFunction\"]\n        NS[\"SimpleNamespace\\nObject\"]\n    end\n    \n    subgraph \"Model Configuration\"\n        TK[\"Tokenizer\\nConfiguration\"]\n        MC[\"LlamaConfig\\nModel structure\"]\n    end\n    \n    HF --> |\"Load JSON\"| LHP\n    LH --> |\"Optional local\\noverrides\"| LHP\n    DF --> |\"Default values\"| CNP\n    LHP --> |\"Merged params\"| CNP\n    CNP --> |\"Initialize\"| NS\n    NS --> |\"Configure\"| TK\n    NS --> |\"Configure\"| MC\n    NS --> |\"Log to WandB\"| WB[\"WandB Config\"]",
      "sequenceDiagram\n    participant MV as \"Miner/Validator\"\n    participant HP as \"Hyperparameters\"\n    participant WI as \"WandB Integration\"\n    participant WB as \"WandB Server\"\n    \n    MV->>HP: \"load_hparams()\"\n    HP->>MV: \"Return config namespace\"\n    MV->>WI: \"initialize_wandb('miner_', uid, config, 'miners', 'miner')\"\n    WI->>WB: \"Create/resume run\"\n    WB->>WI: \"Return run object\"\n    WI->>MV: \"Return configured run with custom log method\"\n    \n    loop Training Loop\n        MV->>MV: \"Train for one step\"\n        MV->>WI: \"run.log({'loss': loss, 'perplexity': ppl})\"\n        WI->>WI: \"Add version prefixes\"\n        WI->>WB: \"Log versioned metrics\"\n    end"
    ],
    "potential_frontmatter": {
      "title": "Experiment Tracking"
    }
  },
  "/tplr-ai/templar/9.3-dashboards": {
    "original_deepwiki_href": "/tplr-ai/templar/9.3-dashboards",
    "title": "Dashboards",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/9.3-dashboards",
    "level": 1,
    "target_astro_path": "/monitoring-and-telemetry/dashboards",
    "main_markdown_content": "# Dashboards\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [telemetry/ansible/group_vars/all.yml.example](telemetry/ansible/group_vars/all.yml.example)\n- [telemetry/ansible/group_vars/vault.yml.example](telemetry/ansible/group_vars/vault.yml.example)\n- [telemetry/ansible/roles/dashboards/files/eval-metrics.json](telemetry/ansible/roles/dashboards/files/eval-metrics.json)\n- [telemetry/ansible/roles/dashboards/files/loki_logs.json](telemetry/ansible/roles/dashboards/files/loki_logs.json)\n- [telemetry/ansible/roles/dashboards/files/templar_dev.json](telemetry/ansible/roles/dashboards/files/templar_dev.json)\n- [telemetry/ansible/roles/dashboards/files/templar_metrics.json](telemetry/ansible/roles/dashboards/files/templar_metrics.json)\n- [telemetry/ansible/roles/loki/templates/loki-config.yaml.j2](telemetry/ansible/roles/loki/templates/loki-config.yaml.j2)\n\n</details>\n\n\n\nThe Templar framework includes a comprehensive set of monitoring dashboards built with Grafana that provide real-time visibility into the distributed training process. These dashboards allow operators to track validator performance, model evaluation metrics, and system logs across the network.\n\nFor information about metrics collection and logging implementation, see [Metrics Logging](#9.1) and [Experiment Tracking](#9.2).\n\n## Dashboard Architecture\n\nThe Templar monitoring system uses Grafana dashboards powered by InfluxDB for time-series metrics and Loki for logs. These dashboards are deployed through Ansible playbooks and provide visualizations for different aspects of the Templar system.\n\n```mermaid\ngraph TD\n    subgraph \"Data Collection\"\n        VM[\"Validator Metrics\"]\n        MM[\"Miner Metrics\"]\n        EM[\"Evaluator Metrics\"]\n        LG[\"System Logs\"]\n    end\n\n    subgraph \"Storage Layer\"\n        IDB[(InfluxDB)]\n        LK[(Loki)]\n    end\n\n    subgraph \"Visualization Layer\"\n        TMD[\"Templar Metrics Dashboard\"]\n        EMD[\"Evaluation Metrics Dashboard\"]\n        LD[\"Logs Dashboard\"]\n        DD[\"Development Dashboard\"]\n    end\n\n    VM --> IDB\n    MM --> IDB\n    EM --> IDB\n    LG --> LK\n\n    IDB --> TMD\n    IDB --> EMD\n    IDB --> DD\n    LK --> LD\n```\n\nSources: [telemetry/ansible/group_vars/all.yml.example]()\n\n## Available Dashboards\n\n### Templar Metrics Dashboard\n\nThe main metrics dashboard provides comprehensive visibility into validator performance and is defined in `templar_metrics.json`. It includes panels for:\n\n- Validator loss tracking (by training window)\n- Time-based performance metrics\n- Processing time breakdowns\n- Global state metrics\n\n```mermaid\ngraph TD\n    subgraph \"Validator Window Metrics\"\n        VL[\"Loss Metrics\"]\n        VPT[\"Peer Update Time\"]\n        VMT[\"Model Update Time\"]\n        VWT[\"Window Total Time\"]\n    end\n\n    subgraph \"Performance Metrics\"\n        GT[\"Gather Time\"]\n        ET[\"Evaluation Time\"]\n        TS[\"Total Skipped\"]\n    end\n\n    subgraph \"State Metrics\"\n        GS[\"Global Step\"]\n        WN[\"Window Number\"]\n    end\n\n    subgraph \"Dashboard Panels\"\n        LP[\"Loss Panels\"]\n        TP[\"Timing Panels\"]\n        SP[\"State Panels\"]\n    end\n\n    VL --> LP\n    VPT --> TP\n    VMT --> TP\n    VWT --> TP\n    \n    GT --> TP\n    ET --> TP\n    TS --> TP\n    \n    GS --> SP\n    WN --> SP\n```\n\nSources: [telemetry/ansible/roles/dashboards/files/templar_metrics.json:66-748]()\n\n#### Key Features\n\nThe Templar Metrics Dashboard includes:\n\n1. **Loss Tracking**: Visualizes validator loss by window with both window-axis and time-axis views\n2. **Performance Monitoring**: Tracks key timing metrics:\n   - Peer update time\n   - Model update time\n   - Window total time\n   - Gather time\n   - Evaluation time\n3. **State Monitoring**: Shows global step and window number information\n4. **Filtering**: Supports filtering by UID and version\n\nAll metrics are tagged with version, UID, and configuration parameters, enabling precise filtering and correlation across different system components.\n\nSources: [telemetry/ansible/roles/dashboards/files/templar_metrics.json:179-198]()\n\n### Evaluation Metrics Dashboard\n\nThe evaluation dashboard (`eval-metrics.json`) focuses on model benchmark performance with trend charts for various benchmark tasks:\n\n- Hellaswag\n- MMLU\n- PIQA\n- ARC Challenge\n- ARC Easy\n- OpenBookQA\n- Winogrande\n\n```mermaid\ngraph TD\n    subgraph \"Benchmark Tasks\"\n        HS[\"Hellaswag\"]\n        MM[\"MMLU\"]\n        PQ[\"PIQA\"]\n        AC[\"ARC Challenge\"]\n        AE[\"ARC Easy\"]\n        OB[\"OpenBookQA\"]\n        WG[\"Winogrande\"]\n    end\n\n    subgraph \"Visualization Types\"\n        TC[\"Trend Charts\"]\n        LS[\"Latest Scores\"]\n    end\n\n    subgraph \"Chart Components\"\n        SA[\"Step Axis\"]\n        TF[\"Timeline Filter\"]\n        VF[\"Version Filter\"]\n    end\n\n    HS --> TC\n    MM --> TC\n    PQ --> TC\n    AC --> TC\n    AE --> TC\n    OB --> TC\n    WG --> TC\n    \n    TC --> LS\n    \n    SA --> TC\n    TF --> TC\n    VF --> TC\n```\n\nSources: [telemetry/ansible/roles/dashboards/files/eval-metrics.json:117-142](), [telemetry/ansible/roles/dashboards/files/eval-metrics.json:204-236]()\n\n#### Key Features\n\n1. **Step-based Tracking**: Charts show model performance vs. training step\n2. **Multi-version Comparison**: Supports comparing multiple Templar versions\n3. **Benchmark Aggregation**: Displays all benchmark scores on a single panel\n4. **Time Range Selection**: Customizable time range for historical analysis\n\nSources: [telemetry/ansible/roles/dashboards/files/eval-metrics.json:737-773]()\n\n### Logs Dashboard\n\nThe Logs Dashboard (`loki_logs.json`) provides a centralized view of system logs from all Templar components:\n\n```mermaid\ngraph TD\n    subgraph \"Log Sources\"\n        VM[\"Validator Logs\"]\n        MM[\"Miner Logs\"]\n        AG[\"Aggregator Logs\"]\n        EV[\"Evaluator Logs\"]\n    end\n\n    subgraph \"Loki Storage System\"\n        LK[(Loki)]\n        FT[\"Fluentd\"]\n        R2[\"R2 Log Archival\"]\n    end\n\n    subgraph \"Dashboard Filters\"\n        SF[\"Service Filter\"]\n        VF[\"Version Filter\"]\n        UF[\"UID Filter\"]\n        LL[\"Log Level Filter\"]\n        TS[\"Text Search\"]\n    end\n\n    VM --> LK\n    MM --> LK\n    AG --> LK\n    EV --> LK\n    \n    LK <--> FT\n    FT --> R2\n    \n    LK --> SF\n    SF --> VF\n    VF --> UF\n    UF --> LL\n    LL --> TS\n```\n\nSources: [telemetry/ansible/roles/dashboards/files/loki_logs.json:87-97](), [telemetry/ansible/roles/loki/templates/loki-config.yaml.j2]()\n\n#### Key Features\n\n1. **Service Filtering**: Filter logs by service (validator, miner, etc.)\n2. **UID Filtering**: Focus on specific node UIDs\n3. **Log Level Filtering**: Filter by severity (error, warning, info, debug)\n4. **Text Search**: Full-text search capabilities\n5. **Real-time Updates**: Live streaming of new log entries\n6. **Integration**: Links to other dashboards for context\n\nSources: [telemetry/ansible/roles/dashboards/files/loki_logs.json:94-97](), [telemetry/ansible/roles/dashboards/files/loki_logs.json:110-143]()\n\n### Development Dashboard\n\nThe Development Dashboard (`templar_dev.json`) provides similar metrics to the main dashboard but is configured specifically for development environments:\n\n- Additional filtering parameters\n- Development-specific metrics\n- Customized for local testing\n\nSources: [telemetry/ansible/roles/dashboards/files/templar_dev.json:192-197]()\n\n## Dashboard Deployment and Configuration\n\nThe dashboards are deployed and configured using Ansible playbooks within the telemetry subsystem:\n\n```mermaid\ngraph TD\n    subgraph \"Configuration Files\"\n        TM[\"templar_metrics.json\"]\n        EM[\"eval-metrics.json\"]\n        LL[\"loki_logs.json\"]\n        TD[\"templar_dev.json\"]\n    end\n\n    subgraph \"Ansible Deployment\"\n        AP[\"Ansible Playbook\"]\n        DT[\"Dashboard Templates\"]\n        DS[\"Datasource Config\"]\n    end\n\n    subgraph \"Grafana\"\n        GF[\"Grafana Server\"]\n        PR[\"Provisioning\"]\n        VA[\"Variables & Templates\"]\n    end\n\n    TM --> DT\n    EM --> DT\n    LL --> DT\n    TD --> DT\n    \n    DT --> AP\n    DS --> AP\n    \n    AP --> PR\n    PR --> GF\n    GF --> VA\n```\n\nSources: [telemetry/ansible/group_vars/all.yml.example:6-69]()\n\n### Configuration Parameters\n\nKey configuration parameters for the dashboard deployment include:\n\n| Parameter | Description | Default |\n|-----------|-------------|---------|\n| `grafana_version` | Grafana version to install | 10.4.0 |\n| `grafana_http_port` | HTTP port for Grafana | 3000 |\n| `grafana_auth_anonymous_enabled` | Enable anonymous access | true |\n| `grafana_influxdb_host` | InfluxDB host | localhost |\n| `grafana_influxdb_port` | InfluxDB port | 8086 |\n| `loki_http_listen_port` | Loki HTTP port | 3100 |\n| `loki_retention_period` | Log retention period | 720h (30 days) |\n\nSources: [telemetry/ansible/group_vars/all.yml.example:7-14](), [telemetry/ansible/group_vars/all.yml.example:95-101]()\n\n### Vault Integration\n\nSensitive configuration values such as API tokens and credentials are stored in an Ansible vault:\n\n- InfluxDB tokens\n- Grafana admin credentials\n- R2 storage credentials\n\nSources: [telemetry/ansible/group_vars/vault.yml.example]()\n\n## Using the Dashboards\n\n### Dashboard Variables\n\nAll dashboards use template variables for filtering:\n\n1. **templar_version**: Filter by specific Templar version\n2. **uid**: Filter by specific node UID\n3. **config_netuid**: Filter by network UID (for dev dashboard)\n4. **log_level**: Filter logs by severity level\n\nVariables can be changed using the dropdown selectors at the top of each dashboard.\n\nSources: [telemetry/ansible/roles/dashboards/files/loki_logs.json:111-205](), [telemetry/ansible/roles/dashboards/files/eval-metrics.json:784-813]()\n\n### Interpreting Key Metrics\n\n#### Validator Performance\n\nThe most important validator metrics to monitor are:\n\n1. **Loss Metrics**: Track how loss changes across training windows\n2. **Timing Metrics**: Monitor for processing bottlenecks\n3. **Skipped Updates**: High skip counts may indicate problems\n4. **Global Step**: Shows training progress\n\n#### Evaluation Benchmarks\n\nEvaluation charts show model performance on standard benchmarks:\n\n1. **Step-based Charts**: Track improvement over training steps\n2. **Latest Scores Panel**: Quick overview of current performance\n3. **Version Comparison**: Compare different model versions\n\n#### Log Analysis\n\nThe logs dashboard helps with troubleshooting:\n\n1. **Error Investigation**: Filter for error/critical logs\n2. **Component Isolation**: Filter by service name\n3. **UID Correlation**: Track issues on specific nodes\n4. **Text Search**: Find specific error messages or patterns\n\n## Best Practices\n\n1. **Regular Monitoring**: Check dashboards regularly during training\n2. **Version Tagging**: Always use consistent version tagging\n3. **Custom Time Ranges**: Adjust time ranges for relevant views\n4. **Dashboard Links**: Use links between dashboards for context\n5. **Variable Combinations**: Combine multiple filters for precise analysis\n\nSources: [telemetry/ansible/roles/dashboards/files/templar_metrics.json:27-64](), [telemetry/ansible/roles/dashboards/files/loki_logs.json:28-40]()",
    "resolved_links": [
      {
        "text": "telemetry/ansible/group_vars/all.yml.example",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/group_vars/all.yml.example",
        "original_deepwiki_href": "telemetry/ansible/group_vars/all.yml.example",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/group_vars/vault.yml.example",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/group_vars/vault.yml.example",
        "original_deepwiki_href": "telemetry/ansible/group_vars/vault.yml.example",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/eval-metrics.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/roles/dashboards/files/eval-metrics.json",
        "original_deepwiki_href": "telemetry/ansible/roles/dashboards/files/eval-metrics.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/loki_logs.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/roles/dashboards/files/loki_logs.json",
        "original_deepwiki_href": "telemetry/ansible/roles/dashboards/files/loki_logs.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/templar_dev.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/roles/dashboards/files/templar_dev.json",
        "original_deepwiki_href": "telemetry/ansible/roles/dashboards/files/templar_dev.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/templar_metrics.json",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/roles/dashboards/files/templar_metrics.json",
        "original_deepwiki_href": "telemetry/ansible/roles/dashboards/files/templar_metrics.json",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/roles/loki/templates/loki-config.yaml.j2",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/telemetry/ansible/roles/loki/templates/loki-config.yaml.j2",
        "original_deepwiki_href": "telemetry/ansible/roles/loki/templates/loki-config.yaml.j2",
        "context": "collapsible_aside_link"
      },
      {
        "text": "telemetry/ansible/group_vars/all.yml.example",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/templar_metrics.json:66-748",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/templar_metrics.json:179-198",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/eval-metrics.json:117-142",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/eval-metrics.json:204-236",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/eval-metrics.json:737-773",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/loki_logs.json:87-97",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/loki/templates/loki-config.yaml.j2",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/loki_logs.json:94-97",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/loki_logs.json:110-143",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/templar_dev.json:192-197",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/group_vars/all.yml.example:6-69",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/group_vars/all.yml.example:7-14",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/group_vars/all.yml.example:95-101",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/group_vars/vault.yml.example",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/loki_logs.json:111-205",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/eval-metrics.json:784-813",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/templar_metrics.json:27-64",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "telemetry/ansible/roles/dashboards/files/loki_logs.json:28-40",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Metrics Logging",
        "href": "/monitoring-and-telemetry/metrics-logging#9.1",
        "original_deepwiki_href": "#9.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Experiment Tracking",
        "href": "/monitoring-and-telemetry/experiment-tracking#9.2",
        "original_deepwiki_href": "#9.2",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Data Collection\"\n        VM[\"Validator Metrics\"]\n        MM[\"Miner Metrics\"]\n        EM[\"Evaluator Metrics\"]\n        LG[\"System Logs\"]\n    end\n\n    subgraph \"Storage Layer\"\n        IDB[(InfluxDB)]\n        LK[(Loki)]\n    end\n\n    subgraph \"Visualization Layer\"\n        TMD[\"Templar Metrics Dashboard\"]\n        EMD[\"Evaluation Metrics Dashboard\"]\n        LD[\"Logs Dashboard\"]\n        DD[\"Development Dashboard\"]\n    end\n\n    VM --> IDB\n    MM --> IDB\n    EM --> IDB\n    LG --> LK\n\n    IDB --> TMD\n    IDB --> EMD\n    IDB --> DD\n    LK --> LD",
      "graph TD\n    subgraph \"Validator Window Metrics\"\n        VL[\"Loss Metrics\"]\n        VPT[\"Peer Update Time\"]\n        VMT[\"Model Update Time\"]\n        VWT[\"Window Total Time\"]\n    end\n\n    subgraph \"Performance Metrics\"\n        GT[\"Gather Time\"]\n        ET[\"Evaluation Time\"]\n        TS[\"Total Skipped\"]\n    end\n\n    subgraph \"State Metrics\"\n        GS[\"Global Step\"]\n        WN[\"Window Number\"]\n    end\n\n    subgraph \"Dashboard Panels\"\n        LP[\"Loss Panels\"]\n        TP[\"Timing Panels\"]\n        SP[\"State Panels\"]\n    end\n\n    VL --> LP\n    VPT --> TP\n    VMT --> TP\n    VWT --> TP\n    \n    GT --> TP\n    ET --> TP\n    TS --> TP\n    \n    GS --> SP\n    WN --> SP",
      "graph TD\n    subgraph \"Benchmark Tasks\"\n        HS[\"Hellaswag\"]\n        MM[\"MMLU\"]\n        PQ[\"PIQA\"]\n        AC[\"ARC Challenge\"]\n        AE[\"ARC Easy\"]\n        OB[\"OpenBookQA\"]\n        WG[\"Winogrande\"]\n    end\n\n    subgraph \"Visualization Types\"\n        TC[\"Trend Charts\"]\n        LS[\"Latest Scores\"]\n    end\n\n    subgraph \"Chart Components\"\n        SA[\"Step Axis\"]\n        TF[\"Timeline Filter\"]\n        VF[\"Version Filter\"]\n    end\n\n    HS --> TC\n    MM --> TC\n    PQ --> TC\n    AC --> TC\n    AE --> TC\n    OB --> TC\n    WG --> TC\n    \n    TC --> LS\n    \n    SA --> TC\n    TF --> TC\n    VF --> TC",
      "graph TD\n    subgraph \"Log Sources\"\n        VM[\"Validator Logs\"]\n        MM[\"Miner Logs\"]\n        AG[\"Aggregator Logs\"]\n        EV[\"Evaluator Logs\"]\n    end\n\n    subgraph \"Loki Storage System\"\n        LK[(Loki)]\n        FT[\"Fluentd\"]\n        R2[\"R2 Log Archival\"]\n    end\n\n    subgraph \"Dashboard Filters\"\n        SF[\"Service Filter\"]\n        VF[\"Version Filter\"]\n        UF[\"UID Filter\"]\n        LL[\"Log Level Filter\"]\n        TS[\"Text Search\"]\n    end\n\n    VM --> LK\n    MM --> LK\n    AG --> LK\n    EV --> LK\n    \n    LK <--> FT\n    FT --> R2\n    \n    LK --> SF\n    SF --> VF\n    VF --> UF\n    UF --> LL\n    LL --> TS",
      "graph TD\n    subgraph \"Configuration Files\"\n        TM[\"templar_metrics.json\"]\n        EM[\"eval-metrics.json\"]\n        LL[\"loki_logs.json\"]\n        TD[\"templar_dev.json\"]\n    end\n\n    subgraph \"Ansible Deployment\"\n        AP[\"Ansible Playbook\"]\n        DT[\"Dashboard Templates\"]\n        DS[\"Datasource Config\"]\n    end\n\n    subgraph \"Grafana\"\n        GF[\"Grafana Server\"]\n        PR[\"Provisioning\"]\n        VA[\"Variables & Templates\"]\n    end\n\n    TM --> DT\n    EM --> DT\n    LL --> DT\n    TD --> DT\n    \n    DT --> AP\n    DS --> AP\n    \n    AP --> PR\n    PR --> GF\n    GF --> VA"
    ],
    "potential_frontmatter": {
      "title": "Dashboards"
    }
  },
  "/tplr-ai/templar/10-development-guide": {
    "original_deepwiki_href": "/tplr-ai/templar/10-development-guide",
    "title": "Development Guide",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/10-development-guide",
    "level": 0,
    "target_astro_path": "/development-guide",
    "main_markdown_content": "# Development Guide\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [.github/workflows/ci.yml](.github/workflows/ci.yml)\n- [.gitignore](.gitignore)\n- [codecov.yml](codecov.yml)\n- [justfile](justfile)\n- [scripts/start.sh](scripts/start.sh)\n\n</details>\n\n\n\nThis guide provides comprehensive instructions for developers contributing to the Templar project. It covers setting up your development environment, working with the codebase, testing procedures, and understanding the CI/CD pipeline. For deployment-specific information, see [Deployment](#8).\n\n## Development Environment Setup\n\nSetting up your development environment requires installing the necessary dependencies and configuring your local system to work with the Templar codebase.\n\n### Prerequisites\n\n- Python 3.11 or 3.12\n- Git\n- PM2 (for process management)\n- UV (Python package installer and environment manager)\n\n### Installation\n\n1. Clone the repository:\n   ```bash\n   git clone https://github.com/tplr-ai/templar.git\n   cd templar\n   ```\n\n2. Install dependencies using UV:\n   ```bash\n   uv venv\n   source .venv/bin/activate\n   uv pip install --pre -e \".[dev]\"\n   ```\n\n   Alternatively, use the provided convenience command in the justfile:\n   ```bash\n   just dev\n   ```\n\n3. Create a `.env` file with required environment variables (see the CI configuration for examples of required variables)\n\nSources: [justfile:23-24](), [.github/workflows/ci.yml:77-100]()\n\n### Development Tools\n\nTemplar uses several development tools:\n\n- **UV**: Modern Python package installer and environment manager\n- **Ruff**: Fast Python linter and formatter\n- **Pytest**: Testing framework\n- **PM2**: Process manager for running multiple components\n- **Just**: Command runner for common development tasks\n\n```mermaid\ngraph TD\n    subgraph \"Development Environment\"\n        UV[\"UV Package Manager\"]\n        RUFF[\"Ruff Linter/Formatter\"]\n        PYTEST[\"Pytest Testing\"]\n        PM2[\"PM2 Process Manager\"]\n        JUST[\"Justfile Command Runner\"]\n    end\n\n    subgraph \"Developer Workflow\"\n        SETUP[\"Setup Environment\"]\n        DEVELOP[\"Write Code\"]\n        TEST[\"Run Tests\"]\n        LINT[\"Format & Lint\"]\n        RUN[\"Run Application\"]\n        PR[\"Submit PR\"]\n    end\n\n    UV --> SETUP\n    SETUP --> DEVELOP\n    DEVELOP --> TEST\n    TEST --> LINT\n    LINT --> RUN\n    RUN --> PR\n    \n    JUST --> LINT\n    JUST --> TEST\n    PYTEST --> TEST\n    RUFF --> LINT\n    PM2 --> RUN\n```\n\nSources: [.github/workflows/ci.yml:30-38](), [justfile:5-12](), [scripts/start.sh:1-16]()\n\n## Development Workflow\n\n### Using Just Commands\n\nThe project includes a `justfile` that provides shortcuts for common development tasks:\n\n| Command | Description |\n|---------|-------------|\n| `just lint` | Run ruff to check and format code |\n| `just fix` | Alias for `just lint` |\n| `just dev` | Install development dependencies |\n| `just test` | Run tests |\n| `just cov` | Run tests with coverage report |\n| `just test-run` | Create a development version and start the application |\n| `just bistro` | Check for running Bistro processes |\n\nSources: [justfile:1-33]()\n\n### Code Formatting and Linting\n\nThe project uses Ruff for both code formatting and linting:\n\n```bash\n# Manually run linting\nruff check --fix .\nruff format .\n\n# Or use the shortcut\njust lint\n```\n\nThe formatting rules are enforced in CI, so all code must pass these checks before being merged.\n\nSources: [justfile:5-12](), [.github/workflows/ci.yml:40-44]()\n\n### Starting the Application\n\nTo start the application locally:\n\n```bash\n# Using PM2 process manager\n./scripts/start.sh\n```\n\nThis script will:\n1. Stop any existing PM2 processes\n2. Check for zombie processes\n3. Start all applications defined in `ecosystem.config.js`\n4. Show logs from the TM1 process\n\nSources: [scripts/start.sh:1-16]()\n\n## Testing\n\n### Running Tests\n\nTests are written using pytest and can be run with:\n\n```bash\n# Run all tests\npytest tests/ -v\n\n# Run with coverage report\npytest tests/ -v --cov=src --cov-report=xml --cov-report=term\n\n# Or use the shortcuts\njust test\njust cov\n```\n\nSources: [justfile:25-32](), [.github/workflows/ci.yml:113-114]()\n\n### Test Coverage Requirements\n\nThe project maintains a minimum code coverage target of 85% with a threshold of 1%. This is enforced in the CI pipeline.\n\n```mermaid\ngraph LR\n    subgraph \"Test Process\"\n        WC[\"Write Code\"]\n        WT[\"Write Tests\"]\n        RT[\"Run Tests\"]\n        CC[\"Check Coverage\"]\n        PC[\"Pass/Fail CI\"]\n    end\n\n    WC --> WT\n    WT --> RT\n    RT --> CC\n    CC --> PC\n\n    subgraph \"Coverage Requirements\"\n        PR[\"Project Coverage: 85%\"]\n        PT[\"Patch Coverage: 85%\"]\n        TH[\"Threshold: 1%\"]\n    end\n\n    PR -.-> CC\n    PT -.-> CC\n    TH -.-> CC\n```\n\nSources: [codecov.yml:1-11](), [.github/workflows/ci.yml:112-121]()\n\n## CI/CD Pipeline\n\nThe project uses GitHub Actions for continuous integration and deployment. The CI pipeline runs on both push to main and pull requests.\n\n### Workflow Steps\n\n```mermaid\nflowchart TD\n    subgraph \"GitHub Actions CI Workflow\"\n        direction TB\n        TRIG[\"Trigger: Push to main/PR\"]\n        \n        subgraph \"Block Fixup Job\"\n            BF[\"Block Fixup Commit Merge\"]\n        end\n        \n        subgraph \"Lint & Format Job\"\n            LF1[\"Setup Python (3.11/3.12)\"]\n            LF2[\"Install Dependencies\"]\n            LF3[\"Run Ruff Lint\"]\n            LF4[\"Run Ruff Format\"]\n        end\n        \n        subgraph \"Test Job\"\n            T1[\"Setup Python (3.11/3.12)\"]\n            T2[\"Create .env file\"]\n            T3[\"Install Dependencies\"]\n            T4[\"Run Tests with Coverage\"]\n            T5[\"Upload to Codecov\"]\n        end\n    end\n\n    TRIG --> BF\n    TRIG --> LF1\n    TRIG --> T1\n    \n    LF1 --> LF2 --> LF3 --> LF4\n    T1 --> T2 --> T3 --> T4 --> T5\n```\n\nThe CI workflow includes three main jobs:\n\n1. **Block Fixup**: Prevents merging PRs that contain fixup commits\n2. **Lint and Format**: Checks code style and formatting\n3. **Test**: Runs the test suite with coverage reporting\n\nSources: [.github/workflows/ci.yml:1-122]()\n\n### Environment Setup in CI\n\nThe CI environment automatically sets up:\n\n1. Python versions (3.11 and 3.12) using a matrix strategy\n2. UV package manager\n3. Environment variables for R2 storage services\n\nSources: [.github/workflows/ci.yml:47-70](), [.github/workflows/ci.yml:102-110]()\n\n### Code Coverage Reporting\n\nTest coverage reports are uploaded to Codecov:\n\n1. Coverage is generated as XML during test runs\n2. The Codecov GitHub Action uploads the report\n3. PRs must maintain coverage thresholds to pass checks\n\nSources: [.github/workflows/ci.yml:116-121](), [codecov.yml:1-15]()\n\n## Development Best Practices\n\n### File Structure\n\nTemplar follows a standard Python package structure:\n\n- `src/tplr/`: Core package code\n- `tests/`: Test suite\n- `scripts/`: Utility scripts\n- `.github/workflows/`: CI configuration\n- `justfile`: Development tasks\n\n### Pull Request Process\n\n1. Create a feature branch from `main`\n2. Make your changes following the code style guidelines\n3. Write tests to maintain coverage\n4. Run linting and tests locally before pushing\n5. Create a PR targeting `main`\n6. Ensure all CI checks pass\n7. Address review feedback\n8. Merge when approved\n\n### Version Management\n\nThe project automatically assigns development versions during test runs:\n\n```bash\nsed -i \"s/__version__ = .*/__version__ = \\\"dev-$(cat /dev/urandom \\\n    | tr -dc 'a-z0-9' \\\n    | fold -w 8 \\\n    | head -n 1)\\\"/\" \\\n    src/tplr/__init__.py\n```\n\nSources: [justfile:13-20]()\n\n### Gitignore Rules\n\nThe project's `.gitignore` is set up to exclude:\n- Environment files (`.env`, `.env.yaml`)\n- Python artifacts (`__pycache__`, `.egg-info`, etc.)\n- Virtual environments (`.uv/`, `.venv/`, etc.)\n- IDE files (`.idea/`, `.vscode/`, etc.)\n- Project-specific files (`wandb`, models, etc.)\n\nSources: [.gitignore:1-84]()\n\n## Next Steps\n\nFor information on how to deploy the system, refer to the [Deployment](#8) guide.\n\nFor subsystem-specific details, check the following:\n- [Miners](#2) for miner development\n- [Validators](#3) for validator development\n- [System Architecture](#1.1) for understanding the overall system design",
    "resolved_links": [
      {
        "text": ".github/workflows/ci.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/.github/workflows/ci.yml",
        "original_deepwiki_href": ".github/workflows/ci.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": ".gitignore",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/.gitignore",
        "original_deepwiki_href": ".gitignore",
        "context": "collapsible_aside_link"
      },
      {
        "text": "codecov.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/codecov.yml",
        "original_deepwiki_href": "codecov.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "justfile",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/justfile",
        "original_deepwiki_href": "justfile",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/start.sh",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/start.sh",
        "original_deepwiki_href": "scripts/start.sh",
        "context": "collapsible_aside_link"
      },
      {
        "text": "justfile:23-24",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:77-100",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:30-38",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:5-12",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/start.sh:1-16",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:1-33",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:40-44",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:25-32",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:113-114",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "codecov.yml:1-11",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:112-121",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:1-122",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:47-70",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:102-110",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:116-121",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "codecov.yml:1-15",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:13-20",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".gitignore:1-84",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Deployment",
        "href": "/deployment#8",
        "original_deepwiki_href": "#8",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Deployment",
        "href": "/deployment#8",
        "original_deepwiki_href": "#8",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Miners",
        "href": "/miners#2",
        "original_deepwiki_href": "#2",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Validators",
        "href": "/validators#3",
        "original_deepwiki_href": "#3",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "System Architecture",
        "href": "/system-architecture#1.1",
        "original_deepwiki_href": "#1.1",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "graph TD\n    subgraph \"Development Environment\"\n        UV[\"UV Package Manager\"]\n        RUFF[\"Ruff Linter/Formatter\"]\n        PYTEST[\"Pytest Testing\"]\n        PM2[\"PM2 Process Manager\"]\n        JUST[\"Justfile Command Runner\"]\n    end\n\n    subgraph \"Developer Workflow\"\n        SETUP[\"Setup Environment\"]\n        DEVELOP[\"Write Code\"]\n        TEST[\"Run Tests\"]\n        LINT[\"Format & Lint\"]\n        RUN[\"Run Application\"]\n        PR[\"Submit PR\"]\n    end\n\n    UV --> SETUP\n    SETUP --> DEVELOP\n    DEVELOP --> TEST\n    TEST --> LINT\n    LINT --> RUN\n    RUN --> PR\n    \n    JUST --> LINT\n    JUST --> TEST\n    PYTEST --> TEST\n    RUFF --> LINT\n    PM2 --> RUN",
      "graph LR\n    subgraph \"Test Process\"\n        WC[\"Write Code\"]\n        WT[\"Write Tests\"]\n        RT[\"Run Tests\"]\n        CC[\"Check Coverage\"]\n        PC[\"Pass/Fail CI\"]\n    end\n\n    WC --> WT\n    WT --> RT\n    RT --> CC\n    CC --> PC\n\n    subgraph \"Coverage Requirements\"\n        PR[\"Project Coverage: 85%\"]\n        PT[\"Patch Coverage: 85%\"]\n        TH[\"Threshold: 1%\"]\n    end\n\n    PR -.-> CC\n    PT -.-> CC\n    TH -.-> CC",
      "flowchart TD\n    subgraph \"GitHub Actions CI Workflow\"\n        direction TB\n        TRIG[\"Trigger: Push to main/PR\"]\n        \n        subgraph \"Block Fixup Job\"\n            BF[\"Block Fixup Commit Merge\"]\n        end\n        \n        subgraph \"Lint & Format Job\"\n            LF1[\"Setup Python (3.11/3.12)\"]\n            LF2[\"Install Dependencies\"]\n            LF3[\"Run Ruff Lint\"]\n            LF4[\"Run Ruff Format\"]\n        end\n        \n        subgraph \"Test Job\"\n            T1[\"Setup Python (3.11/3.12)\"]\n            T2[\"Create .env file\"]\n            T3[\"Install Dependencies\"]\n            T4[\"Run Tests with Coverage\"]\n            T5[\"Upload to Codecov\"]\n        end\n    end\n\n    TRIG --> BF\n    TRIG --> LF1\n    TRIG --> T1\n    \n    LF1 --> LF2 --> LF3 --> LF4\n    T1 --> T2 --> T3 --> T4 --> T5"
    ],
    "potential_frontmatter": {
      "title": "Development Guide"
    }
  },
  "/tplr-ai/templar/10.1-development-environment": {
    "original_deepwiki_href": "/tplr-ai/templar/10.1-development-environment",
    "title": "Development Environment",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/10.1-development-environment",
    "level": 1,
    "target_astro_path": "/development-guide/development-environment",
    "main_markdown_content": "# Development Environment\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [.gitignore](.gitignore)\n- [justfile](justfile)\n- [scripts/start.sh](scripts/start.sh)\n\n</details>\n\n\n\nThis document provides comprehensive guidance for setting up and using the development environment for the Templar decentralized training framework. It covers environment setup, development tools, and common workflows for contributors. For information about testing specifically, see [Testing](#10.2). For deployment options, see [Deployment](#8).\n\n## Environment Setup\n\nSetting up your development environment for Templar requires installing several dependencies and configuring your local environment.\n\n### Prerequisites\n\n- Python 3.10 or newer\n- UV (Python package manager)\n- PM2 (Process manager for Node.js)\n- Git\n\n### Development Installation\n\nTemplar uses UV for dependency management. To set up your development environment:\n\n```bash\n# Clone the repository\ngit clone https://github.com/tplr-ai/templar\ncd templar\n\n# Install development dependencies\njust dev\n```\n\nThe `just dev` command runs `uv pip install --pre -e \".[dev]\"` which installs the package in development mode with all development dependencies.\n\nSources: [justfile:22-23]()\n\n### Environment Files\n\nTemplar uses `.env.yaml` and `.env` files for configuration, which are excluded from version control. You'll need to create these files based on your local setup.\n\nSources: [.gitignore:1-2]()\n\n## Development Tools\n\nTemplar uses several tools to streamline the development process.\n\n```mermaid\nflowchart TD\n    subgraph \"Development Environment\"\n        UV[\"UV Package Manager\"]\n        Just[\"Just Command Runner\"]\n        Ruff[\"Ruff Linter & Formatter\"]\n        PyTest[\"PyTest Testing Framework\"]\n        PM2[\"PM2 Process Manager\"]\n    end\n\n    Just -->|\"just dev\"| UV\n    Just -->|\"just lint\"| Ruff\n    Just -->|\"just test\"| PyTest\n    Just -->|\"just test-run\"| TestRun[\"Test Run Script\"]\n    Just -->|\"just cov\"| Coverage[\"Code Coverage\"]\n    PM2 --- Start[\"scripts/start.sh\"]\n    \n    TestRun --> PM2\n    \n    class UV,Just,Ruff,PyTest,PM2 interface;\n```\n\n### Just Command Runner\n\nTemplar uses `just` as a command runner. The following commands are available:\n\n| Command | Description |\n|---------|-------------|\n| `just lint` | Run ruff check with auto-fix and format |\n| `just fix` | Alias for `just lint` |\n| `just test-run` | Run a development version with randomized version |\n| `just dev` | Install development dependencies |\n| `just test` | Run pytest |\n| `just cov` | Run pytest with coverage reporting |\n| `just bistro` | Check for zombie Bistro processes |\n\nSources: [justfile:5-33]()\n\n### UV Package Manager\n\nTemplar uses UV for Python package management instead of pip. UV provides faster dependency resolution and installation.\n\nSources: [justfile:22-23](), [.gitignore:29-34]()\n\n### PM2 Process Manager\n\nTemplar uses PM2 to manage its processes. The `scripts/start.sh` script manages the startup of all components using PM2:\n\n```mermaid\nflowchart LR\n    subgraph \"Process Management\"\n        Start[\"start.sh\"]\n        PM2[\"PM2\"]\n        Config[\"ecosystem.config.js\"]\n        Processes[\"Templar Processes\"]\n    end\n\n    Start -->|\"pm2 delete all\"| PM2\n    Start -->|\"Check zombie processes\"| ZombieCheck[\"ps aux | grep Bistro\"]\n    Start -->|\"pm2 start\"| Config\n    Config --> PM2\n    PM2 --> Processes\n    Start -->|\"pm2 log TM1\"| Logs[\"Process Logs\"]\n```\n\nThe `ecosystem.config.js` file contains the configuration for all processes that need to be started.\n\nSources: [scripts/start.sh:1-16]()\n\n## Directory Structure\n\nThe Templar repository follows a standard Python package structure with some additional directories for specific purposes.\n\n```mermaid\ngraph TD\n    subgraph \"Repository Structure\"\n        Root[\"templar/\"]\n        Src[\"src/\"]\n        Scripts[\"scripts/\"]\n        Tests[\"tests/\"]\n        Neurons[\"neurons/\"]\n        Data[\"data/\"]\n        Models[\"models/\"]\n    end\n\n    Root --> Src\n    Root --> Scripts\n    Root --> Tests\n    Root --> Neurons\n    Root --> Data\n    Root --> Models\n\n    Src --> TPLR[\"tplr/\"]\n    Scripts --> StartSh[\"start.sh\"]\n    Scripts --> OtherScripts[\"Other utility scripts\"]\n```\n\n### Ignored Files and Directories\n\nThe `.gitignore` file lists files and directories that are excluded from version control. Notable exclusions include:\n\n- Environment files (`.env.yaml`, `.env`)\n- Python cache files (`__pycache__/`, `*.pyc`, etc.)\n- Virtual environment directories (`.venv/`, `venv/`, `.env/`)\n- Build artifacts (`build/`, `dist/`, `*.egg-info/`)\n- IDE-specific files (`.idea/`, `.vscode/`)\n- Node.js files (`node_modules/`, package lock files)\n- Project-specific files (`wandb`, model files, data directories)\n\nSources: [.gitignore:1-84]()\n\n## Development Workflow\n\nThe typical development workflow for Templar involves the following steps:\n\n```mermaid\nsequenceDiagram\n    participant Developer\n    participant Git as \"Git Repository\"\n    participant Local as \"Local Environment\"\n    participant PM2 as \"PM2 Process Manager\"\n    \n    Developer->>Git: Clone repository\n    Developer->>Local: just dev (Install dependencies)\n    Developer->>Local: Make code changes\n    Developer->>Local: just lint (Run code formatting)\n    Developer->>Local: just test (Run tests)\n    Developer->>PM2: just test-run (Test with PM2)\n    Developer->>Git: Commit and push changes\n```\n\n### Making Changes\n\nWhen making changes to the codebase:\n\n1. **Install dependencies**: Run `just dev` to ensure you have all required dependencies.\n2. **Make changes**: Edit code as needed.\n3. **Lint code**: Run `just lint` to automatically format and check code style.\n4. **Run tests**: Use `just test` to run tests or `just cov` to generate coverage reports.\n5. **Test locally**: Run `just test-run` to test your changes using PM2.\n\nSources: [justfile:5-33](), [scripts/start.sh:1-16]()\n\n### Running the Application\n\nTo start all components locally:\n\n```bash\n./scripts/start.sh\n```\n\nThis command:\n1. Stops any existing PM2 processes\n2. Checks for zombie Bistro processes\n3. Starts all applications defined in the ecosystem.config.js file\n4. Attaches to the logs of the TM1 process\n\nSources: [scripts/start.sh:1-16]()\n\n## Code Quality Tools\n\nTemplar uses several tools to maintain code quality:\n\n### Ruff\n\nRuff is used for both linting and formatting Python code. Run:\n\n```bash\njust lint  # Or just fix\n```\n\nThis runs `ruff check --fix .` and `ruff format .` to automatically fix issues and format code.\n\nSources: [justfile:5-11]()\n\n### Pytest\n\nPytest is used for running tests. The project supports several test commands:\n\n```bash\njust test  # Run all tests\njust cov   # Run tests with coverage reporting\n```\n\nSources: [justfile:25-32]()\n\n## Version Management\n\nDuring development, a temporary version string is generated for test runs:\n\n```bash\njust test-run\n```\n\nThis command:\n1. Temporarily modifies the version string in `src/tplr/__init__.py`\n2. Runs the application\n3. Restores the original version\n\nSources: [justfile:13-20]()\n\n## Common Issues and Troubleshooting\n\n### Zombie Processes\n\nThe project includes a command to check for zombie Bistro processes:\n\n```bash\njust bistro\n```\n\nThis runs `ps aux | grep Bistro` to identify any lingering processes.\n\nSources: [justfile:28-29](), [scripts/start.sh:5-6]()\n\n### Environment File Issues\n\nIf you encounter configuration errors, check that your `.env.yaml` and `.env` files are properly set up. These files are not included in version control and must be created manually.\n\nSources: [.gitignore:1-2]()",
    "resolved_links": [
      {
        "text": ".gitignore",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/.gitignore",
        "original_deepwiki_href": ".gitignore",
        "context": "collapsible_aside_link"
      },
      {
        "text": "justfile",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/justfile",
        "original_deepwiki_href": "justfile",
        "context": "collapsible_aside_link"
      },
      {
        "text": "scripts/start.sh",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/scripts/start.sh",
        "original_deepwiki_href": "scripts/start.sh",
        "context": "collapsible_aside_link"
      },
      {
        "text": "justfile:22-23",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".gitignore:1-2",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:5-33",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".gitignore:29-34",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/start.sh:1-16",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".gitignore:1-84",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:5-11",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:25-32",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:13-20",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "justfile:28-29",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "scripts/start.sh:5-6",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Testing",
        "href": "/development-guide/testing#10.2",
        "original_deepwiki_href": "#10.2",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Deployment",
        "href": "/deployment#8",
        "original_deepwiki_href": "#8",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Development Environment\"\n        UV[\"UV Package Manager\"]\n        Just[\"Just Command Runner\"]\n        Ruff[\"Ruff Linter & Formatter\"]\n        PyTest[\"PyTest Testing Framework\"]\n        PM2[\"PM2 Process Manager\"]\n    end\n\n    Just -->|\"just dev\"| UV\n    Just -->|\"just lint\"| Ruff\n    Just -->|\"just test\"| PyTest\n    Just -->|\"just test-run\"| TestRun[\"Test Run Script\"]\n    Just -->|\"just cov\"| Coverage[\"Code Coverage\"]\n    PM2 --- Start[\"scripts/start.sh\"]\n    \n    TestRun --> PM2\n    \n    class UV,Just,Ruff,PyTest,PM2 interface;",
      "flowchart LR\n    subgraph \"Process Management\"\n        Start[\"start.sh\"]\n        PM2[\"PM2\"]\n        Config[\"ecosystem.config.js\"]\n        Processes[\"Templar Processes\"]\n    end\n\n    Start -->|\"pm2 delete all\"| PM2\n    Start -->|\"Check zombie processes\"| ZombieCheck[\"ps aux | grep Bistro\"]\n    Start -->|\"pm2 start\"| Config\n    Config --> PM2\n    PM2 --> Processes\n    Start -->|\"pm2 log TM1\"| Logs[\"Process Logs\"]",
      "graph TD\n    subgraph \"Repository Structure\"\n        Root[\"templar/\"]\n        Src[\"src/\"]\n        Scripts[\"scripts/\"]\n        Tests[\"tests/\"]\n        Neurons[\"neurons/\"]\n        Data[\"data/\"]\n        Models[\"models/\"]\n    end\n\n    Root --> Src\n    Root --> Scripts\n    Root --> Tests\n    Root --> Neurons\n    Root --> Data\n    Root --> Models\n\n    Src --> TPLR[\"tplr/\"]\n    Scripts --> StartSh[\"start.sh\"]\n    Scripts --> OtherScripts[\"Other utility scripts\"]",
      "sequenceDiagram\n    participant Developer\n    participant Git as \"Git Repository\"\n    participant Local as \"Local Environment\"\n    participant PM2 as \"PM2 Process Manager\"\n    \n    Developer->>Git: Clone repository\n    Developer->>Local: just dev (Install dependencies)\n    Developer->>Local: Make code changes\n    Developer->>Local: just lint (Run code formatting)\n    Developer->>Local: just test (Run tests)\n    Developer->>PM2: just test-run (Test with PM2)\n    Developer->>Git: Commit and push changes"
    ],
    "potential_frontmatter": {
      "title": "Development Environment"
    }
  },
  "/tplr-ai/templar/10.2-testing": {
    "original_deepwiki_href": "/tplr-ai/templar/10.2-testing",
    "title": "Testing",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/10.2-testing",
    "level": 1,
    "target_astro_path": "/development-guide/testing",
    "main_markdown_content": "# Testing\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [tests/conftest.py](tests/conftest.py)\n- [tests/test_checkpoints.py](tests/test_checkpoints.py)\n- [tests/test_evaluator.py](tests/test_evaluator.py)\n- [tests/test_metrics_logger.py](tests/test_metrics_logger.py)\n- [tests/test_prepare_gradient_dict.py](tests/test_prepare_gradient_dict.py)\n\n</details>\n\n\n\nThis page documents the testing infrastructure and practices for the Templar codebase. It covers the test organization, key test fixtures, testing of core components, and guidelines for running tests and creating new tests. For information about the CI/CD pipeline, see [CI/CD Pipeline](#10.3).\n\n## Test Organization\n\nThe Templar project uses pytest as its primary testing framework. Tests are organized in the `tests/` directory, with individual test files corresponding to specific components of the system.\n\n```mermaid\nflowchart TD\n    subgraph \"Test Structure\"\n        TS[\"/tests directory\"]\n        CF[\"conftest.py\"]\n        MET[\"test_metrics_logger.py\"]\n        EVAL[\"test_evaluator.py\"]\n        CKPT[\"test_checkpoints.py\"]\n        GRAD[\"test_prepare_gradient_dict.py\"]\n    end\n\n    subgraph \"System Components\"\n        ML[\"Metrics Logger\"]\n        EV[\"Evaluator\"]\n        CP[\"Checkpoint Management\"]\n        GP[\"Gradient Processing\"]\n    end\n\n    CF --> MET\n    CF --> EVAL\n    CF --> CKPT\n    CF --> GRAD\n    \n    MET --> ML\n    EVAL --> EV\n    CKPT --> CP\n    GRAD --> GP\n```\n\nSources: [tests/conftest.py](), [tests/test_metrics_logger.py](), [tests/test_evaluator.py](), [tests/test_checkpoints.py](), [tests/test_prepare_gradient_dict.py]()\n\n## Test Fixtures\n\nTest fixtures provide a consistent environment for tests to run in. The `conftest.py` file defines fixtures that are available across all test files, including mock models, metadata, communications interfaces, and system configurations.\n\n```mermaid\nflowchart LR\n    subgraph \"Core Fixtures\"\n        M[\"model()\"]\n        TK[\"totalks()\"]\n        CI[\"comms_instance()\"]\n        EL[\"enable_tplr_logger_propagation()\"]\n    end\n\n    subgraph \"Mocks for Integration Testing\"\n        MM[\"mock_metagraph()\"]\n        MV[\"mock_validator()\"]\n        MNN[\"num_non_zero_incentive()\"]\n        NAM[\"num_active_miners()\"]\n    end\n\n    subgraph \"Helper Classes\"\n        DW[\"DummyWallet\"]\n        DC[\"DummyConfig\"]\n        DH[\"DummyHParams\"]\n        DM[\"DummyMetagraph\"]\n    end\n\n    M --- CI\n    TK --- CI\n    MM --> MV\n    MNN --> MM\n    NAM --> MV\n    DW --> CI\n    DC --> CI\n    DH --> CI\n    DM --> CI\n```\n\nSources: [tests/conftest.py:60-197]()\n\n## Testing Core Components\n\n### Metrics Logging\n\nThe tests for the metrics logging system verify that metrics can be properly collected, formatted, and sent to the metrics storage backend (InfluxDB). The tests use mocking to isolate the metrics logger from the actual InfluxDB service.\n\n```mermaid\nflowchart TD\n    subgraph \"MetricsLogger Tests\"\n        TI[\"test_init()\"]\n        TPV[\"test_process_value()\"]\n        TLB[\"test_log_basic()\"]\n        TLSM[\"test_log_with_system_metrics()\"]\n        TLGM[\"test_log_with_gpu_metrics()\"]\n        TLWL[\"test_log_with_list_fields()\"]\n        TLCT[\"test_log_with_config_tags()\"]\n        TLE[\"test_log_with_exception()\"]\n        TLOC[\"test_log_call_invokes_write_once()\"]\n    end\n\n    subgraph \"Fixtures\"\n        MI[\"mock_influxdb_client()\"]\n        ML[\"metrics_logger()\"]\n        MCF[\"mock_cuda_functions()\"]\n        MSM[\"mock_system_metrics()\"]\n        BTC[\"bt_config()\"]\n    end\n\n    MI --> ML\n    ML --> TI\n    ML --> TPV\n    ML --> TLB\n    ML --> TLSM\n    ML --> TLGM\n    ML --> TLWL\n    ML --> TLCT\n    ML --> TLE\n    ML --> TLOC\n    MCF --> TLGM\n    MSM --> TLSM\n    BTC --> TLCT\n```\n\nSources: [tests/test_metrics_logger.py:58-341]()\n\n### Evaluator Testing\n\nThe evaluator tests verify that the evaluator component can properly detect, load, and evaluate new model checkpoints, handling versioning and tracking state correctly.\n\n| Test Case | Purpose |\n|-----------|---------|\n| `test_evaluator_skips_old_checkpoints` | Verifies the evaluator doesn't reload already evaluated checkpoints |\n| `test_evaluator_loads_new_checkpoints` | Confirms the evaluator correctly loads and processes new checkpoints |\n\nSources: [tests/test_evaluator.py:21-143]()\n\n### Checkpoint Management Testing\n\nThe checkpoint tests verify the creation, storage, and loading of model checkpoints, which are critical for distributed training continuity and recovery.\n\n```mermaid\nflowchart TD\n    subgraph \"Checkpoint Tests\"\n        TCDS[\"test_checkpoint_data_structure()\"]\n        TMK[\"test_missing_key_in_checkpoint()\"]\n        TCF[\"test_corrupted_checkpoint_file()\"]\n        TCL[\"test_catch_up_logic()\"]\n        TNC[\"test_no_catch_up_when_aligned()\"]\n        TMC[\"test_miner_checkpoint_cycle()\"]\n        TSO[\"test_scheduler_optimizer_sync_after_catch_up()\"]\n        TAG[\"test_async_gather_failures()\"]\n        TCSF[\"test_checkpoint_save_trigger_frequency()\"]\n        TLFC[\"test_local_file_creation_after_checkpoint_save()\"]\n        TCPUV[\"test_cpu_device_verification_for_checkpoint_saved_tensors()\"]\n        TCSLC[\"test_checkpoint_save_and_load_cycle()\"]\n    end\n\n    subgraph \"Test Components\"\n        DC[\"DummyComponents\"]\n        CCD[\"create_checkpoint_data()\"]\n        DCOM[\"DummyComms\"]\n    end\n\n    DC --> TCDS\n    DC --> TMK\n    DC --> TCL\n    DC --> TNC\n    DC --> TMC\n    DC --> TSO\n    DC --> TAG\n    DC --> TCSF\n    DC --> TLFC\n    DC --> TCPUV\n    DC --> TCSLC\n    \n    CCD --> TCDS\n    CCD --> TMK\n    CCD --> TCL\n    CCD --> TNC\n    \n    DCOM --> TMK\n    DCOM --> TCF\n    DCOM --> TCL\n    DCOM --> TNC\n    DCOM --> TMC\n    DCOM --> TSO\n    DCOM --> TAG\n    DCOM --> TCSF\n    DCOM --> TLFC\n    DCOM --> TCPUV\n    DCOM --> TCSLC\n```\n\nSources: [tests/test_checkpoints.py:236-774]()\n\n### Gradient Processing Testing\n\nTests for the `prepare_gradient_dict` function verify proper gradient processing, compression, momentum calculation, and metadata attachment.\n\n| Test Case | Purpose |\n|-----------|---------|\n| `test_return_structure_and_types` | Verifies the function returns the expected structure |\n| `test_metadata_attachment` | Confirms metadata is properly attached to gradients |\n| `test_weight_decay_application` | Tests weight decay is correctly applied |\n| `test_momentum_decay_and_gradient_accumulation` | Verifies momentum calculation |\n| `test_compressor_and_transformer_calls` | Tests compression and transformation operations |\n| `test_handling_multiple_parameters` | Verifies handling of multiple model parameters |\n| `test_behavior_when_p_grad_is_none` | Tests error handling for missing gradients |\n| `test_logging_behavior` | Verifies proper logging |\n| `test_correct_use_of_scheduler_learning_rate` | Tests learning rate is properly used |\n| `test_propagation_of_compressor_failure` | Tests exception handling from compressor |\n| `test_propagation_of_transformer_failure` | Tests exception handling from transformer |\n\nSources: [tests/test_prepare_gradient_dict.py:80-516]()\n\n## Test Fixtures and Mock Objects\n\nTemplar tests use a variety of fixtures and mock objects to create isolated test environments. These include:\n\n### Core Fixtures\n\n1. **Model Fixture**\n   ```python\n   @pytest.fixture\n   def model():\n       # Create a simple dummy model for testing.\n       return torch.nn.Sequential(torch.nn.Linear(10, 10))\n   ```\n\n2. **Communications Fixture**\n   ```python\n   @pytest.fixture\n   async def comms_instance():\n       # Initialize communications with mock dependencies\n       comms = comms_module.Comms(...)\n       # Add transformer and compressor\n       return comms\n   ```\n\n3. **Metagraph and Validator Fixtures**\n   ```python\n   @pytest.fixture\n   def mock_metagraph(mocker, num_non_zero_incentive, num_miners=250):\n       # Create a mock metagraph with specified miners and incentive distribution\n       metagraph = mocker.Mock()\n       # Configure properties\n       return metagraph\n   \n   @pytest.fixture\n   def mock_validator(mocker, mock_metagraph, num_active_miners):\n       # Initialize mock validator\n       validator = object.__new__(Validator)\n       # Set up necessary attributes\n       return validator\n   ```\n\nSources: [tests/conftest.py:60-198]()\n\n## Running Tests\n\nTests can be run using pytest. The Templar project has both synchronous and asynchronous tests, with the latter being marked with the `@pytest.mark.asyncio` decorator.\n\n### Basic Test Execution\n\n```bash\n# Run all tests\npytest\n\n# Run tests in a specific file\npytest tests/test_metrics_logger.py\n\n# Run a specific test function\npytest tests/test_metrics_logger.py::TestMetricsLogger::test_init\n```\n\n### Handling Asynchronous Tests\n\nAsynchronous tests are configured via the `pytest_configure` function in `conftest.py`:\n\n```python\ndef pytest_configure(config):\n    config.addinivalue_line(\"markers\", \"asyncio: mark test as requiring async\")\n```\n\nWhen writing asynchronous tests, use the `@pytest.mark.asyncio` decorator and `async def` function definition:\n\n```python\n@pytest.mark.asyncio\nasync def test_async_function():\n    # Test code here\n    pass\n```\n\nSources: [tests/conftest.py:1-6](), [tests/test_evaluator.py:59-143](), [tests/test_checkpoints.py:279-593]()\n\n## Testing Patterns\n\n### Fixture-Based Testing\n\nTemplar tests use pytest fixtures extensively to set up test dependencies:\n\n```python\n@pytest.fixture\ndef metrics_logger(self, mock_influxdb_client):\n    # Create a MetricsLogger instance for testing\n    logger = MetricsLogger(...)\n    return logger\n```\n\n### Mock Implementation Patterns\n\nMocks are used to isolate components under test:\n\n```python\n@pytest.fixture\ndef mock_influxdb_client(self):\n    # Patch InfluxDBClient, configure mocks, and return the mock class\n    with patch(\"tplr.metrics.InfluxDBClient\", autospec=True) as mock_client_class:\n        # Configure mock\n        yield mock_client_class\n```\n\n### Waiting For Asynchronous Operations\n\nFor asynchronous operations, the codebase includes helper functions like `wait_for_mock_call`:\n\n```python\ndef wait_for_mock_call(mock_object: Mock, timeout: float = 3.0):\n    \"\"\"Waits for a mock object to be called at least once.\"\"\"\n    start_time = time.monotonic()\n    while time.monotonic() < start_time + timeout:\n        if mock_object.call_count > 0:\n            return True\n        time.sleep(0.05)\n    return False\n```\n\nSources: [tests/test_metrics_logger.py:40-55](), [tests/test_metrics_logger.py:84-114](), [tests/test_metrics_logger.py:60-82]()\n\n## Adding New Tests\n\nWhen adding new tests to the Templar project, follow these guidelines:\n\n1. **Test Organization**: Place tests in the appropriate file based on the component being tested\n2. **Fixtures**: Use existing fixtures from `conftest.py` when possible, or add new ones if needed\n3. **Mocking**: Use mocks to isolate the component under test from external dependencies\n4. **Async Testing**: Use the `@pytest.mark.asyncio` decorator for asynchronous tests\n5. **Test Coverage**: Aim to test both normal operation and error conditions\n\n## Test Architecture and Component Relationship\n\nThe test architecture mirrors the Templar system architecture, with tests for each major component and their interactions.\n\n```mermaid\nflowchart TD\n    subgraph \"Test Framework\"\n        PF[\"pytest Framework\"]\n        FST[\"Fixtures (conftest.py)\"]\n        TMO[\"Test Mocks\"]\n        UHF[\"Utility Helper Functions\"]\n    end\n\n    subgraph \"Component Tests\"\n        MTL[\"MetricsLogger Tests\"]\n        EVT[\"Evaluator Tests\"]\n        CKT[\"Checkpoint Tests\"]\n        GPT[\"Gradient Processing Tests\"]\n    end\n\n    subgraph \"System Components\"\n        ML[\"tplr.metrics.MetricsLogger\"]\n        EV[\"scripts.evaluator.Evaluator\"]\n        CP[\"tplr.comms (Checkpoint Functions)\"]\n        GP[\"tplr.neurons.prepare_gradient_dict\"]\n    end\n\n    PF --> FST\n    PF --> TMO\n    PF --> UHF\n    \n    FST --> MTL\n    FST --> EVT\n    FST --> CKT\n    FST --> GPT\n    \n    TMO --> MTL\n    TMO --> EVT\n    TMO --> CKT\n    TMO --> GPT\n    \n    UHF --> MTL\n    UHF --> EVT\n    UHF --> CKT\n    \n    MTL --> ML\n    EVT --> EV\n    CKT --> CP\n    GPT --> GP\n```\n\nSources: [tests/conftest.py](), [tests/test_metrics_logger.py](), [tests/test_evaluator.py](), [tests/test_checkpoints.py](), [tests/test_prepare_gradient_dict.py]()",
    "resolved_links": [
      {
        "text": "tests/conftest.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/conftest.py",
        "original_deepwiki_href": "tests/conftest.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_checkpoints.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_checkpoints.py",
        "original_deepwiki_href": "tests/test_checkpoints.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_evaluator.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_evaluator.py",
        "original_deepwiki_href": "tests/test_evaluator.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_metrics_logger.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_metrics_logger.py",
        "original_deepwiki_href": "tests/test_metrics_logger.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/test_prepare_gradient_dict.py",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/tests/test_prepare_gradient_dict.py",
        "original_deepwiki_href": "tests/test_prepare_gradient_dict.py",
        "context": "collapsible_aside_link"
      },
      {
        "text": "tests/conftest.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_metrics_logger.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_evaluator.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_checkpoints.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_prepare_gradient_dict.py",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/conftest.py:60-197",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_metrics_logger.py:58-341",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_evaluator.py:21-143",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_checkpoints.py:236-774",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_prepare_gradient_dict.py:80-516",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/conftest.py:60-198",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/conftest.py:1-6",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_evaluator.py:59-143",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_checkpoints.py:279-593",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_metrics_logger.py:40-55",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_metrics_logger.py:84-114",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "tests/test_metrics_logger.py:60-82",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "CI/CD Pipeline",
        "href": "/development-guide/cicd-pipeline#10.3",
        "original_deepwiki_href": "#10.3",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Test Structure\"\n        TS[\"/tests directory\"]\n        CF[\"conftest.py\"]\n        MET[\"test_metrics_logger.py\"]\n        EVAL[\"test_evaluator.py\"]\n        CKPT[\"test_checkpoints.py\"]\n        GRAD[\"test_prepare_gradient_dict.py\"]\n    end\n\n    subgraph \"System Components\"\n        ML[\"Metrics Logger\"]\n        EV[\"Evaluator\"]\n        CP[\"Checkpoint Management\"]\n        GP[\"Gradient Processing\"]\n    end\n\n    CF --> MET\n    CF --> EVAL\n    CF --> CKPT\n    CF --> GRAD\n    \n    MET --> ML\n    EVAL --> EV\n    CKPT --> CP\n    GRAD --> GP",
      "flowchart LR\n    subgraph \"Core Fixtures\"\n        M[\"model()\"]\n        TK[\"totalks()\"]\n        CI[\"comms_instance()\"]\n        EL[\"enable_tplr_logger_propagation()\"]\n    end\n\n    subgraph \"Mocks for Integration Testing\"\n        MM[\"mock_metagraph()\"]\n        MV[\"mock_validator()\"]\n        MNN[\"num_non_zero_incentive()\"]\n        NAM[\"num_active_miners()\"]\n    end\n\n    subgraph \"Helper Classes\"\n        DW[\"DummyWallet\"]\n        DC[\"DummyConfig\"]\n        DH[\"DummyHParams\"]\n        DM[\"DummyMetagraph\"]\n    end\n\n    M --- CI\n    TK --- CI\n    MM --> MV\n    MNN --> MM\n    NAM --> MV\n    DW --> CI\n    DC --> CI\n    DH --> CI\n    DM --> CI",
      "flowchart TD\n    subgraph \"MetricsLogger Tests\"\n        TI[\"test_init()\"]\n        TPV[\"test_process_value()\"]\n        TLB[\"test_log_basic()\"]\n        TLSM[\"test_log_with_system_metrics()\"]\n        TLGM[\"test_log_with_gpu_metrics()\"]\n        TLWL[\"test_log_with_list_fields()\"]\n        TLCT[\"test_log_with_config_tags()\"]\n        TLE[\"test_log_with_exception()\"]\n        TLOC[\"test_log_call_invokes_write_once()\"]\n    end\n\n    subgraph \"Fixtures\"\n        MI[\"mock_influxdb_client()\"]\n        ML[\"metrics_logger()\"]\n        MCF[\"mock_cuda_functions()\"]\n        MSM[\"mock_system_metrics()\"]\n        BTC[\"bt_config()\"]\n    end\n\n    MI --> ML\n    ML --> TI\n    ML --> TPV\n    ML --> TLB\n    ML --> TLSM\n    ML --> TLGM\n    ML --> TLWL\n    ML --> TLCT\n    ML --> TLE\n    ML --> TLOC\n    MCF --> TLGM\n    MSM --> TLSM\n    BTC --> TLCT",
      "flowchart TD\n    subgraph \"Checkpoint Tests\"\n        TCDS[\"test_checkpoint_data_structure()\"]\n        TMK[\"test_missing_key_in_checkpoint()\"]\n        TCF[\"test_corrupted_checkpoint_file()\"]\n        TCL[\"test_catch_up_logic()\"]\n        TNC[\"test_no_catch_up_when_aligned()\"]\n        TMC[\"test_miner_checkpoint_cycle()\"]\n        TSO[\"test_scheduler_optimizer_sync_after_catch_up()\"]\n        TAG[\"test_async_gather_failures()\"]\n        TCSF[\"test_checkpoint_save_trigger_frequency()\"]\n        TLFC[\"test_local_file_creation_after_checkpoint_save()\"]\n        TCPUV[\"test_cpu_device_verification_for_checkpoint_saved_tensors()\"]\n        TCSLC[\"test_checkpoint_save_and_load_cycle()\"]\n    end\n\n    subgraph \"Test Components\"\n        DC[\"DummyComponents\"]\n        CCD[\"create_checkpoint_data()\"]\n        DCOM[\"DummyComms\"]\n    end\n\n    DC --> TCDS\n    DC --> TMK\n    DC --> TCL\n    DC --> TNC\n    DC --> TMC\n    DC --> TSO\n    DC --> TAG\n    DC --> TCSF\n    DC --> TLFC\n    DC --> TCPUV\n    DC --> TCSLC\n    \n    CCD --> TCDS\n    CCD --> TMK\n    CCD --> TCL\n    CCD --> TNC\n    \n    DCOM --> TMK\n    DCOM --> TCF\n    DCOM --> TCL\n    DCOM --> TNC\n    DCOM --> TMC\n    DCOM --> TSO\n    DCOM --> TAG\n    DCOM --> TCSF\n    DCOM --> TLFC\n    DCOM --> TCPUV\n    DCOM --> TCSLC",
      "flowchart TD\n    subgraph \"Test Framework\"\n        PF[\"pytest Framework\"]\n        FST[\"Fixtures (conftest.py)\"]\n        TMO[\"Test Mocks\"]\n        UHF[\"Utility Helper Functions\"]\n    end\n\n    subgraph \"Component Tests\"\n        MTL[\"MetricsLogger Tests\"]\n        EVT[\"Evaluator Tests\"]\n        CKT[\"Checkpoint Tests\"]\n        GPT[\"Gradient Processing Tests\"]\n    end\n\n    subgraph \"System Components\"\n        ML[\"tplr.metrics.MetricsLogger\"]\n        EV[\"scripts.evaluator.Evaluator\"]\n        CP[\"tplr.comms (Checkpoint Functions)\"]\n        GP[\"tplr.neurons.prepare_gradient_dict\"]\n    end\n\n    PF --> FST\n    PF --> TMO\n    PF --> UHF\n    \n    FST --> MTL\n    FST --> EVT\n    FST --> CKT\n    FST --> GPT\n    \n    TMO --> MTL\n    TMO --> EVT\n    TMO --> CKT\n    TMO --> GPT\n    \n    UHF --> MTL\n    UHF --> EVT\n    UHF --> CKT\n    \n    MTL --> ML\n    EVT --> EV\n    CKT --> CP\n    GPT --> GP"
    ],
    "potential_frontmatter": {
      "title": "Testing"
    }
  },
  "/tplr-ai/templar/10.3-cicd-pipeline": {
    "original_deepwiki_href": "/tplr-ai/templar/10.3-cicd-pipeline",
    "title": "CI/CD Pipeline",
    "full_deepwiki_url": "https://deepwiki.com/tplr-ai/templar/10.3-cicd-pipeline",
    "level": 1,
    "target_astro_path": "/development-guide/cicd-pipeline",
    "main_markdown_content": "# CI/CD Pipeline\n\n<details>\n<summary>Relevant source files</summary>\n\nThe following files were used as context for generating this wiki page:\n\n- [.github/workflows/ci.yml](.github/workflows/ci.yml)\n- [codecov.yml](codecov.yml)\n\n</details>\n\n\n\nThis document details the Continuous Integration and Continuous Deployment (CI/CD) pipeline implemented for the Templar project. It focuses on the automated workflows that run when code changes are pushed, ensuring code quality, test coverage, and consistent formatting. For information about the development environment setup, see [Development Environment](#10.1), and for testing strategies, see [Testing](#10.2).\n\n## Pipeline Overview\n\nThe Templar project uses GitHub Actions as its primary CI/CD platform. The pipeline automates code quality checks, testing, and coverage reporting to maintain high standards of code quality while enabling rapid development.\n\n```mermaid\nflowchart TD\n    subgraph \"Trigger Events\"\n        PR[\"Pull Request\"]\n        Push[\"Push to main branch\"]\n    end\n\n    subgraph \"CI Pipeline\"\n        Block[\"Block Fixup Job\"]\n        Lint[\"Lint and Format Job\"]\n        Test[\"Test Job\"]\n    end\n\n    subgraph \"Reporting\"\n        Coverage[\"Codecov Coverage Report\"]\n    end\n\n    PR --> Block\n    PR --> Lint\n    PR --> Test\n    Push --> Lint\n    Push --> Test\n    Test --> Coverage\n```\n\nSources: [.github/workflows/ci.yml:3-8]()\n\n## Workflow Configuration\n\nThe CI/CD pipeline is configured in the GitHub Actions workflow file, which defines the jobs, their dependencies, and execution environments.\n\n```mermaid\nflowchart TB\n    subgraph \"CI Workflow\"\n        direction TB\n        subgraph \"Jobs\"\n            direction LR\n            block[\"block-fixup\"]\n            lint[\"lint-and-format\"]\n            test[\"test\"]\n        end\n        \n        subgraph \"Environment\"\n            ubuntu[\"Ubuntu Latest\"]\n            py311[\"Python 3.11\"]\n            py312[\"Python 3.12\"]\n        end\n        \n        subgraph \"Tools\"\n            uv[\"uv package manager\"]\n            ruff[\"Ruff (lint/format)\"]\n            pytest[\"Pytest with coverage\"]\n            codecov[\"Codecov uploader\"]\n        end\n    end\n    \n    block --> ubuntu\n    lint --> ubuntu\n    lint --> py311\n    lint --> py312\n    test --> ubuntu\n    test --> py311\n    test --> py312\n    \n    ubuntu --> uv\n    uv --> ruff\n    uv --> pytest\n    pytest --> codecov\n```\n\nSources: [.github/workflows/ci.yml:9-122]()\n\n## Jobs in the Pipeline\n\nThe pipeline consists of three main jobs, each serving a specific purpose in maintaining code quality.\n\n### Block Fixup Job\n\nThis job prevents pull requests containing fixup commits from being merged, ensuring a clean git history.\n\n```mermaid\nflowchart TD\n    PR[\"Pull Request\"] --> Check{{\"Is PR?\"}}\n    Check -->|Yes| Checkout[\"Checkout Repository\"]\n    Check -->|No| Skip[\"Skip Job\"]\n    Checkout --> BlockFixup[\"Block Fixup Commit Merge\"]\n    BlockFixup -->|Fixup Found| Fail[\"Fail CI\"]\n    BlockFixup -->|No Fixups| Pass[\"Pass\"]\n```\n\nSources: [.github/workflows/ci.yml:10-17]()\n\n### Lint and Format Job\n\nThis job checks that code follows the project's styling and linting rules, running on both Python 3.11 and 3.12.\n\n```mermaid\nflowchart TD\n    Start[\"Lint and Format Job\"] --> Checkout[\"Checkout Repository\"]\n    Checkout --> SetupUV[\"Setup uv package manager\"]\n    SetupUV --> InstallDeps[\"Install dependencies\"]\n    InstallDeps --> RuffLint[\"Run Ruff Lint\"]\n    RuffLint --> RuffFormat[\"Run Ruff Format Check\"]\n    RuffLint -->|Errors| Fail[\"Fail CI\"]\n    RuffFormat -->|Errors| Fail\n    RuffFormat -->|No Errors| Pass[\"Pass\"]\n```\n\nSources: [.github/workflows/ci.yml:19-44]()\n\n### Test Job\n\nThis job runs the test suite with coverage reporting, ensuring that code changes don't break existing functionality and maintain adequate test coverage.\n\n```mermaid\nflowchart TD\n    Start[\"Test Job\"] --> Checkout[\"Checkout Repository\"]\n    Checkout --> CreateEnv[\"Create .env file from secrets\"]\n    CreateEnv --> SetupUV[\"Setup uv package manager\"]\n    SetupUV --> InstallDeps[\"Install dependencies\"]\n    InstallDeps --> RunTests[\"Run Tests with Coverage\"]\n    RunTests --> UploadCodecov[\"Upload to Codecov\"]\n    RunTests -->|Tests Fail| FailCI[\"Fail CI\"]\n    UploadCodecov -->|Upload Fails| FailCI\n    UploadCodecov -->|Success| Pass[\"Pass\"]\n```\n\nSources: [.github/workflows/ci.yml:46-122]()\n\n## Environment Configuration\n\nThe test job requires specific environment variables to properly run tests that interact with storage services. These variables are securely stored as GitHub Secrets and injected into the workflow runtime.\n\n### Secret Variables\n\nThe pipeline uses several R2 storage-related secrets for running tests that interact with Cloudflare R2 storage:\n\n| Secret Category | Variables |\n|----------------|-----------|\n| Gradients Bucket | Account ID, Bucket Name, Read/Write Access Keys |\n| Dataset Bucket | Account ID, Bucket Name, Read/Write Access Keys, Bucket List |\n| Aggregator Bucket | Account ID, Bucket Name, Read Access Keys |\n\nSources: [.github/workflows/ci.yml:53-70](), [.github/workflows/ci.yml:78-100]()\n\n## Code Coverage Configuration\n\nThe project enforces code coverage requirements through Codecov integration, with specific targets defined in the configuration file.\n\n```mermaid\nflowchart TD\n    Test[\"Run Tests with Coverage\"] --> GenerateXML[\"Generate XML Coverage Report\"]\n    GenerateXML --> UploadCodecov[\"Upload to Codecov\"]\n    UploadCodecov --> CheckTarget{\"Meet 85% Target?\"}\n    CheckTarget -->|Yes| Pass[\"Pass CI\"]\n    CheckTarget -->|No, but within 1% threshold| Pass\n    CheckTarget -->|No, exceeds threshold| Fail[\"Fail CI\"]\n```\n\nCoverage requirements:\n- Project target: 85% code coverage\n- Patch target: 85% code coverage for changes\n- Threshold: 1% tolerance for coverage changes\n\nSources: [codecov.yml:1-10](), [.github/workflows/ci.yml:112-121]()\n\n## Pipeline Integration with Development Workflow\n\nThe CI/CD pipeline is integrated into the development workflow to ensure code quality at different stages.\n\n```mermaid\nflowchart LR\n    subgraph \"Developer Workflow\"\n        Fork[\"Fork Repository\"] --> Branch[\"Create Branch\"]\n        Branch --> Code[\"Make Changes\"]\n        Code --> Test[\"Run Local Tests\"]\n        Test --> Commit[\"Commit Changes\"]\n        Commit --> PR[\"Create Pull Request\"]\n        PR --> Review[\"Code Review\"]\n        Review --> Merge[\"Merge to main\"]\n    end\n    \n    subgraph \"CI Pipeline Checks\"\n        BlockFixup[\"Block Fixup Commits\"]\n        LintFormat[\"Lint and Format Check\"]\n        TestCov[\"Test with Coverage\"]\n    end\n    \n    PR --> BlockFixup\n    PR --> LintFormat\n    PR --> TestCov\n    \n    BlockFixup -->|Pass| Review\n    LintFormat -->|Pass| Review\n    TestCov -->|Pass| Review\n    \n    BlockFixup -->|Fail| Code\n    LintFormat -->|Fail| Code\n    TestCov -->|Fail| Code\n```\n\nSources: [.github/workflows/ci.yml:3-8]()\n\n## Package Management with UV\n\nThe CI pipeline uses the UV package manager for Python dependency management, which provides faster and more reliable dependency resolution than pip.\n\n| Feature | Implementation |\n|---------|---------------|\n| Cache Support | Enabled for faster CI runs |\n| Dependency Installation | `uv sync --all-extras --dev` |\n| Python Versions | 3.11 and 3.12 matrix testing |\n\nSources: [.github/workflows/ci.yml:30-35](), [.github/workflows/ci.yml:102-110]()\n\n## Codecov Reporting Configuration\n\nCodecov is configured to provide detailed feedback on code coverage through PR comments.\n\n```mermaid\nflowchart TD\n    Test[\"Run Tests\"] --> GenerateCovXML[\"Generate Coverage XML\"]\n    GenerateCovXML --> UploadCodecov[\"Upload to Codecov\"]\n    UploadCodecov --> PRComment[\"Generate PR Comment\"]\n    \n    subgraph \"Comment Contents\"\n        Reach[\"Coverage Reach Stats\"]\n        Diff[\"Coverage Diff\"]\n        Flags[\"Coverage Flags\"]\n        Files[\"Affected Files\"]\n    end\n    \n    PRComment --> Reach\n    PRComment --> Diff\n    PRComment --> Flags\n    PRComment --> Files\n```\n\nSources: [codecov.yml:12-15](), [.github/workflows/ci.yml:116-121]()\n\n## Summary of CI/CD Components\n\nThe Templar CI/CD pipeline combines several key technologies to ensure code quality:\n\n| Component | Tool | Purpose |\n|-----------|------|---------|\n| Workflow Engine | GitHub Actions | Orchestrates the CI/CD process |\n| Package Management | UV | Fast, reliable dependency installation |\n| Code Quality | Ruff | Linting and formatting |\n| Testing | pytest | Running test suite |\n| Coverage | pytest-cov | Generating coverage reports |\n| Coverage Reporting | Codecov | Tracking and enforcing coverage targets |\n| Commit Quality | block-fixup-merge-action | Ensuring clean git history |\n\nSources: [.github/workflows/ci.yml:1-122](), [codecov.yml:1-15]()",
    "resolved_links": [
      {
        "text": ".github/workflows/ci.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/.github/workflows/ci.yml",
        "original_deepwiki_href": ".github/workflows/ci.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": "codecov.yml",
        "href": "https://github.com/tplr-ai/templar/blob/bb2fc2a9/codecov.yml",
        "original_deepwiki_href": "codecov.yml",
        "context": "collapsible_aside_link"
      },
      {
        "text": ".github/workflows/ci.yml:3-8",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:9-122",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:10-17",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:19-44",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:46-122",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:53-70",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:78-100",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "codecov.yml:1-10",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:112-121",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:30-35",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:102-110",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "codecov.yml:12-15",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:116-121",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": ".github/workflows/ci.yml:1-122",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "codecov.yml:1-15",
        "href": "",
        "original_deepwiki_href": "",
        "context": "inline_source_link"
      },
      {
        "text": "Development Environment",
        "href": "/development-guide/development-environment#10.1",
        "original_deepwiki_href": "#10.1",
        "context": "internal_page_link_from_content_body"
      },
      {
        "text": "Testing",
        "href": "/development-guide/testing#10.2",
        "original_deepwiki_href": "#10.2",
        "context": "internal_page_link_from_content_body"
      }
    ],
    "mermaid_diagrams": [
      "flowchart TD\n    subgraph \"Trigger Events\"\n        PR[\"Pull Request\"]\n        Push[\"Push to main branch\"]\n    end\n\n    subgraph \"CI Pipeline\"\n        Block[\"Block Fixup Job\"]\n        Lint[\"Lint and Format Job\"]\n        Test[\"Test Job\"]\n    end\n\n    subgraph \"Reporting\"\n        Coverage[\"Codecov Coverage Report\"]\n    end\n\n    PR --> Block\n    PR --> Lint\n    PR --> Test\n    Push --> Lint\n    Push --> Test\n    Test --> Coverage",
      "flowchart TB\n    subgraph \"CI Workflow\"\n        direction TB\n        subgraph \"Jobs\"\n            direction LR\n            block[\"block-fixup\"]\n            lint[\"lint-and-format\"]\n            test[\"test\"]\n        end\n        \n        subgraph \"Environment\"\n            ubuntu[\"Ubuntu Latest\"]\n            py311[\"Python 3.11\"]\n            py312[\"Python 3.12\"]\n        end\n        \n        subgraph \"Tools\"\n            uv[\"uv package manager\"]\n            ruff[\"Ruff (lint/format)\"]\n            pytest[\"Pytest with coverage\"]\n            codecov[\"Codecov uploader\"]\n        end\n    end\n    \n    block --> ubuntu\n    lint --> ubuntu\n    lint --> py311\n    lint --> py312\n    test --> ubuntu\n    test --> py311\n    test --> py312\n    \n    ubuntu --> uv\n    uv --> ruff\n    uv --> pytest\n    pytest --> codecov",
      "flowchart TD\n    PR[\"Pull Request\"] --> Check{{\"Is PR?\"}}\n    Check -->|Yes| Checkout[\"Checkout Repository\"]\n    Check -->|No| Skip[\"Skip Job\"]\n    Checkout --> BlockFixup[\"Block Fixup Commit Merge\"]\n    BlockFixup -->|Fixup Found| Fail[\"Fail CI\"]\n    BlockFixup -->|No Fixups| Pass[\"Pass\"]",
      "flowchart TD\n    Start[\"Lint and Format Job\"] --> Checkout[\"Checkout Repository\"]\n    Checkout --> SetupUV[\"Setup uv package manager\"]\n    SetupUV --> InstallDeps[\"Install dependencies\"]\n    InstallDeps --> RuffLint[\"Run Ruff Lint\"]\n    RuffLint --> RuffFormat[\"Run Ruff Format Check\"]\n    RuffLint -->|Errors| Fail[\"Fail CI\"]\n    RuffFormat -->|Errors| Fail\n    RuffFormat -->|No Errors| Pass[\"Pass\"]",
      "flowchart TD\n    Start[\"Test Job\"] --> Checkout[\"Checkout Repository\"]\n    Checkout --> CreateEnv[\"Create .env file from secrets\"]\n    CreateEnv --> SetupUV[\"Setup uv package manager\"]\n    SetupUV --> InstallDeps[\"Install dependencies\"]\n    InstallDeps --> RunTests[\"Run Tests with Coverage\"]\n    RunTests --> UploadCodecov[\"Upload to Codecov\"]\n    RunTests -->|Tests Fail| FailCI[\"Fail CI\"]\n    UploadCodecov -->|Upload Fails| FailCI\n    UploadCodecov -->|Success| Pass[\"Pass\"]",
      "flowchart TD\n    Test[\"Run Tests with Coverage\"] --> GenerateXML[\"Generate XML Coverage Report\"]\n    GenerateXML --> UploadCodecov[\"Upload to Codecov\"]\n    UploadCodecov --> CheckTarget{\"Meet 85% Target?\"}\n    CheckTarget -->|Yes| Pass[\"Pass CI\"]\n    CheckTarget -->|No, but within 1% threshold| Pass\n    CheckTarget -->|No, exceeds threshold| Fail[\"Fail CI\"]",
      "flowchart LR\n    subgraph \"Developer Workflow\"\n        Fork[\"Fork Repository\"] --> Branch[\"Create Branch\"]\n        Branch --> Code[\"Make Changes\"]\n        Code --> Test[\"Run Local Tests\"]\n        Test --> Commit[\"Commit Changes\"]\n        Commit --> PR[\"Create Pull Request\"]\n        PR --> Review[\"Code Review\"]\n        Review --> Merge[\"Merge to main\"]\n    end\n    \n    subgraph \"CI Pipeline Checks\"\n        BlockFixup[\"Block Fixup Commits\"]\n        LintFormat[\"Lint and Format Check\"]\n        TestCov[\"Test with Coverage\"]\n    end\n    \n    PR --> BlockFixup\n    PR --> LintFormat\n    PR --> TestCov\n    \n    BlockFixup -->|Pass| Review\n    LintFormat -->|Pass| Review\n    TestCov -->|Pass| Review\n    \n    BlockFixup -->|Fail| Code\n    LintFormat -->|Fail| Code\n    TestCov -->|Fail| Code",
      "flowchart TD\n    Test[\"Run Tests\"] --> GenerateCovXML[\"Generate Coverage XML\"]\n    GenerateCovXML --> UploadCodecov[\"Upload to Codecov\"]\n    UploadCodecov --> PRComment[\"Generate PR Comment\"]\n    \n    subgraph \"Comment Contents\"\n        Reach[\"Coverage Reach Stats\"]\n        Diff[\"Coverage Diff\"]\n        Flags[\"Coverage Flags\"]\n        Files[\"Affected Files\"]\n    end\n    \n    PRComment --> Reach\n    PRComment --> Diff\n    PRComment --> Flags\n    PRComment --> Files"
    ],
    "potential_frontmatter": {
      "title": "CI/CD Pipeline"
    }
  }
}